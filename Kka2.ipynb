{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t8gJDJizp4et"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5lgUUfQfqCfU"
   },
   "outputs": [],
   "source": [
    "function_df = pd.read_csv('Kka2/Kka2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein</th>\n",
       "      <th>uniprot</th>\n",
       "      <th>dms_id</th>\n",
       "      <th>position</th>\n",
       "      <th>aa1</th>\n",
       "      <th>aa2</th>\n",
       "      <th>predicted?</th>\n",
       "      <th>predictions</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kka2</td>\n",
       "      <td>P00552</td>\n",
       "      <td>kka2_1:2</td>\n",
       "      <td>62</td>\n",
       "      <td>D</td>\n",
       "      <td>Q</td>\n",
       "      <td>NO</td>\n",
       "      <td>-0.382303</td>\n",
       "      <td>MIEQDGLHAGSPAAWVERLFGYDWAQQTIGCSDAAVFRLSAQGRPV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kka2</td>\n",
       "      <td>P00552</td>\n",
       "      <td>kka2_1:2</td>\n",
       "      <td>19</td>\n",
       "      <td>L</td>\n",
       "      <td>H</td>\n",
       "      <td>NO</td>\n",
       "      <td>-0.232793</td>\n",
       "      <td>MIEQDGLHAGSPAAWVERHFGYDWAQQTIGCSDAAVFRLSAQGRPV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kka2</td>\n",
       "      <td>P00552</td>\n",
       "      <td>kka2_1:2</td>\n",
       "      <td>77</td>\n",
       "      <td>C</td>\n",
       "      <td>N</td>\n",
       "      <td>NO</td>\n",
       "      <td>-0.132649</td>\n",
       "      <td>MIEQDGLHAGSPAAWVERLFGYDWAQQTIGCSDAAVFRLSAQGRPV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kka2</td>\n",
       "      <td>P00552</td>\n",
       "      <td>kka2_1:2</td>\n",
       "      <td>78</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>NO</td>\n",
       "      <td>-0.124879</td>\n",
       "      <td>MIEQDGLHAGSPAAWVERLFGYDWAQQTIGCSDAAVFRLSAQGRPV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kka2</td>\n",
       "      <td>P00552</td>\n",
       "      <td>kka2_1:2</td>\n",
       "      <td>187</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "      <td>NO</td>\n",
       "      <td>-0.075618</td>\n",
       "      <td>MIEQDGLHAGSPAAWVERLFGYDWAQQTIGCSDAAVFRLSAQGRPV...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  protein uniprot    dms_id  position aa1 aa2 predicted?  predictions  \\\n",
       "0    Kka2  P00552  kka2_1:2        62   D   Q         NO    -0.382303   \n",
       "1    Kka2  P00552  kka2_1:2        19   L   H         NO    -0.232793   \n",
       "2    Kka2  P00552  kka2_1:2        77   C   N         NO    -0.132649   \n",
       "3    Kka2  P00552  kka2_1:2        78   A   W         NO    -0.124879   \n",
       "4    Kka2  P00552  kka2_1:2       187   T   P         NO    -0.075618   \n",
       "\n",
       "                                            sequence  \n",
       "0  MIEQDGLHAGSPAAWVERLFGYDWAQQTIGCSDAAVFRLSAQGRPV...  \n",
       "1  MIEQDGLHAGSPAAWVERHFGYDWAQQTIGCSDAAVFRLSAQGRPV...  \n",
       "2  MIEQDGLHAGSPAAWVERLFGYDWAQQTIGCSDAAVFRLSAQGRPV...  \n",
       "3  MIEQDGLHAGSPAAWVERLFGYDWAQQTIGCSDAAVFRLSAQGRPV...  \n",
       "4  MIEQDGLHAGSPAAWVERLFGYDWAQQTIGCSDAAVFRLSAQGRPV...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d0I-YNvSt2sW"
   },
   "outputs": [],
   "source": [
    "function_df['sequence_len'] = function_df['sequence'].apply(lambda seq: len(seq)) \n",
    "max_len = function_df['sequence_len'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "06tBDnNKq0KT"
   },
   "outputs": [],
   "source": [
    "def sequence_to_aa(seq):\n",
    "  return list(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BChHPyycri7T"
   },
   "outputs": [],
   "source": [
    "def get_sequence_aa(df):\n",
    "  df['sequence_aa'] = df['sequence'].apply(lambda seq:sequence_to_aa(seq))\n",
    "  df['length'] = df['sequence'].apply(lambda seq:len(seq))\n",
    "  sequence_aa = np.array(df['sequence_aa'])\n",
    "  return sequence_aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m8nxTIFWro57"
   },
   "outputs": [],
   "source": [
    "sequence_aa = get_sequence_aa(function_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2046,
     "status": "ok",
     "timestamp": 1562879485473,
     "user": {
      "displayName": "Lam Vo",
      "photoUrl": "",
      "userId": "02914051558378699969"
     },
     "user_tz": 300
    },
    "id": "9PT5O2jBr0BJ",
    "outputId": "9f121849-6e8d-4cbd-fd98-106ab33763db"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import neccesary tools from Keras\n",
    "import keras\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6iaBEPPhr5q-"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sequence_aa)\n",
    "encoded = tokenizer.texts_to_sequences(sequence_aa)\n",
    "vocab_len = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XcjcQR75tP17"
   },
   "outputs": [],
   "source": [
    "X = np.array(encoded)\n",
    "y = function_df['predictions']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.698958515091104"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4eYw1KV10snV"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Embedding, LSTM, Bidirectional, Dropout, BatchNormalization, Softmax, multiply, Lambda, Flatten, Activation, RepeatVector, Permute, LeakyReLU\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.initializers import Constant\n",
    "\n",
    "# from fit_one_cycle.clr import LRFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_size = 10\n",
    "dense_sizes = [16]\n",
    "LSTM_dropout = 0.0\n",
    "n_epochs = 1500\n",
    "adam_lr = [0.003]\n",
    "initializers = ['he_uniform']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 87902,
     "status": "ok",
     "timestamp": 1562879747208,
     "user": {
      "displayName": "Lam Vo",
      "photoUrl": "",
      "userId": "02914051558378699969"
     },
     "user_tz": 300
    },
    "id": "WQ6PkDDT0-Ny",
    "outputId": "1e8ebf38-10de-4921-fd93-26c93098e73e"
   },
   "outputs": [],
   "source": [
    "def get_model_LSTM(initializer, LSTM_size):\n",
    "    input = Input(shape = [max_len])\n",
    "    embedding = Embedding(input_dim = vocab_len, \n",
    "                          output_dim = 20, \n",
    "                          input_length = max_len, \n",
    "                          trainable = True)(input)\n",
    "\n",
    "    activations = LSTM(LSTM_size,\n",
    "                       dropout = LSTM_dropout,\n",
    "                       kernel_initializer = initializer)(embedding)\n",
    "\n",
    "    sequence_representation = Dense(16, kernel_initializer = initializer)(activations)\n",
    "    sequence_representation = LeakyReLU()(sequence_representation)\n",
    "    # sequence_representation = Dropout(0.2)(sequence_representation)\n",
    "    sequence_representation = Dense(8, kernel_initializer = initializer)(sequence_representation)\n",
    "    sequence_representation = LeakyReLU()(sequence_representation)\n",
    "    # sequence_representation = Dropout(0.2)(sequence_representation)\n",
    "\n",
    "    output = Dense(1, bias_initializer = Constant(y_train.mean()))(sequence_representation)\n",
    "\n",
    "    model = Model(inputs = [input], outputs = output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_LSTM_attention(initializer, LSTM_size):\n",
    "    input = Input(shape = [max_len])\n",
    "    embedding = Embedding(input_dim = vocab_len, \n",
    "                          output_dim = 20, \n",
    "                          input_length = max_len, \n",
    "                          trainable = True)(input)\n",
    "\n",
    "    activations = LSTM(LSTM_size, return_sequences = True,\n",
    "                       dropout = LSTM_dropout,\n",
    "                       kernel_initializer = initializer)(embedding)\n",
    "\n",
    "    attention = Dense(1, activation = 'tanh', kernel_initializer = initializer)(activations)\n",
    "    attention = Flatten()(attention)\n",
    "    attention = Activation('softmax', name = 'attention_activations')(attention)\n",
    "    attention = RepeatVector(LSTM_size)(attention)\n",
    "    attention = Permute([2, 1])(attention)\n",
    "\n",
    "    sequence_representation = multiply([activations, attention])\n",
    "    sequence_representation = Lambda(lambda xin: K.sum(xin, axis = -2), output_shape = (LSTM_size,))(sequence_representation)\n",
    "    \n",
    "    sequence_representation = Dense(16, kernel_initializer = initializer)(sequence_representation)\n",
    "    sequence_representation = LeakyReLU()(sequence_representation)\n",
    "    # sequence_representation = Dropout(0.2)(sequence_representation)\n",
    "    sequence_representation = Dense(8, kernel_initializer = initializer)(sequence_representation)\n",
    "    sequence_representation = LeakyReLU()(sequence_representation)\n",
    "    # sequence_representation = Dropout(0.2)(sequence_representation)\n",
    "\n",
    "    output = Dense(1, bias_initializer = Constant(y_train.mean()))(sequence_representation)\n",
    "\n",
    "    model = Model(inputs = [input], outputs = output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_biLSTM_attention(initializer, LSTM_size):\n",
    "    input = Input(shape = [max_len])\n",
    "    embedding = Embedding(input_dim = vocab_len, \n",
    "                          output_dim = 20, \n",
    "                          input_length = max_len, \n",
    "                          trainable = True)(input)\n",
    "\n",
    "    activations = Bidirectional(LSTM(LSTM_size, return_sequences = True,\n",
    "                       dropout = LSTM_dropout,\n",
    "                       kernel_initializer = initializer))(embedding)\n",
    "\n",
    "    attention = Dense(1, activation = 'tanh', kernel_initializer = initializer)(activations)\n",
    "    attention = Flatten()(attention)\n",
    "    attention = Activation('softmax', name = 'attention_activations')(attention)\n",
    "    attention = RepeatVector(LSTM_size * 2)(attention)\n",
    "    attention = Permute([2, 1])(attention)\n",
    "\n",
    "    sequence_representation = multiply([activations, attention])\n",
    "    sequence_representation = Lambda(lambda xin: K.sum(xin, axis = -2), output_shape = (LSTM_size * 2,))(sequence_representation)\n",
    "    \n",
    "    sequence_representation = Dense(16, kernel_initializer = initializer)(sequence_representation)\n",
    "    sequence_representation = LeakyReLU()(sequence_representation)\n",
    "    # sequence_representation = Dropout(0.2)(sequence_representation)\n",
    "    sequence_representation = Dense(8, kernel_initializer = initializer)(sequence_representation)\n",
    "    sequence_representation = LeakyReLU()(sequence_representation)\n",
    "    # sequence_representation = Dropout(0.2)(sequence_representation)\n",
    "\n",
    "    output = Dense(1, bias_initializer = Constant(y_train.mean()))(sequence_representation)\n",
    "\n",
    "    model = Model(inputs = [input], outputs = output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adam_lr - 0.001 initializer - he_uniform\n",
      "WARNING:tensorflow:From C:\\Users\\Lam\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Lam\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 3238 samples, validate on 360 samples\n",
      "Epoch 1/1000\n",
      "3238/3238 [==============================] - 32s 10ms/step - loss: 0.1546 - val_loss: 0.1517\n",
      "Epoch 2/1000\n",
      "3238/3238 [==============================] - 18s 6ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 3/1000\n",
      "3238/3238 [==============================] - 17s 5ms/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 4/1000\n",
      "3238/3238 [==============================] - 10s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 5/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 6/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 7/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 8/1000\n",
      "3238/3238 [==============================] - 13s 4ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 9/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 10/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 11/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 12/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 13/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 14/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 15/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 16/1000\n",
      "3238/3238 [==============================] - 10s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 17/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 18/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 19/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 20/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 21/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 22/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 23/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 24/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 25/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 26/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 27/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 28/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 29/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 30/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 31/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 32/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 33/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 34/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 35/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 36/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 37/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 38/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 39/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 40/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 41/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 42/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 43/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 44/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 45/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 46/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 47/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 48/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 49/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 50/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 51/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 52/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 53/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 54/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 55/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 56/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 57/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 58/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 59/1000\n",
      "3238/3238 [==============================] - 10s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 60/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 61/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 62/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 63/1000\n",
      "3238/3238 [==============================] - 8s 2ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 64/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 65/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 66/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 67/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 68/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 69/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 70/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 71/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 72/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 74/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 75/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 76/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 77/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 78/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 79/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 80/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 81/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 82/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 83/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 84/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 85/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 86/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 87/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 88/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 89/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 90/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 91/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 92/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 93/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 94/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 95/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 96/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 97/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 98/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 99/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 100/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 101/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 102/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 103/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 104/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 105/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 106/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 107/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 108/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 109/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 110/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 111/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 112/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 113/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 114/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 115/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 116/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 117/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 118/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 119/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 120/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 121/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 122/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 123/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 124/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 125/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 126/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 127/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 128/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 129/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 130/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 131/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 132/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 133/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 134/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 135/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1545 - val_loss: 0.1516\n",
      "Epoch 136/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 137/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 138/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 139/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 140/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 141/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 142/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 143/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 144/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 145/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 146/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 147/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 148/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 149/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 150/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 151/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 152/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 153/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 154/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1518\n",
      "Epoch 155/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 156/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 157/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 158/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 159/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 160/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1545 - val_loss: 0.1517\n",
      "Epoch 161/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 162/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 163/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 164/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 165/1000\n",
      "3238/3238 [==============================] - 8s 2ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 166/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 167/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 168/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 169/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 170/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 171/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 172/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 173/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 174/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 175/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 176/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 177/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 178/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 179/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 180/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 181/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 182/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 183/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 184/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 185/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 186/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 187/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 188/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 189/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 190/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 191/1000\n",
      "3238/3238 [==============================] - 11s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 192/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 193/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 194/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 195/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 196/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 197/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 198/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 199/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 200/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 201/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 202/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 203/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 204/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 205/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1542 - val_loss: 0.1516\n",
      "Epoch 206/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 207/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 208/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 209/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1542 - val_loss: 0.1515\n",
      "Epoch 210/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1542 - val_loss: 0.1515\n",
      "Epoch 211/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1542 - val_loss: 0.1515\n",
      "Epoch 212/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1515\n",
      "Epoch 213/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1545 - val_loss: 0.1515\n",
      "Epoch 214/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1518\n",
      "Epoch 215/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 216/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1515\n",
      "Epoch 217/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 218/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1515\n",
      "Epoch 219/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1542 - val_loss: 0.1515\n",
      "Epoch 220/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1542 - val_loss: 0.1515\n",
      "Epoch 221/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1542 - val_loss: 0.1515\n",
      "Epoch 222/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1542 - val_loss: 0.1515\n",
      "Epoch 223/1000\n",
      "3238/3238 [==============================] - 10s 3ms/step - loss: 0.1542 - val_loss: 0.1515\n",
      "Epoch 224/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1542 - val_loss: 0.1515\n",
      "Epoch 225/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1542 - val_loss: 0.1515\n",
      "Epoch 226/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1542 - val_loss: 0.1515\n",
      "Epoch 227/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1542 - val_loss: 0.1516\n",
      "Epoch 228/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 229/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1542 - val_loss: 0.1515\n",
      "Epoch 230/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1542 - val_loss: 0.1514\n",
      "Epoch 231/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1541 - val_loss: 0.1515\n",
      "Epoch 232/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1515\n",
      "Epoch 233/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1540 - val_loss: 0.1517\n",
      "Epoch 234/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1515\n",
      "Epoch 235/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1540 - val_loss: 0.1518\n",
      "Epoch 236/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1540 - val_loss: 0.1512\n",
      "Epoch 237/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1548 - val_loss: 0.1531\n",
      "Epoch 238/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1551 - val_loss: 0.1514\n",
      "Epoch 239/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1513\n",
      "Epoch 240/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1539 - val_loss: 0.1516\n",
      "Epoch 241/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1553 - val_loss: 0.1516\n",
      "Epoch 242/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1556 - val_loss: 0.1523\n",
      "Epoch 243/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1539 - val_loss: 0.1534\n",
      "Epoch 244/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1551 - val_loss: 0.1515\n",
      "Epoch 245/1000\n",
      "3238/3238 [==============================] - 5s 2ms/step - loss: 0.1541 - val_loss: 0.1513\n",
      "Epoch 246/1000\n",
      "3238/3238 [==============================] - 1s 407us/step - loss: 0.1540 - val_loss: 0.1513\n",
      "Epoch 247/1000\n",
      "3238/3238 [==============================] - 1s 398us/step - loss: 0.1541 - val_loss: 0.1513\n",
      "Epoch 248/1000\n",
      "3238/3238 [==============================] - 1s 404us/step - loss: 0.1542 - val_loss: 0.1514\n",
      "Epoch 249/1000\n",
      "3238/3238 [==============================] - 1s 404us/step - loss: 0.1540 - val_loss: 0.1513\n",
      "Epoch 250/1000\n",
      "3238/3238 [==============================] - 2s 501us/step - loss: 0.1541 - val_loss: 0.1513\n",
      "Epoch 251/1000\n",
      "3238/3238 [==============================] - 3s 942us/step - loss: 0.1542 - val_loss: 0.1512\n",
      "Epoch 252/1000\n",
      "3238/3238 [==============================] - 6s 2ms/step - loss: 0.1539 - val_loss: 0.1512\n",
      "Epoch 253/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1540 - val_loss: 0.1514\n",
      "Epoch 254/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1541 - val_loss: 0.1512\n",
      "Epoch 255/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1540 - val_loss: 0.1514\n",
      "Epoch 256/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1540 - val_loss: 0.1512\n",
      "Epoch 257/1000\n",
      "3238/3238 [==============================] - 10s 3ms/step - loss: 0.1539 - val_loss: 0.1512\n",
      "Epoch 258/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1543 - val_loss: 0.1513\n",
      "Epoch 259/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1539 - val_loss: 0.1512\n",
      "Epoch 260/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1538 - val_loss: 0.1515\n",
      "Epoch 261/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1545 - val_loss: 0.1510\n",
      "Epoch 262/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1538 - val_loss: 0.1512\n",
      "Epoch 263/1000\n",
      "3238/3238 [==============================] - 12s 4ms/step - loss: 0.1541 - val_loss: 0.1510\n",
      "Epoch 264/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1541 - val_loss: 0.1511\n",
      "Epoch 265/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1542 - val_loss: 0.1511\n",
      "Epoch 266/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1540 - val_loss: 0.1512\n",
      "Epoch 267/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1538 - val_loss: 0.1511\n",
      "Epoch 268/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1539 - val_loss: 0.1510\n",
      "Epoch 269/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1539 - val_loss: 0.1512\n",
      "Epoch 270/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1538 - val_loss: 0.1510\n",
      "Epoch 271/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1539 - val_loss: 0.1513\n",
      "Epoch 272/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1540 - val_loss: 0.1510\n",
      "Epoch 273/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1552 - val_loss: 0.1510\n",
      "Epoch 274/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1515\n",
      "Epoch 275/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1541 - val_loss: 0.1515\n",
      "Epoch 276/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1541 - val_loss: 0.1513\n",
      "Epoch 277/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1539 - val_loss: 0.1513\n",
      "Epoch 278/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1539 - val_loss: 0.1512\n",
      "Epoch 279/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1539 - val_loss: 0.1512\n",
      "Epoch 280/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1539 - val_loss: 0.1512\n",
      "Epoch 281/1000\n",
      "3238/3238 [==============================] - 10s 3ms/step - loss: 0.1538 - val_loss: 0.1512\n",
      "Epoch 282/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1539 - val_loss: 0.1511\n",
      "Epoch 283/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1537 - val_loss: 0.1512\n",
      "Epoch 284/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1537 - val_loss: 0.1511\n",
      "Epoch 285/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1537 - val_loss: 0.1510\n",
      "Epoch 286/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1539 - val_loss: 0.1510\n",
      "Epoch 287/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1542 - val_loss: 0.1512\n",
      "Epoch 288/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1542 - val_loss: 0.1510\n",
      "Epoch 289/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1536 - val_loss: 0.1509\n",
      "Epoch 290/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1532 - val_loss: 0.1514\n",
      "Epoch 291/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1538 - val_loss: 0.1507\n",
      "Epoch 292/1000\n",
      "3238/3238 [==============================] - 8s 2ms/step - loss: 0.1534 - val_loss: 0.1541\n",
      "Epoch 293/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1512\n",
      "Epoch 294/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1540 - val_loss: 0.1513\n",
      "Epoch 295/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1531 - val_loss: 0.1512\n",
      "Epoch 296/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1536 - val_loss: 0.1508\n",
      "Epoch 297/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1533 - val_loss: 0.1502\n",
      "Epoch 298/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1535 - val_loss: 0.1503\n",
      "Epoch 299/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1530 - val_loss: 0.1505\n",
      "Epoch 300/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1533 - val_loss: 0.1511\n",
      "Epoch 301/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1552 - val_loss: 0.1502\n",
      "Epoch 302/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1534 - val_loss: 0.1503\n",
      "Epoch 303/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1528 - val_loss: 0.1512\n",
      "Epoch 304/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1528 - val_loss: 0.1535\n",
      "Epoch 305/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1544 - val_loss: 0.1501\n",
      "Epoch 306/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1532 - val_loss: 0.1501\n",
      "Epoch 307/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1530 - val_loss: 0.1504\n",
      "Epoch 308/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1527 - val_loss: 0.1500\n",
      "Epoch 309/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1528 - val_loss: 0.1499\n",
      "Epoch 310/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1522 - val_loss: 0.1515\n",
      "Epoch 311/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1537 - val_loss: 0.1497\n",
      "Epoch 312/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1521 - val_loss: 0.1502\n",
      "Epoch 313/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1525 - val_loss: 0.1524\n",
      "Epoch 314/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1557 - val_loss: 0.1531\n",
      "Epoch 315/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1536 - val_loss: 0.1500\n",
      "Epoch 316/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1532 - val_loss: 0.1564\n",
      "Epoch 317/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1572 - val_loss: 0.1528\n",
      "Epoch 318/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1540 - val_loss: 0.1517\n",
      "Epoch 319/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1533 - val_loss: 0.1514\n",
      "Epoch 320/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1532 - val_loss: 0.1509\n",
      "Epoch 321/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1537 - val_loss: 0.1509\n",
      "Epoch 322/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1533 - val_loss: 0.1510\n",
      "Epoch 323/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1531 - val_loss: 0.1508\n",
      "Epoch 324/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1532 - val_loss: 0.1504\n",
      "Epoch 325/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1527 - val_loss: 0.1502\n",
      "Epoch 326/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1526 - val_loss: 0.1505\n",
      "Epoch 327/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1527 - val_loss: 0.1500\n",
      "Epoch 328/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1525 - val_loss: 0.1497\n",
      "Epoch 329/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1520 - val_loss: 0.1496\n",
      "Epoch 330/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1525 - val_loss: 0.1497\n",
      "Epoch 331/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1521 - val_loss: 0.1507\n",
      "Epoch 332/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1523 - val_loss: 0.1493\n",
      "Epoch 333/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1517 - val_loss: 0.1509\n",
      "Epoch 334/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1518 - val_loss: 0.1492\n",
      "Epoch 335/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1529 - val_loss: 0.1525\n",
      "Epoch 336/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1520 - val_loss: 0.1490\n",
      "Epoch 337/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1533 - val_loss: 0.1491\n",
      "Epoch 338/1000\n",
      "3238/3238 [==============================] - 8s 2ms/step - loss: 0.1526 - val_loss: 0.1494\n",
      "Epoch 339/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1517 - val_loss: 0.1500\n",
      "Epoch 340/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1514 - val_loss: 0.1488\n",
      "Epoch 341/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1516 - val_loss: 0.1486\n",
      "Epoch 342/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1516 - val_loss: 0.1487\n",
      "Epoch 343/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1524 - val_loss: 0.1496\n",
      "Epoch 344/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1534 - val_loss: 0.1485\n",
      "Epoch 345/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1533 - val_loss: 0.1503\n",
      "Epoch 346/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1526 - val_loss: 0.1539\n",
      "Epoch 347/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1548 - val_loss: 0.1491\n",
      "Epoch 348/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1530 - val_loss: 0.1512\n",
      "Epoch 349/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1536 - val_loss: 0.1494\n",
      "Epoch 350/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1521 - val_loss: 0.1504\n",
      "Epoch 351/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1519 - val_loss: 0.1491\n",
      "Epoch 352/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1517 - val_loss: 0.1497\n",
      "Epoch 353/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1517 - val_loss: 0.1504\n",
      "Epoch 354/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1527 - val_loss: 0.1531\n",
      "Epoch 355/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1545 - val_loss: 0.1488\n",
      "Epoch 356/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1535 - val_loss: 0.1517\n",
      "Epoch 357/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1521 - val_loss: 0.1499\n",
      "Epoch 358/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1516 - val_loss: 0.1491\n",
      "Epoch 359/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1517 - val_loss: 0.1492\n",
      "Epoch 360/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1514 - val_loss: 0.1487\n",
      "Epoch 361/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1512 - val_loss: 0.1484\n",
      "Epoch 362/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1502 - val_loss: 0.1484\n",
      "Epoch 363/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1509 - val_loss: 0.1544\n",
      "Epoch 364/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1567 - val_loss: 0.1519\n",
      "Epoch 365/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1519 - val_loss: 0.1495\n",
      "Epoch 366/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1511 - val_loss: 0.1481\n",
      "Epoch 367/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1511 - val_loss: 0.1479\n",
      "Epoch 368/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1503 - val_loss: 0.1484\n",
      "Epoch 369/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1513 - val_loss: 0.1485\n",
      "Epoch 370/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1494 - val_loss: 0.1474\n",
      "Epoch 371/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1501 - val_loss: 0.1475\n",
      "Epoch 372/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1489 - val_loss: 0.1490\n",
      "Epoch 373/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1487 - val_loss: 0.1467\n",
      "Epoch 374/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1483 - val_loss: 0.1465\n",
      "Epoch 375/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1488 - val_loss: 0.1464\n",
      "Epoch 376/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1504 - val_loss: 0.1465\n",
      "Epoch 377/1000\n",
      "3238/3238 [==============================] - 5s 1ms/step - loss: 0.1480 - val_loss: 0.1469\n",
      "Epoch 378/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1504 - val_loss: 0.1576\n",
      "Epoch 379/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1570 - val_loss: 0.1472\n",
      "Epoch 380/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1552 - val_loss: 0.1472\n",
      "Epoch 381/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1512 - val_loss: 0.1477\n",
      "Epoch 382/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1495 - val_loss: 0.1510\n",
      "Epoch 383/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1509 - val_loss: 0.1499\n",
      "Epoch 384/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1503 - val_loss: 0.1478\n",
      "Epoch 385/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1500 - val_loss: 0.1476\n",
      "Epoch 386/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1490 - val_loss: 0.1472\n",
      "Epoch 387/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1491 - val_loss: 0.1477\n",
      "Epoch 388/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1514 - val_loss: 0.1592\n",
      "Epoch 389/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1552 - val_loss: 0.1473\n",
      "Epoch 390/1000\n",
      "3238/3238 [==============================] - 10s 3ms/step - loss: 0.1523 - val_loss: 0.1515\n",
      "Epoch 391/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1505 - val_loss: 0.1475\n",
      "Epoch 392/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1489 - val_loss: 0.1476\n",
      "Epoch 393/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1502 - val_loss: 0.1492\n",
      "Epoch 394/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1513 - val_loss: 0.1536\n",
      "Epoch 395/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1514 - val_loss: 0.1482\n",
      "Epoch 396/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1498 - val_loss: 0.1485\n",
      "Epoch 397/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1488 - val_loss: 0.1469\n",
      "Epoch 398/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1481 - val_loss: 0.1470\n",
      "Epoch 399/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1490 - val_loss: 0.1467\n",
      "Epoch 400/1000\n",
      "3238/3238 [==============================] - 10s 3ms/step - loss: 0.1519 - val_loss: 0.1537\n",
      "Epoch 401/1000\n",
      "3238/3238 [==============================] - 10s 3ms/step - loss: 0.1570 - val_loss: 0.1476\n",
      "Epoch 402/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1562 - val_loss: 0.1662\n",
      "Epoch 403/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1585 - val_loss: 0.1564\n",
      "Epoch 404/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1528 - val_loss: 0.1506\n",
      "Epoch 405/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1530 - val_loss: 0.1497\n",
      "Epoch 406/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1516 - val_loss: 0.1492\n",
      "Epoch 407/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1510 - val_loss: 0.1487\n",
      "Epoch 408/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1506 - val_loss: 0.1490\n",
      "Epoch 409/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1507 - val_loss: 0.1486\n",
      "Epoch 410/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1502 - val_loss: 0.1479\n",
      "Epoch 411/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1498 - val_loss: 0.1507\n",
      "Epoch 412/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1528 - val_loss: 0.1483\n",
      "Epoch 413/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1509 - val_loss: 0.1476\n",
      "Epoch 414/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1497 - val_loss: 0.1487\n",
      "Epoch 415/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1496 - val_loss: 0.1474\n",
      "Epoch 416/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1490 - val_loss: 0.1484\n",
      "Epoch 417/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1501 - val_loss: 0.1518\n",
      "Epoch 418/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1534 - val_loss: 0.1527\n",
      "Epoch 419/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1527 - val_loss: 0.1490\n",
      "Epoch 420/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1501 - val_loss: 0.1485\n",
      "Epoch 421/1000\n",
      "3238/3238 [==============================] - 10s 3ms/step - loss: 0.1488 - val_loss: 0.1473\n",
      "Epoch 422/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1496 - val_loss: 0.1475\n",
      "Epoch 423/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1482 - val_loss: 0.1468\n",
      "Epoch 424/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1479 - val_loss: 0.1466\n",
      "Epoch 425/1000\n",
      "3238/3238 [==============================] - 10s 3ms/step - loss: 0.1476 - val_loss: 0.1464\n",
      "Epoch 426/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1474 - val_loss: 0.1463\n",
      "Epoch 427/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1471 - val_loss: 0.1463\n",
      "Epoch 428/1000\n",
      "3238/3238 [==============================] - 10s 3ms/step - loss: 0.1483 - val_loss: 0.1466\n",
      "Epoch 429/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1482 - val_loss: 0.1464\n",
      "Epoch 430/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1481 - val_loss: 0.1506\n",
      "Epoch 431/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1520 - val_loss: 0.1479\n",
      "Epoch 432/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1497 - val_loss: 0.1543\n",
      "Epoch 433/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1506 - val_loss: 0.1471\n",
      "Epoch 434/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1516 - val_loss: 0.1476\n",
      "Epoch 435/1000\n",
      "3238/3238 [==============================] - 10s 3ms/step - loss: 0.1539 - val_loss: 0.1515\n",
      "Epoch 436/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1489 - val_loss: 0.1462\n",
      "Epoch 437/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1479 - val_loss: 0.1463\n",
      "Epoch 438/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1470 - val_loss: 0.1477\n",
      "Epoch 439/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1483 - val_loss: 0.1479\n",
      "Epoch 440/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1517 - val_loss: 0.1487\n",
      "Epoch 441/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1496 - val_loss: 0.1482\n",
      "Epoch 442/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1501 - val_loss: 0.1462\n",
      "Epoch 443/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1489 - val_loss: 0.1459\n",
      "Epoch 444/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1480 - val_loss: 0.1477\n",
      "Epoch 445/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1479 - val_loss: 0.1472\n",
      "Epoch 446/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1473 - val_loss: 0.1469\n",
      "Epoch 447/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1470 - val_loss: 0.1498\n",
      "Epoch 448/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1489 - val_loss: 0.1502\n",
      "Epoch 449/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1508 - val_loss: 0.1567\n",
      "Epoch 450/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1527 - val_loss: 0.1455\n",
      "Epoch 451/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1504 - val_loss: 0.1455\n",
      "Epoch 452/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1492 - val_loss: 0.1504\n",
      "Epoch 453/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1507 - val_loss: 0.1520\n",
      "Epoch 454/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1509 - val_loss: 0.1459\n",
      "Epoch 455/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1492 - val_loss: 0.1474\n",
      "Epoch 456/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1495 - val_loss: 0.1469\n",
      "Epoch 457/1000\n",
      "3238/3238 [==============================] - 10s 3ms/step - loss: 0.1489 - val_loss: 0.1499\n",
      "Epoch 458/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3238/3238 [==============================] - 10s 3ms/step - loss: 0.1493 - val_loss: 0.1477\n",
      "Epoch 459/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1506 - val_loss: 0.1499\n",
      "Epoch 460/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1492 - val_loss: 0.1458\n",
      "Epoch 461/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1485 - val_loss: 0.1466\n",
      "Epoch 462/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1481 - val_loss: 0.1456\n",
      "Epoch 463/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1467 - val_loss: 0.1452\n",
      "Epoch 464/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1466 - val_loss: 0.1450\n",
      "Epoch 465/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1465 - val_loss: 0.1449\n",
      "Epoch 466/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1462 - val_loss: 0.1451\n",
      "Epoch 467/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1468 - val_loss: 0.1456\n",
      "Epoch 468/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1489 - val_loss: 0.1477\n",
      "Epoch 469/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1487 - val_loss: 0.1449\n",
      "Epoch 470/1000\n",
      "3238/3238 [==============================] - 10s 3ms/step - loss: 0.1470 - val_loss: 0.1452\n",
      "Epoch 471/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1479 - val_loss: 0.1506\n",
      "Epoch 472/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1502 - val_loss: 0.1519\n",
      "Epoch 473/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1488 - val_loss: 0.1465\n",
      "Epoch 474/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1464 - val_loss: 0.1463\n",
      "Epoch 475/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1456 - val_loss: 0.1445\n",
      "Epoch 476/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1459 - val_loss: 0.1478\n",
      "Epoch 477/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1460 - val_loss: 0.1448\n",
      "Epoch 478/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1454 - val_loss: 0.1452\n",
      "Epoch 479/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1459 - val_loss: 0.1447\n",
      "Epoch 480/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1470 - val_loss: 0.1457\n",
      "Epoch 481/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1450 - val_loss: 0.1442\n",
      "Epoch 482/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1452 - val_loss: 0.1451\n",
      "Epoch 483/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1458 - val_loss: 0.1498\n",
      "Epoch 484/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1469 - val_loss: 0.1443\n",
      "Epoch 485/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1451 - val_loss: 0.1502\n",
      "Epoch 486/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1466 - val_loss: 0.1445\n",
      "Epoch 487/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1448 - val_loss: 0.1461\n",
      "Epoch 488/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1448 - val_loss: 0.1460\n",
      "Epoch 489/1000\n",
      "3238/3238 [==============================] - 10s 3ms/step - loss: 0.1471 - val_loss: 0.1443\n",
      "Epoch 490/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1463 - val_loss: 0.1451\n",
      "Epoch 491/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1448 - val_loss: 0.1437\n",
      "Epoch 492/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1448 - val_loss: 0.1453\n",
      "Epoch 493/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1459 - val_loss: 0.1495\n",
      "Epoch 494/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1469 - val_loss: 0.1440\n",
      "Epoch 495/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1454 - val_loss: 0.1481\n",
      "Epoch 496/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1463 - val_loss: 0.1446\n",
      "Epoch 497/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1452 - val_loss: 0.1436\n",
      "Epoch 498/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1441 - val_loss: 0.1454\n",
      "Epoch 499/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1445 - val_loss: 0.1438\n",
      "Epoch 500/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1437 - val_loss: 0.1442\n",
      "Epoch 501/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1450 - val_loss: 0.1435\n",
      "Epoch 502/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1467 - val_loss: 0.1453\n",
      "Epoch 503/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1467 - val_loss: 0.1454\n",
      "Epoch 504/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1456 - val_loss: 0.1539\n",
      "Epoch 505/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1511 - val_loss: 0.1460\n",
      "Epoch 506/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1456 - val_loss: 0.1440\n",
      "Epoch 507/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1452 - val_loss: 0.1476\n",
      "Epoch 508/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1454 - val_loss: 0.1444\n",
      "Epoch 509/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1460 - val_loss: 0.1440\n",
      "Epoch 510/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1442 - val_loss: 0.1458\n",
      "Epoch 511/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1476 - val_loss: 0.1550\n",
      "Epoch 512/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1540 - val_loss: 0.1497\n",
      "Epoch 513/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1607 - val_loss: 0.1463\n",
      "Epoch 514/1000\n",
      "3238/3238 [==============================] - 2s 472us/step - loss: 0.1502 - val_loss: 0.1496\n",
      "Epoch 515/1000\n",
      "3238/3238 [==============================] - 1s 401us/step - loss: 0.1481 - val_loss: 0.1457\n",
      "Epoch 516/1000\n",
      "3238/3238 [==============================] - 1s 401us/step - loss: 0.1466 - val_loss: 0.1454\n",
      "Epoch 517/1000\n",
      "3238/3238 [==============================] - 1s 404us/step - loss: 0.1466 - val_loss: 0.1448\n",
      "Epoch 518/1000\n",
      "3238/3238 [==============================] - 1s 414us/step - loss: 0.1455 - val_loss: 0.1442\n",
      "Epoch 519/1000\n",
      "3238/3238 [==============================] - 3s 1ms/step - loss: 0.1451 - val_loss: 0.1450\n",
      "Epoch 520/1000\n",
      "3238/3238 [==============================] - 1s 429us/step - loss: 0.1450 - val_loss: 0.1455\n",
      "Epoch 521/1000\n",
      "3238/3238 [==============================] - 6s 2ms/step - loss: 0.1449 - val_loss: 0.1438\n",
      "Epoch 522/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1456 - val_loss: 0.1444\n",
      "Epoch 523/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1470 - val_loss: 0.1472\n",
      "Epoch 524/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1463 - val_loss: 0.1437\n",
      "Epoch 525/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1453 - val_loss: 0.1430\n",
      "Epoch 526/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1437 - val_loss: 0.1437\n",
      "Epoch 527/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1435 - val_loss: 0.1432\n",
      "Epoch 528/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1435 - val_loss: 0.1428\n",
      "Epoch 529/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1432 - val_loss: 0.1445\n",
      "Epoch 530/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1445 - val_loss: 0.1439\n",
      "Epoch 531/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1461 - val_loss: 0.1430\n",
      "Epoch 532/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1439 - val_loss: 0.1466\n",
      "Epoch 533/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1457 - val_loss: 0.1481\n",
      "Epoch 534/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1519 - val_loss: 0.1454\n",
      "Epoch 535/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1509 - val_loss: 0.1446\n",
      "Epoch 536/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1453 - val_loss: 0.1464\n",
      "Epoch 537/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1454 - val_loss: 0.1437\n",
      "Epoch 538/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1437 - val_loss: 0.1431\n",
      "Epoch 539/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1436 - val_loss: 0.1450\n",
      "Epoch 540/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1471 - val_loss: 0.1434\n",
      "Epoch 541/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1449 - val_loss: 0.1426\n",
      "Epoch 542/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1439 - val_loss: 0.1443\n",
      "Epoch 543/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1456 - val_loss: 0.1434\n",
      "Epoch 544/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1446 - val_loss: 0.1427\n",
      "Epoch 545/1000\n",
      "3238/3238 [==============================] - 10s 3ms/step - loss: 0.1447 - val_loss: 0.1457\n",
      "Epoch 546/1000\n",
      "3238/3238 [==============================] - 10s 3ms/step - loss: 0.1481 - val_loss: 0.1424\n",
      "Epoch 547/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1463 - val_loss: 0.1425\n",
      "Epoch 548/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1432 - val_loss: 0.1427\n",
      "Epoch 549/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1426 - val_loss: 0.1427\n",
      "Epoch 550/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1429 - val_loss: 0.1461\n",
      "Epoch 551/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1443 - val_loss: 0.1456\n",
      "Epoch 552/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1436 - val_loss: 0.1435\n",
      "Epoch 553/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1453 - val_loss: 0.1485\n",
      "Epoch 554/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1451 - val_loss: 0.1480\n",
      "Epoch 555/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1440 - val_loss: 0.1424\n",
      "Epoch 556/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1434 - val_loss: 0.1446\n",
      "Epoch 557/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1442 - val_loss: 0.1430\n",
      "Epoch 558/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1444 - val_loss: 0.1424\n",
      "Epoch 559/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1425 - val_loss: 0.1419\n",
      "Epoch 560/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1423 - val_loss: 0.1427\n",
      "Epoch 561/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1420 - val_loss: 0.1419\n",
      "Epoch 562/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1420 - val_loss: 0.1423\n",
      "Epoch 563/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1422 - val_loss: 0.1430\n",
      "Epoch 564/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1428 - val_loss: 0.1416\n",
      "Epoch 565/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1444 - val_loss: 0.1492\n",
      "Epoch 566/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1468 - val_loss: 0.1425\n",
      "Epoch 567/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1430 - val_loss: 0.1416\n",
      "Epoch 568/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1421 - val_loss: 0.1416\n",
      "Epoch 569/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1415 - val_loss: 0.1414\n",
      "Epoch 570/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1431 - val_loss: 0.1426\n",
      "Epoch 571/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1415 - val_loss: 0.1415\n",
      "Epoch 572/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1414 - val_loss: 0.1428\n",
      "Epoch 573/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1420 - val_loss: 0.1431\n",
      "Epoch 574/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1438 - val_loss: 0.1443\n",
      "Epoch 575/1000\n",
      "3238/3238 [==============================] - 10s 3ms/step - loss: 0.1446 - val_loss: 0.1471\n",
      "Epoch 576/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1441 - val_loss: 0.1471\n",
      "Epoch 577/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1447 - val_loss: 0.1430\n",
      "Epoch 578/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1419 - val_loss: 0.1421\n",
      "Epoch 579/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1429 - val_loss: 0.1412\n",
      "Epoch 580/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1420 - val_loss: 0.1417\n",
      "Epoch 581/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1430 - val_loss: 0.1443\n",
      "Epoch 582/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1468 - val_loss: 0.1427\n",
      "Epoch 583/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1420 - val_loss: 0.1411\n",
      "Epoch 584/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1416 - val_loss: 0.1441\n",
      "Epoch 585/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1416 - val_loss: 0.1409\n",
      "Epoch 586/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1413 - val_loss: 0.1417\n",
      "Epoch 587/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1417 - val_loss: 0.1413\n",
      "Epoch 588/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1417 - val_loss: 0.1413\n",
      "Epoch 589/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1416 - val_loss: 0.1414\n",
      "Epoch 590/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1409 - val_loss: 0.1427\n",
      "Epoch 591/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1419 - val_loss: 0.1407\n",
      "Epoch 592/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1456 - val_loss: 0.1414\n",
      "Epoch 593/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1470 - val_loss: 0.1421\n",
      "Epoch 594/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1418 - val_loss: 0.1406\n",
      "Epoch 595/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1414 - val_loss: 0.1407\n",
      "Epoch 596/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1404 - val_loss: 0.1463\n",
      "Epoch 597/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1422 - val_loss: 0.1409\n",
      "Epoch 598/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1417 - val_loss: 0.1405\n",
      "Epoch 599/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1423 - val_loss: 0.1404\n",
      "Epoch 600/1000\n",
      "3238/3238 [==============================] - 10s 3ms/step - loss: 0.1443 - val_loss: 0.1406\n",
      "Epoch 601/1000\n",
      "3238/3238 [==============================] - 11s 3ms/step - loss: 0.1437 - val_loss: 0.1407\n",
      "Epoch 602/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1413 - val_loss: 0.1426\n",
      "Epoch 603/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1422 - val_loss: 0.1405\n",
      "Epoch 604/1000\n",
      "3238/3238 [==============================] - 10s 3ms/step - loss: 0.1413 - val_loss: 0.1403\n",
      "Epoch 605/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1405 - val_loss: 0.1402\n",
      "Epoch 606/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1402 - val_loss: 0.1406\n",
      "Epoch 607/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1407 - val_loss: 0.1418\n",
      "Epoch 608/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1431 - val_loss: 0.1411\n",
      "Epoch 609/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1405 - val_loss: 0.1411\n",
      "Epoch 610/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1403 - val_loss: 0.1430\n",
      "Epoch 611/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1412 - val_loss: 0.1411\n",
      "Epoch 612/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1423 - val_loss: 0.1402\n",
      "Epoch 613/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1404 - val_loss: 0.1420\n",
      "Epoch 614/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1409 - val_loss: 0.1409\n",
      "Epoch 615/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1397 - val_loss: 0.1404\n",
      "Epoch 616/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1413 - val_loss: 0.1427\n",
      "Epoch 617/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1434 - val_loss: 0.1496\n",
      "Epoch 618/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1444 - val_loss: 0.1423\n",
      "Epoch 619/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1419 - val_loss: 0.1413\n",
      "Epoch 620/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1422 - val_loss: 0.1413\n",
      "Epoch 621/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1414 - val_loss: 0.1405\n",
      "Epoch 622/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1424 - val_loss: 0.1410\n",
      "Epoch 623/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1438 - val_loss: 0.1409\n",
      "Epoch 624/1000\n",
      "3238/3238 [==============================] - 10s 3ms/step - loss: 0.1453 - val_loss: 0.1434\n",
      "Epoch 625/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1435 - val_loss: 0.1441\n",
      "Epoch 626/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1426 - val_loss: 0.1405\n",
      "Epoch 627/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1409 - val_loss: 0.1398\n",
      "Epoch 628/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1406 - val_loss: 0.1395\n",
      "Epoch 629/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1395 - val_loss: 0.1398\n",
      "Epoch 630/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1392 - val_loss: 0.1393\n",
      "Epoch 631/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1393 - val_loss: 0.1402\n",
      "Epoch 632/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1411 - val_loss: 0.1430\n",
      "Epoch 633/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1423 - val_loss: 0.1439\n",
      "Epoch 634/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1409 - val_loss: 0.1395\n",
      "Epoch 635/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1391 - val_loss: 0.1410\n",
      "Epoch 636/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1396 - val_loss: 0.1412\n",
      "Epoch 637/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1415 - val_loss: 0.1392\n",
      "Epoch 638/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1411 - val_loss: 0.1419\n",
      "Epoch 639/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1404 - val_loss: 0.1411\n",
      "Epoch 640/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1418 - val_loss: 0.1455\n",
      "Epoch 641/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1487 - val_loss: 0.1417\n",
      "Epoch 642/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1440 - val_loss: 0.1467\n",
      "Epoch 643/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1434 - val_loss: 0.1453\n",
      "Epoch 644/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1449 - val_loss: 0.1415\n",
      "Epoch 645/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1420 - val_loss: 0.1431\n",
      "Epoch 646/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1415 - val_loss: 0.1399\n",
      "Epoch 647/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1399 - val_loss: 0.1403\n",
      "Epoch 648/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1402 - val_loss: 0.1422\n",
      "Epoch 649/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1396 - val_loss: 0.1400\n",
      "Epoch 650/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1401 - val_loss: 0.1394\n",
      "Epoch 651/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1390 - val_loss: 0.1393\n",
      "Epoch 652/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1388 - val_loss: 0.1388\n",
      "Epoch 653/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1396 - val_loss: 0.1412\n",
      "Epoch 654/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1397 - val_loss: 0.1387\n",
      "Epoch 655/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1401 - val_loss: 0.1387\n",
      "Epoch 656/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1386 - val_loss: 0.1389\n",
      "Epoch 657/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1383 - val_loss: 0.1400\n",
      "Epoch 658/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1392 - val_loss: 0.1388\n",
      "Epoch 659/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1386 - val_loss: 0.1436\n",
      "Epoch 660/1000\n",
      "3238/3238 [==============================] - 8s 3ms/step - loss: 0.1391 - val_loss: 0.1395\n",
      "Epoch 661/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1382 - val_loss: 0.1389\n",
      "Epoch 662/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1388 - val_loss: 0.1423\n",
      "Epoch 663/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1411 - val_loss: 0.1539\n",
      "Epoch 664/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1449 - val_loss: 0.1434\n",
      "Epoch 665/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1433 - val_loss: 0.1443\n",
      "Epoch 666/1000\n",
      "3238/3238 [==============================] - 12s 4ms/step - loss: 0.1405 - val_loss: 0.1388\n",
      "Epoch 667/1000\n",
      "3238/3238 [==============================] - 10s 3ms/step - loss: 0.1382 - val_loss: 0.1392\n",
      "Epoch 668/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1381 - val_loss: 0.1383\n",
      "Epoch 669/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1377 - val_loss: 0.1414\n",
      "Epoch 670/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1397 - val_loss: 0.1383\n",
      "Epoch 671/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1389 - val_loss: 0.1406\n",
      "Epoch 672/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1392 - val_loss: 0.1421\n",
      "Epoch 673/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1380 - val_loss: 0.1399\n",
      "Epoch 674/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1380 - val_loss: 0.1382\n",
      "Epoch 675/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1387 - val_loss: 0.1439\n",
      "Epoch 676/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1392 - val_loss: 0.1387\n",
      "Epoch 677/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1378 - val_loss: 0.1399\n",
      "Epoch 678/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1378 - val_loss: 0.1387\n",
      "Epoch 679/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1372 - val_loss: 0.1383\n",
      "Epoch 680/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1374 - val_loss: 0.1387\n",
      "Epoch 681/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1377 - val_loss: 0.1381\n",
      "Epoch 682/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1381 - val_loss: 0.1382\n",
      "Epoch 683/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1373 - val_loss: 0.1384\n",
      "Epoch 684/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1375 - val_loss: 0.1388\n",
      "Epoch 685/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1370 - val_loss: 0.1520\n",
      "Epoch 686/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1444 - val_loss: 0.1523\n",
      "Epoch 687/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1420 - val_loss: 0.1415\n",
      "Epoch 688/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1397 - val_loss: 0.1468\n",
      "Epoch 689/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1413 - val_loss: 0.1394\n",
      "Epoch 690/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1388 - val_loss: 0.1417\n",
      "Epoch 691/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1394 - val_loss: 0.1412\n",
      "Epoch 692/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1427 - val_loss: 0.1395\n",
      "Epoch 693/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1402 - val_loss: 0.1390\n",
      "Epoch 694/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1392 - val_loss: 0.1388\n",
      "Epoch 695/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1372 - val_loss: 0.1397\n",
      "Epoch 696/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1375 - val_loss: 0.1392\n",
      "Epoch 697/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1377 - val_loss: 0.1417\n",
      "Epoch 698/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1411 - val_loss: 0.1425\n",
      "Epoch 699/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1401 - val_loss: 0.1445\n",
      "Epoch 700/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1399 - val_loss: 0.1390\n",
      "Epoch 701/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1395 - val_loss: 0.1394\n",
      "Epoch 702/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1404 - val_loss: 0.1391\n",
      "Epoch 703/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1427 - val_loss: 0.1395\n",
      "Epoch 704/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1409 - val_loss: 0.1451\n",
      "Epoch 705/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1411 - val_loss: 0.1425\n",
      "Epoch 706/1000\n",
      "3238/3238 [==============================] - 10s 3ms/step - loss: 0.1401 - val_loss: 0.1391\n",
      "Epoch 707/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1377 - val_loss: 0.1382\n",
      "Epoch 708/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1381 - val_loss: 0.1381\n",
      "Epoch 709/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1373 - val_loss: 0.1405\n",
      "Epoch 710/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1383 - val_loss: 0.1382\n",
      "Epoch 711/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1367 - val_loss: 0.1380\n",
      "Epoch 712/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1371 - val_loss: 0.1386\n",
      "Epoch 713/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1370 - val_loss: 0.1401\n",
      "Epoch 714/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1386 - val_loss: 0.1398\n",
      "Epoch 715/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1381 - val_loss: 0.1409\n",
      "Epoch 716/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1397 - val_loss: 0.1425\n",
      "Epoch 717/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1388 - val_loss: 0.1399\n",
      "Epoch 718/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1372 - val_loss: 0.1403\n",
      "Epoch 719/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1375 - val_loss: 0.1392\n",
      "Epoch 720/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1377 - val_loss: 0.1408\n",
      "Epoch 721/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1365 - val_loss: 0.1377\n",
      "Epoch 722/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1357 - val_loss: 0.1381\n",
      "Epoch 723/1000\n",
      "3238/3238 [==============================] - 10s 3ms/step - loss: 0.1363 - val_loss: 0.1381\n",
      "Epoch 724/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1368 - val_loss: 0.1382\n",
      "Epoch 725/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1365 - val_loss: 0.1405\n",
      "Epoch 726/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1363 - val_loss: 0.1385\n",
      "Epoch 727/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1354 - val_loss: 0.1375\n",
      "Epoch 728/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1370 - val_loss: 0.1453\n",
      "Epoch 729/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1449 - val_loss: 0.1442\n",
      "Epoch 730/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1381 - val_loss: 0.1396\n",
      "Epoch 731/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1399 - val_loss: 0.1391\n",
      "Epoch 732/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1384 - val_loss: 0.1414\n",
      "Epoch 733/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1402 - val_loss: 0.1408\n",
      "Epoch 734/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1403 - val_loss: 0.1419\n",
      "Epoch 735/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1394 - val_loss: 0.1444\n",
      "Epoch 736/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1402 - val_loss: 0.1386\n",
      "Epoch 737/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1382 - val_loss: 0.1429\n",
      "Epoch 738/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1404 - val_loss: 0.1444\n",
      "Epoch 739/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1394 - val_loss: 0.1410\n",
      "Epoch 740/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1381 - val_loss: 0.1391\n",
      "Epoch 741/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1369 - val_loss: 0.1415\n",
      "Epoch 742/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1364 - val_loss: 0.1377\n",
      "Epoch 743/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1352 - val_loss: 0.1396\n",
      "Epoch 744/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1377 - val_loss: 0.1382\n",
      "Epoch 745/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1356 - val_loss: 0.1402\n",
      "Epoch 746/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1363 - val_loss: 0.1423\n",
      "Epoch 747/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1381 - val_loss: 0.1401\n",
      "Epoch 748/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1365 - val_loss: 0.1402\n",
      "Epoch 749/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1356 - val_loss: 0.1380\n",
      "Epoch 750/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1348 - val_loss: 0.1378\n",
      "Epoch 751/1000\n",
      "3238/3238 [==============================] - 14s 4ms/step - loss: 0.1355 - val_loss: 0.1373\n",
      "Epoch 752/1000\n",
      "3238/3238 [==============================] - 17s 5ms/step - loss: 0.1341 - val_loss: 0.1377\n",
      "Epoch 753/1000\n",
      "3238/3238 [==============================] - 21s 6ms/step - loss: 0.1342 - val_loss: 0.1384\n",
      "Epoch 754/1000\n",
      "3238/3238 [==============================] - 17s 5ms/step - loss: 0.1346 - val_loss: 0.1390\n",
      "Epoch 755/1000\n",
      "3238/3238 [==============================] - 14s 4ms/step - loss: 0.1351 - val_loss: 0.1419\n",
      "Epoch 756/1000\n",
      "3238/3238 [==============================] - 15s 5ms/step - loss: 0.1361 - val_loss: 0.1382\n",
      "Epoch 757/1000\n",
      "3238/3238 [==============================] - 14s 4ms/step - loss: 0.1352 - val_loss: 0.1383\n",
      "Epoch 758/1000\n",
      "3238/3238 [==============================] - 15s 5ms/step - loss: 0.1350 - val_loss: 0.1395\n",
      "Epoch 759/1000\n",
      "3238/3238 [==============================] - 17s 5ms/step - loss: 0.1348 - val_loss: 0.1377\n",
      "Epoch 760/1000\n",
      "3238/3238 [==============================] - 15s 5ms/step - loss: 0.1344 - val_loss: 0.1398\n",
      "Epoch 761/1000\n",
      "3238/3238 [==============================] - 13s 4ms/step - loss: 0.1349 - val_loss: 0.1396\n",
      "Epoch 762/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1352 - val_loss: 0.1383\n",
      "Epoch 763/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1338 - val_loss: 0.1369\n",
      "Epoch 764/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1329 - val_loss: 0.1371\n",
      "Epoch 765/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1332 - val_loss: 0.1390\n",
      "Epoch 766/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3238/3238 [==============================] - 10s 3ms/step - loss: 0.1334 - val_loss: 0.1517\n",
      "Epoch 767/1000\n",
      "3238/3238 [==============================] - 9s 3ms/step - loss: 0.1381 - val_loss: 0.1408\n",
      "Epoch 768/1000\n",
      "3238/3238 [==============================] - 13s 4ms/step - loss: 0.1378 - val_loss: 0.1384\n",
      "Epoch 769/1000\n",
      "3238/3238 [==============================] - 15s 5ms/step - loss: 0.1373 - val_loss: 0.1369\n",
      "Epoch 770/1000\n",
      "3238/3238 [==============================] - 15s 5ms/step - loss: 0.1329 - val_loss: 0.1400\n",
      "Epoch 771/1000\n",
      "3238/3238 [==============================] - 12s 4ms/step - loss: 0.1347 - val_loss: 0.1372\n",
      "Epoch 772/1000\n",
      "3238/3238 [==============================] - 12s 4ms/step - loss: 0.1337 - val_loss: 0.1405\n",
      "Epoch 773/1000\n",
      "3238/3238 [==============================] - 5s 1ms/step - loss: 0.1357 - val_loss: 0.1388\n",
      "Epoch 774/1000\n",
      "3238/3238 [==============================] - 1s 342us/step - loss: 0.1336 - val_loss: 0.1409\n",
      "Epoch 775/1000\n",
      "3238/3238 [==============================] - 1s 418us/step - loss: 0.1354 - val_loss: 0.1382\n",
      "Epoch 776/1000\n",
      "3238/3238 [==============================] - 1s 360us/step - loss: 0.1345 - val_loss: 0.1380\n",
      "Epoch 777/1000\n",
      "3238/3238 [==============================] - 1s 357us/step - loss: 0.1346 - val_loss: 0.1372\n",
      "Epoch 778/1000\n",
      "3238/3238 [==============================] - 1s 355us/step - loss: 0.1330 - val_loss: 0.1364\n",
      "Epoch 779/1000\n",
      "3238/3238 [==============================] - 1s 350us/step - loss: 0.1319 - val_loss: 0.1381\n",
      "Epoch 780/1000\n",
      "3238/3238 [==============================] - 1s 351us/step - loss: 0.1328 - val_loss: 0.1362\n",
      "Epoch 781/1000\n",
      "3238/3238 [==============================] - 1s 353us/step - loss: 0.1324 - val_loss: 0.1363\n",
      "Epoch 782/1000\n",
      "3238/3238 [==============================] - 1s 416us/step - loss: 0.1315 - val_loss: 0.1369\n",
      "Epoch 783/1000\n",
      "3238/3238 [==============================] - 1s 354us/step - loss: 0.1320 - val_loss: 0.1373\n",
      "Epoch 784/1000\n",
      "3238/3238 [==============================] - 1s 423us/step - loss: 0.1329 - val_loss: 0.1364\n",
      "Epoch 785/1000\n",
      "3238/3238 [==============================] - 1s 400us/step - loss: 0.1318 - val_loss: 0.1379\n",
      "Epoch 786/1000\n",
      "3238/3238 [==============================] - 1s 347us/step - loss: 0.1319 - val_loss: 0.1363\n",
      "Epoch 787/1000\n",
      "3238/3238 [==============================] - 1s 407us/step - loss: 0.1313 - val_loss: 0.1368\n",
      "Epoch 788/1000\n",
      "3238/3238 [==============================] - 1s 402us/step - loss: 0.1325 - val_loss: 0.1379\n",
      "Epoch 789/1000\n",
      "3238/3238 [==============================] - 1s 363us/step - loss: 0.1339 - val_loss: 0.1370\n",
      "Epoch 790/1000\n",
      "3238/3238 [==============================] - 1s 384us/step - loss: 0.1333 - val_loss: 0.1356\n",
      "Epoch 791/1000\n",
      "3238/3238 [==============================] - 2s 569us/step - loss: 0.1325 - val_loss: 0.1354\n",
      "Epoch 792/1000\n",
      "3238/3238 [==============================] - 1s 347us/step - loss: 0.1314 - val_loss: 0.1385\n",
      "Epoch 793/1000\n",
      "3238/3238 [==============================] - 1s 349us/step - loss: 0.1341 - val_loss: 0.1376\n",
      "Epoch 794/1000\n",
      "3238/3238 [==============================] - 1s 363us/step - loss: 0.1341 - val_loss: 0.1397\n",
      "Epoch 795/1000\n",
      "3238/3238 [==============================] - 1s 406us/step - loss: 0.1333 - val_loss: 0.1367\n",
      "Epoch 796/1000\n",
      "3238/3238 [==============================] - 2s 557us/step - loss: 0.1319 - val_loss: 0.1447\n",
      "Epoch 797/1000\n",
      "3238/3238 [==============================] - 1s 360us/step - loss: 0.1396 - val_loss: 0.1358\n",
      "Epoch 798/1000\n",
      "3238/3238 [==============================] - 1s 354us/step - loss: 0.1332 - val_loss: 0.1372\n",
      "Epoch 799/1000\n",
      "3238/3238 [==============================] - 1s 353us/step - loss: 0.1315 - val_loss: 0.1360\n",
      "Epoch 800/1000\n",
      "3238/3238 [==============================] - 1s 386us/step - loss: 0.1320 - val_loss: 0.1363\n",
      "Epoch 801/1000\n",
      "3238/3238 [==============================] - 1s 392us/step - loss: 0.1326 - val_loss: 0.1355\n",
      "Epoch 802/1000\n",
      "3238/3238 [==============================] - 1s 358us/step - loss: 0.1307 - val_loss: 0.1361\n",
      "Epoch 803/1000\n",
      "3238/3238 [==============================] - 1s 385us/step - loss: 0.1310 - val_loss: 0.1353\n",
      "Epoch 804/1000\n",
      "3238/3238 [==============================] - 1s 364us/step - loss: 0.1319 - val_loss: 0.1369\n",
      "Epoch 805/1000\n",
      "3238/3238 [==============================] - 1s 385us/step - loss: 0.1317 - val_loss: 0.1380\n",
      "Epoch 806/1000\n",
      "3238/3238 [==============================] - 1s 361us/step - loss: 0.1355 - val_loss: 0.1389\n",
      "Epoch 807/1000\n",
      "3238/3238 [==============================] - 1s 364us/step - loss: 0.1310 - val_loss: 0.1358\n",
      "Epoch 808/1000\n",
      "3238/3238 [==============================] - 1s 351us/step - loss: 0.1307 - val_loss: 0.1353\n",
      "Epoch 809/1000\n",
      "3238/3238 [==============================] - 1s 373us/step - loss: 0.1301 - val_loss: 0.1352\n",
      "Epoch 810/1000\n",
      "3238/3238 [==============================] - 1s 399us/step - loss: 0.1306 - val_loss: 0.1365\n",
      "Epoch 811/1000\n",
      "3238/3238 [==============================] - 1s 379us/step - loss: 0.1305 - val_loss: 0.1356\n",
      "Epoch 812/1000\n",
      "3238/3238 [==============================] - 1s 366us/step - loss: 0.1326 - val_loss: 0.1361\n",
      "Epoch 813/1000\n",
      "3238/3238 [==============================] - 1s 378us/step - loss: 0.1325 - val_loss: 0.1381\n",
      "Epoch 814/1000\n",
      "3238/3238 [==============================] - 1s 363us/step - loss: 0.1338 - val_loss: 0.1392\n",
      "Epoch 815/1000\n",
      "3238/3238 [==============================] - 1s 422us/step - loss: 0.1359 - val_loss: 0.1440\n",
      "Epoch 816/1000\n",
      "3238/3238 [==============================] - 1s 367us/step - loss: 0.1379 - val_loss: 0.1374\n",
      "Epoch 817/1000\n",
      "3238/3238 [==============================] - 2s 479us/step - loss: 0.1315 - val_loss: 0.1364\n",
      "Epoch 818/1000\n",
      "3238/3238 [==============================] - 2s 557us/step - loss: 0.1310 - val_loss: 0.1398\n",
      "Epoch 819/1000\n",
      "3238/3238 [==============================] - 1s 342us/step - loss: 0.1330 - val_loss: 0.1362\n",
      "Epoch 820/1000\n",
      "3238/3238 [==============================] - 1s 344us/step - loss: 0.1301 - val_loss: 0.1376\n",
      "Epoch 821/1000\n",
      "3238/3238 [==============================] - 1s 341us/step - loss: 0.1304 - val_loss: 0.1359\n",
      "Epoch 822/1000\n",
      "3238/3238 [==============================] - 1s 342us/step - loss: 0.1309 - val_loss: 0.1378\n",
      "Epoch 823/1000\n",
      "3238/3238 [==============================] - 1s 341us/step - loss: 0.1306 - val_loss: 0.1356\n",
      "Epoch 824/1000\n",
      "3238/3238 [==============================] - 1s 341us/step - loss: 0.1306 - val_loss: 0.1371\n",
      "Epoch 825/1000\n",
      "3238/3238 [==============================] - 1s 348us/step - loss: 0.1307 - val_loss: 0.1397\n",
      "Epoch 826/1000\n",
      "3238/3238 [==============================] - 1s 352us/step - loss: 0.1321 - val_loss: 0.1406\n",
      "Epoch 827/1000\n",
      "3238/3238 [==============================] - 1s 347us/step - loss: 0.1315 - val_loss: 0.1353\n",
      "Epoch 828/1000\n",
      "3238/3238 [==============================] - 1s 341us/step - loss: 0.1305 - val_loss: 0.1357\n",
      "Epoch 829/1000\n",
      "3238/3238 [==============================] - 1s 387us/step - loss: 0.1292 - val_loss: 0.1362\n",
      "Epoch 830/1000\n",
      "3238/3238 [==============================] - 2s 475us/step - loss: 0.1299 - val_loss: 0.1359\n",
      "Epoch 831/1000\n",
      "3238/3238 [==============================] - 2s 535us/step - loss: 0.1293 - val_loss: 0.1368\n",
      "Epoch 832/1000\n",
      "3238/3238 [==============================] - 1s 424us/step - loss: 0.1294 - val_loss: 0.1361\n",
      "Epoch 833/1000\n",
      "3238/3238 [==============================] - 1s 377us/step - loss: 0.1318 - val_loss: 0.1375\n",
      "Epoch 834/1000\n",
      "3238/3238 [==============================] - 1s 355us/step - loss: 0.1301 - val_loss: 0.1373\n",
      "Epoch 835/1000\n",
      "3238/3238 [==============================] - 1s 343us/step - loss: 0.1295 - val_loss: 0.1363\n",
      "Epoch 836/1000\n",
      "3238/3238 [==============================] - 1s 344us/step - loss: 0.1304 - val_loss: 0.1388\n",
      "Epoch 837/1000\n",
      "3238/3238 [==============================] - 1s 342us/step - loss: 0.1304 - val_loss: 0.1360\n",
      "Epoch 838/1000\n",
      "3238/3238 [==============================] - 1s 385us/step - loss: 0.1302 - val_loss: 0.1407\n",
      "Epoch 839/1000\n",
      "3238/3238 [==============================] - 1s 431us/step - loss: 0.1307 - val_loss: 0.1363\n",
      "Epoch 840/1000\n",
      "3238/3238 [==============================] - 1s 437us/step - loss: 0.1294 - val_loss: 0.1355\n",
      "Epoch 841/1000\n",
      "3238/3238 [==============================] - 1s 348us/step - loss: 0.1290 - val_loss: 0.1371\n",
      "Epoch 842/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3238/3238 [==============================] - 1s 348us/step - loss: 0.1303 - val_loss: 0.1359\n",
      "Epoch 843/1000\n",
      "3238/3238 [==============================] - 1s 360us/step - loss: 0.1295 - val_loss: 0.1357\n",
      "Epoch 844/1000\n",
      "3238/3238 [==============================] - 1s 378us/step - loss: 0.1315 - val_loss: 0.1407\n",
      "Epoch 845/1000\n",
      "3238/3238 [==============================] - 1s 395us/step - loss: 0.1329 - val_loss: 0.1434\n",
      "Epoch 846/1000\n",
      "3238/3238 [==============================] - 1s 463us/step - loss: 0.1365 - val_loss: 0.1434\n",
      "Epoch 847/1000\n",
      "3238/3238 [==============================] - 1s 381us/step - loss: 0.1331 - val_loss: 0.1363\n",
      "Epoch 848/1000\n",
      "3238/3238 [==============================] - 1s 357us/step - loss: 0.1312 - val_loss: 0.1361\n",
      "Epoch 849/1000\n",
      "3238/3238 [==============================] - 1s 357us/step - loss: 0.1314 - val_loss: 0.1356\n",
      "Epoch 850/1000\n",
      "3238/3238 [==============================] - 1s 366us/step - loss: 0.1310 - val_loss: 0.1407\n",
      "Epoch 851/1000\n",
      "3238/3238 [==============================] - 1s 352us/step - loss: 0.1341 - val_loss: 0.1433\n",
      "Epoch 852/1000\n",
      "3238/3238 [==============================] - 1s 378us/step - loss: 0.1323 - val_loss: 0.1356\n",
      "Epoch 853/1000\n",
      "3238/3238 [==============================] - 1s 375us/step - loss: 0.1300 - val_loss: 0.1401\n",
      "Epoch 854/1000\n",
      "3238/3238 [==============================] - 1s 364us/step - loss: 0.1318 - val_loss: 0.1429\n",
      "Epoch 855/1000\n",
      "3238/3238 [==============================] - 1s 358us/step - loss: 0.1323 - val_loss: 0.1354\n",
      "Epoch 856/1000\n",
      "3238/3238 [==============================] - 1s 419us/step - loss: 0.1304 - val_loss: 0.1398\n",
      "Epoch 857/1000\n",
      "3238/3238 [==============================] - 1s 353us/step - loss: 0.1299 - val_loss: 0.1362\n",
      "Epoch 858/1000\n",
      "3238/3238 [==============================] - 1s 371us/step - loss: 0.1304 - val_loss: 0.1394\n",
      "Epoch 859/1000\n",
      "3238/3238 [==============================] - 1s 366us/step - loss: 0.1323 - val_loss: 0.1379\n",
      "Epoch 860/1000\n",
      "3238/3238 [==============================] - 1s 376us/step - loss: 0.1320 - val_loss: 0.1374\n",
      "Epoch 861/1000\n",
      "3238/3238 [==============================] - 1s 362us/step - loss: 0.1307 - val_loss: 0.1361\n",
      "Epoch 862/1000\n",
      "3238/3238 [==============================] - 1s 369us/step - loss: 0.1295 - val_loss: 0.1506\n",
      "Epoch 863/1000\n",
      "3238/3238 [==============================] - 1s 358us/step - loss: 0.1353 - val_loss: 0.1370\n",
      "Epoch 864/1000\n",
      "3238/3238 [==============================] - 1s 393us/step - loss: 0.1337 - val_loss: 0.1433\n",
      "Epoch 865/1000\n",
      "3238/3238 [==============================] - 1s 372us/step - loss: 0.1320 - val_loss: 0.1369\n",
      "Epoch 866/1000\n",
      "3238/3238 [==============================] - 1s 366us/step - loss: 0.1293 - val_loss: 0.1353\n",
      "Epoch 867/1000\n",
      "3238/3238 [==============================] - 1s 375us/step - loss: 0.1285 - val_loss: 0.1353\n",
      "Epoch 868/1000\n",
      "3238/3238 [==============================] - 1s 408us/step - loss: 0.1286 - val_loss: 0.1364\n",
      "Epoch 869/1000\n",
      "3238/3238 [==============================] - 1s 366us/step - loss: 0.1294 - val_loss: 0.1354\n",
      "Epoch 870/1000\n",
      "3238/3238 [==============================] - 1s 441us/step - loss: 0.1281 - val_loss: 0.1353\n",
      "Epoch 871/1000\n",
      "3238/3238 [==============================] - 2s 563us/step - loss: 0.1283 - val_loss: 0.1367\n",
      "Epoch 872/1000\n",
      "3238/3238 [==============================] - 2s 623us/step - loss: 0.1286 - val_loss: 0.1353\n",
      "Epoch 873/1000\n",
      "3238/3238 [==============================] - 1s 360us/step - loss: 0.1286 - val_loss: 0.1391\n",
      "Epoch 874/1000\n",
      "3238/3238 [==============================] - 1s 348us/step - loss: 0.1295 - val_loss: 0.1357\n",
      "Epoch 875/1000\n",
      "3238/3238 [==============================] - 1s 353us/step - loss: 0.1300 - val_loss: 0.1394\n",
      "Epoch 876/1000\n",
      "3238/3238 [==============================] - 1s 377us/step - loss: 0.1305 - val_loss: 0.1391\n",
      "Epoch 877/1000\n",
      "3238/3238 [==============================] - 1s 375us/step - loss: 0.1318 - val_loss: 0.1359\n",
      "Epoch 878/1000\n",
      "3238/3238 [==============================] - 1s 360us/step - loss: 0.1293 - val_loss: 0.1427\n",
      "Epoch 879/1000\n",
      "3238/3238 [==============================] - 1s 385us/step - loss: 0.1318 - val_loss: 0.1382\n",
      "Epoch 880/1000\n",
      "3238/3238 [==============================] - 1s 384us/step - loss: 0.1310 - val_loss: 0.1387\n",
      "Epoch 881/1000\n",
      "3238/3238 [==============================] - 1s 381us/step - loss: 0.1314 - val_loss: 0.1367\n",
      "Epoch 882/1000\n",
      "3238/3238 [==============================] - 1s 361us/step - loss: 0.1292 - val_loss: 0.1404\n",
      "Epoch 883/1000\n",
      "3238/3238 [==============================] - 1s 369us/step - loss: 0.1308 - val_loss: 0.1361\n",
      "Epoch 884/1000\n",
      "3238/3238 [==============================] - 1s 443us/step - loss: 0.1299 - val_loss: 0.1390\n",
      "Epoch 885/1000\n",
      "3238/3238 [==============================] - 1s 382us/step - loss: 0.1288 - val_loss: 0.1367\n",
      "Epoch 886/1000\n",
      "3238/3238 [==============================] - 1s 419us/step - loss: 0.1279 - val_loss: 0.1371\n",
      "Epoch 887/1000\n",
      "3238/3238 [==============================] - 1s 370us/step - loss: 0.1277 - val_loss: 0.1357\n",
      "Epoch 888/1000\n",
      "3238/3238 [==============================] - 1s 373us/step - loss: 0.1278 - val_loss: 0.1365\n",
      "Epoch 889/1000\n",
      "3238/3238 [==============================] - 1s 367us/step - loss: 0.1282 - val_loss: 0.1360\n",
      "Epoch 890/1000\n",
      "3238/3238 [==============================] - 1s 353us/step - loss: 0.1292 - val_loss: 0.1366\n",
      "Epoch 891/1000\n",
      "3238/3238 [==============================] - 1s 352us/step - loss: 0.1295 - val_loss: 0.1380\n",
      "Epoch 892/1000\n",
      "3238/3238 [==============================] - 1s 351us/step - loss: 0.1283 - val_loss: 0.1362\n",
      "Epoch 893/1000\n",
      "3238/3238 [==============================] - 1s 354us/step - loss: 0.1273 - val_loss: 0.1359\n",
      "Epoch 894/1000\n",
      "3238/3238 [==============================] - 1s 374us/step - loss: 0.1285 - val_loss: 0.1401\n",
      "Epoch 895/1000\n",
      "3238/3238 [==============================] - 1s 363us/step - loss: 0.1290 - val_loss: 0.1359\n",
      "Epoch 896/1000\n",
      "3238/3238 [==============================] - 1s 367us/step - loss: 0.1300 - val_loss: 0.1360\n",
      "Epoch 897/1000\n",
      "3238/3238 [==============================] - 1s 361us/step - loss: 0.1283 - val_loss: 0.1358\n",
      "Epoch 898/1000\n",
      "3238/3238 [==============================] - 1s 376us/step - loss: 0.1274 - val_loss: 0.1362\n",
      "Epoch 899/1000\n",
      "3238/3238 [==============================] - 1s 384us/step - loss: 0.1277 - val_loss: 0.1353\n",
      "Epoch 900/1000\n",
      "3238/3238 [==============================] - 1s 382us/step - loss: 0.1292 - val_loss: 0.1384\n",
      "Epoch 901/1000\n",
      "3238/3238 [==============================] - 2s 485us/step - loss: 0.1293 - val_loss: 0.1357\n",
      "Epoch 902/1000\n",
      "3238/3238 [==============================] - 1s 374us/step - loss: 0.1283 - val_loss: 0.1377\n",
      "Epoch 903/1000\n",
      "3238/3238 [==============================] - 2s 609us/step - loss: 0.1291 - val_loss: 0.1441\n",
      "Epoch 904/1000\n",
      "3238/3238 [==============================] - 1s 430us/step - loss: 0.1313 - val_loss: 0.1360\n",
      "Epoch 905/1000\n",
      "3238/3238 [==============================] - 2s 524us/step - loss: 0.1280 - val_loss: 0.1356\n",
      "Epoch 906/1000\n",
      "3238/3238 [==============================] - 1s 386us/step - loss: 0.1284 - val_loss: 0.1417\n",
      "Epoch 907/1000\n",
      "3238/3238 [==============================] - 1s 356us/step - loss: 0.1302 - val_loss: 0.1352\n",
      "Epoch 908/1000\n",
      "3238/3238 [==============================] - 1s 352us/step - loss: 0.1323 - val_loss: 0.1357\n",
      "Epoch 909/1000\n",
      "3238/3238 [==============================] - 1s 348us/step - loss: 0.1296 - val_loss: 0.1394\n",
      "Epoch 910/1000\n",
      "3238/3238 [==============================] - 1s 392us/step - loss: 0.1285 - val_loss: 0.1353\n",
      "Epoch 911/1000\n",
      "3238/3238 [==============================] - 1s 364us/step - loss: 0.1266 - val_loss: 0.1358\n",
      "Epoch 912/1000\n",
      "3238/3238 [==============================] - 1s 353us/step - loss: 0.1269 - val_loss: 0.1410\n",
      "Epoch 913/1000\n",
      "3238/3238 [==============================] - 1s 353us/step - loss: 0.1316 - val_loss: 0.1418\n",
      "Epoch 914/1000\n",
      "3238/3238 [==============================] - 1s 356us/step - loss: 0.1315 - val_loss: 0.1358\n",
      "Epoch 915/1000\n",
      "3238/3238 [==============================] - 2s 557us/step - loss: 0.1276 - val_loss: 0.1355\n",
      "Epoch 916/1000\n",
      "3238/3238 [==============================] - 2s 624us/step - loss: 0.1277 - val_loss: 0.1363\n",
      "Epoch 917/1000\n",
      "3238/3238 [==============================] - 2s 532us/step - loss: 0.1294 - val_loss: 0.1365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 918/1000\n",
      "3238/3238 [==============================] - 2s 518us/step - loss: 0.1274 - val_loss: 0.1365\n",
      "Epoch 919/1000\n",
      "3238/3238 [==============================] - 1s 406us/step - loss: 0.1270 - val_loss: 0.1358\n",
      "Epoch 920/1000\n",
      "3238/3238 [==============================] - 2s 590us/step - loss: 0.1277 - val_loss: 0.1363\n",
      "Epoch 921/1000\n",
      "3238/3238 [==============================] - 2s 531us/step - loss: 0.1270 - val_loss: 0.1363\n",
      "Epoch 922/1000\n",
      "3238/3238 [==============================] - 2s 669us/step - loss: 0.1284 - val_loss: 0.1378\n",
      "Epoch 923/1000\n",
      "3238/3238 [==============================] - 2s 643us/step - loss: 0.1293 - val_loss: 0.1352\n",
      "Epoch 924/1000\n",
      "3238/3238 [==============================] - 1s 361us/step - loss: 0.1292 - val_loss: 0.1400\n",
      "Epoch 925/1000\n",
      "3238/3238 [==============================] - 1s 358us/step - loss: 0.1290 - val_loss: 0.1364\n",
      "Epoch 926/1000\n",
      "3238/3238 [==============================] - 1s 356us/step - loss: 0.1303 - val_loss: 0.1394\n",
      "Epoch 927/1000\n",
      "3238/3238 [==============================] - 1s 363us/step - loss: 0.1332 - val_loss: 0.1369\n",
      "Epoch 928/1000\n",
      "3238/3238 [==============================] - 1s 364us/step - loss: 0.1302 - val_loss: 0.1371\n",
      "Epoch 929/1000\n",
      "3238/3238 [==============================] - 2s 552us/step - loss: 0.1265 - val_loss: 0.1354\n",
      "Epoch 930/1000\n",
      "3238/3238 [==============================] - 1s 366us/step - loss: 0.1276 - val_loss: 0.1354\n",
      "Epoch 931/1000\n",
      "3238/3238 [==============================] - 1s 369us/step - loss: 0.1281 - val_loss: 0.1356\n",
      "Epoch 932/1000\n",
      "3238/3238 [==============================] - 1s 360us/step - loss: 0.1274 - val_loss: 0.1356\n",
      "Epoch 933/1000\n",
      "3238/3238 [==============================] - 1s 415us/step - loss: 0.1272 - val_loss: 0.1365\n",
      "Epoch 934/1000\n",
      "3238/3238 [==============================] - 2s 475us/step - loss: 0.1266 - val_loss: 0.1369\n",
      "Epoch 935/1000\n",
      "3238/3238 [==============================] - 2s 542us/step - loss: 0.1297 - val_loss: 0.1383\n",
      "Epoch 936/1000\n",
      "3238/3238 [==============================] - 1s 339us/step - loss: 0.1306 - val_loss: 0.1375\n",
      "Epoch 937/1000\n",
      "3238/3238 [==============================] - 1s 353us/step - loss: 0.1276 - val_loss: 0.1357\n",
      "Epoch 938/1000\n",
      "3238/3238 [==============================] - 1s 342us/step - loss: 0.1284 - val_loss: 0.1357\n",
      "Epoch 939/1000\n",
      "3238/3238 [==============================] - 1s 378us/step - loss: 0.1269 - val_loss: 0.1360\n",
      "Epoch 940/1000\n",
      "3238/3238 [==============================] - 1s 344us/step - loss: 0.1265 - val_loss: 0.1362\n",
      "Epoch 941/1000\n",
      "3238/3238 [==============================] - 1s 342us/step - loss: 0.1268 - val_loss: 0.1401\n",
      "Epoch 942/1000\n",
      "3238/3238 [==============================] - 1s 341us/step - loss: 0.1294 - val_loss: 0.1353\n",
      "Epoch 943/1000\n",
      "3238/3238 [==============================] - 1s 344us/step - loss: 0.1273 - val_loss: 0.1367\n",
      "Epoch 944/1000\n",
      "3238/3238 [==============================] - 1s 341us/step - loss: 0.1266 - val_loss: 0.1349\n",
      "Epoch 945/1000\n",
      "3238/3238 [==============================] - 1s 341us/step - loss: 0.1325 - val_loss: 0.1373\n",
      "Epoch 946/1000\n",
      "3238/3238 [==============================] - 1s 344us/step - loss: 0.1305 - val_loss: 0.1404\n",
      "Epoch 947/1000\n",
      "3238/3238 [==============================] - 1s 370us/step - loss: 0.1285 - val_loss: 0.1368\n",
      "Epoch 948/1000\n",
      "3238/3238 [==============================] - 2s 552us/step - loss: 0.1266 - val_loss: 0.1353\n",
      "Epoch 949/1000\n",
      "3238/3238 [==============================] - 2s 587us/step - loss: 0.1272 - val_loss: 0.1356\n",
      "Epoch 950/1000\n",
      "3238/3238 [==============================] - 2s 480us/step - loss: 0.1263 - val_loss: 0.1364\n",
      "Epoch 951/1000\n",
      "3238/3238 [==============================] - 2s 656us/step - loss: 0.1275 - val_loss: 0.1364\n",
      "Epoch 952/1000\n",
      "3238/3238 [==============================] - 2s 665us/step - loss: 0.1263 - val_loss: 0.1358\n",
      "Epoch 953/1000\n",
      "3238/3238 [==============================] - 1s 364us/step - loss: 0.1263 - val_loss: 0.1352\n",
      "Epoch 954/1000\n",
      "3238/3238 [==============================] - 1s 363us/step - loss: 0.1274 - val_loss: 0.1372\n",
      "Epoch 955/1000\n",
      "3238/3238 [==============================] - 1s 366us/step - loss: 0.1276 - val_loss: 0.1387\n",
      "Epoch 956/1000\n",
      "3238/3238 [==============================] - 1s 363us/step - loss: 0.1282 - val_loss: 0.1368\n",
      "Epoch 957/1000\n",
      "3238/3238 [==============================] - 1s 398us/step - loss: 0.1268 - val_loss: 0.1357\n",
      "Epoch 958/1000\n",
      "3238/3238 [==============================] - 1s 369us/step - loss: 0.1260 - val_loss: 0.1384\n",
      "Epoch 959/1000\n",
      "3238/3238 [==============================] - 2s 618us/step - loss: 0.1278 - val_loss: 0.1354\n",
      "Epoch 960/1000\n",
      "3238/3238 [==============================] - 2s 545us/step - loss: 0.1264 - val_loss: 0.1378\n",
      "Epoch 961/1000\n",
      "3238/3238 [==============================] - 2s 686us/step - loss: 0.1290 - val_loss: 0.1389\n",
      "Epoch 962/1000\n",
      "3238/3238 [==============================] - 1s 414us/step - loss: 0.1284 - val_loss: 0.1395\n",
      "Epoch 963/1000\n",
      "3238/3238 [==============================] - 1s 366us/step - loss: 0.1283 - val_loss: 0.1424\n",
      "Epoch 964/1000\n",
      "3238/3238 [==============================] - 1s 358us/step - loss: 0.1282 - val_loss: 0.1352\n",
      "Epoch 965/1000\n",
      "3238/3238 [==============================] - 1s 401us/step - loss: 0.1267 - val_loss: 0.1367\n",
      "Epoch 966/1000\n",
      "3238/3238 [==============================] - 2s 580us/step - loss: 0.1279 - val_loss: 0.1345\n",
      "Epoch 967/1000\n",
      "3238/3238 [==============================] - 2s 565us/step - loss: 0.1261 - val_loss: 0.1376\n",
      "Epoch 968/1000\n",
      "3238/3238 [==============================] - 1s 376us/step - loss: 0.1257 - val_loss: 0.1353\n",
      "Epoch 969/1000\n",
      "3238/3238 [==============================] - 2s 475us/step - loss: 0.1259 - val_loss: 0.1395\n",
      "Epoch 970/1000\n",
      "3238/3238 [==============================] - 2s 484us/step - loss: 0.1276 - val_loss: 0.1361\n",
      "Epoch 971/1000\n",
      "3238/3238 [==============================] - 2s 527us/step - loss: 0.1273 - val_loss: 0.1376\n",
      "Epoch 972/1000\n",
      "3238/3238 [==============================] - 1s 456us/step - loss: 0.1283 - val_loss: 0.1397\n",
      "Epoch 973/1000\n",
      "3238/3238 [==============================] - 1s 461us/step - loss: 0.1312 - val_loss: 0.1369\n",
      "Epoch 974/1000\n",
      "3238/3238 [==============================] - 1s 460us/step - loss: 0.1271 - val_loss: 0.1360\n",
      "Epoch 975/1000\n",
      "3238/3238 [==============================] - 1s 456us/step - loss: 0.1269 - val_loss: 0.1395\n",
      "Epoch 976/1000\n",
      "3238/3238 [==============================] - 2s 508us/step - loss: 0.1274 - val_loss: 0.1359\n",
      "Epoch 977/1000\n",
      "3238/3238 [==============================] - 2s 671us/step - loss: 0.1262 - val_loss: 0.1364\n",
      "Epoch 978/1000\n",
      "3238/3238 [==============================] - 2s 674us/step - loss: 0.1258 - val_loss: 0.1368\n",
      "Epoch 979/1000\n",
      "3238/3238 [==============================] - 2s 560us/step - loss: 0.1270 - val_loss: 0.1361\n",
      "Epoch 980/1000\n",
      "3238/3238 [==============================] - 1s 453us/step - loss: 0.1265 - val_loss: 0.1351\n",
      "Epoch 981/1000\n",
      "3238/3238 [==============================] - 2s 573us/step - loss: 0.1263 - val_loss: 0.1382\n",
      "Epoch 982/1000\n",
      "3238/3238 [==============================] - 2s 666us/step - loss: 0.1287 - val_loss: 0.1357\n",
      "Epoch 983/1000\n",
      "3238/3238 [==============================] - 2s 652us/step - loss: 0.1268 - val_loss: 0.1370\n",
      "Epoch 984/1000\n",
      "3238/3238 [==============================] - 2s 677us/step - loss: 0.1270 - val_loss: 0.1394\n",
      "Epoch 985/1000\n",
      "3238/3238 [==============================] - 2s 661us/step - loss: 0.1288 - val_loss: 0.1359\n",
      "Epoch 986/1000\n",
      "3238/3238 [==============================] - 2s 658us/step - loss: 0.1264 - val_loss: 0.1359\n",
      "Epoch 987/1000\n",
      "3238/3238 [==============================] - 2s 748us/step - loss: 0.1296 - val_loss: 0.1368\n",
      "Epoch 988/1000\n",
      "3238/3238 [==============================] - 3s 1ms/step - loss: 0.1308 - val_loss: 0.1349\n",
      "Epoch 989/1000\n",
      "3238/3238 [==============================] - 4s 1ms/step - loss: 0.1292 - val_loss: 0.1356\n",
      "Epoch 990/1000\n",
      "3238/3238 [==============================] - 4s 1ms/step - loss: 0.1278 - val_loss: 0.1375\n",
      "Epoch 991/1000\n",
      "3238/3238 [==============================] - 5s 1ms/step - loss: 0.1263 - val_loss: 0.1350\n",
      "Epoch 992/1000\n",
      "3238/3238 [==============================] - 5s 1ms/step - loss: 0.1259 - val_loss: 0.1379\n",
      "Epoch 993/1000\n",
      "3238/3238 [==============================] - 2s 728us/step - loss: 0.1288 - val_loss: 0.1489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 994/1000\n",
      "3238/3238 [==============================] - 2s 728us/step - loss: 0.1342 - val_loss: 0.1358\n",
      "Epoch 995/1000\n",
      "3238/3238 [==============================] - 2s 694us/step - loss: 0.1291 - val_loss: 0.1366\n",
      "Epoch 996/1000\n",
      "3238/3238 [==============================] - 2s 689us/step - loss: 0.1316 - val_loss: 0.1407\n",
      "Epoch 997/1000\n",
      "3238/3238 [==============================] - 2s 678us/step - loss: 0.1295 - val_loss: 0.1352\n",
      "Epoch 998/1000\n",
      "3238/3238 [==============================] - 2s 711us/step - loss: 0.1277 - val_loss: 0.1362\n",
      "Epoch 999/1000\n",
      "3238/3238 [==============================] - 2s 688us/step - loss: 0.1268 - val_loss: 0.1433\n",
      "Epoch 1000/1000\n",
      "3238/3238 [==============================] - 2s 691us/step - loss: 0.1311 - val_loss: 0.1354\n",
      "adam_lr - 0.003 initializer - he_uniform\n",
      "Train on 3238 samples, validate on 360 samples\n",
      "Epoch 1/1000\n",
      "3238/3238 [==============================] - 5s 2ms/step - loss: 0.1545 - val_loss: 0.1516\n",
      "Epoch 2/1000\n",
      "3238/3238 [==============================] - 2s 703us/step - loss: 0.1545 - val_loss: 0.1516\n",
      "Epoch 3/1000\n",
      "3238/3238 [==============================] - 2s 685us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 4/1000\n",
      "3238/3238 [==============================] - 2s 703us/step - loss: 0.1547 - val_loss: 0.1517\n",
      "Epoch 5/1000\n",
      "3238/3238 [==============================] - 2s 703us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 6/1000\n",
      "3238/3238 [==============================] - 2s 728us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 7/1000\n",
      "3238/3238 [==============================] - 2s 713us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 8/1000\n",
      "3238/3238 [==============================] - 2s 711us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 9/1000\n",
      "3238/3238 [==============================] - 2s 699us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 10/1000\n",
      "3238/3238 [==============================] - 2s 703us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 11/1000\n",
      "3238/3238 [==============================] - 2s 699us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 12/1000\n",
      "3238/3238 [==============================] - 2s 720us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 13/1000\n",
      "3238/3238 [==============================] - 2s 716us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 14/1000\n",
      "3238/3238 [==============================] - 2s 694us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 15/1000\n",
      "3238/3238 [==============================] - 2s 709us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 16/1000\n",
      "3238/3238 [==============================] - 2s 705us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 17/1000\n",
      "3238/3238 [==============================] - 2s 699us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 18/1000\n",
      "3238/3238 [==============================] - 2s 705us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 19/1000\n",
      "3238/3238 [==============================] - 2s 688us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 20/1000\n",
      "3238/3238 [==============================] - 2s 706us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 21/1000\n",
      "3238/3238 [==============================] - 2s 717us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 22/1000\n",
      "3238/3238 [==============================] - 2s 693us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 23/1000\n",
      "3238/3238 [==============================] - 2s 720us/step - loss: 0.1544 - val_loss: 0.1518\n",
      "Epoch 24/1000\n",
      "3238/3238 [==============================] - 2s 701us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 25/1000\n",
      "3238/3238 [==============================] - 2s 699us/step - loss: 0.1545 - val_loss: 0.1517\n",
      "Epoch 26/1000\n",
      "3238/3238 [==============================] - 2s 716us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 27/1000\n",
      "3238/3238 [==============================] - 2s 698us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 28/1000\n",
      "3238/3238 [==============================] - 2s 725us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 29/1000\n",
      "3238/3238 [==============================] - 2s 712us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 30/1000\n",
      "3238/3238 [==============================] - 2s 703us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 31/1000\n",
      "3238/3238 [==============================] - 2s 701us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 32/1000\n",
      "3238/3238 [==============================] - 4s 1ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 33/1000\n",
      "3238/3238 [==============================] - 3s 1ms/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 34/1000\n",
      "3238/3238 [==============================] - 3s 1ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 35/1000\n",
      "3238/3238 [==============================] - 2s 697us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 36/1000\n",
      "3238/3238 [==============================] - 2s 769us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 37/1000\n",
      "3238/3238 [==============================] - 3s 930us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 38/1000\n",
      "3238/3238 [==============================] - 2s 669us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 39/1000\n",
      "3238/3238 [==============================] - 2s 668us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 40/1000\n",
      "3238/3238 [==============================] - 2s 656us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 41/1000\n",
      "3238/3238 [==============================] - 2s 671us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 42/1000\n",
      "3238/3238 [==============================] - 3s 775us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 43/1000\n",
      "3238/3238 [==============================] - 3s 793us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 44/1000\n",
      "3238/3238 [==============================] - 2s 659us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 45/1000\n",
      "3238/3238 [==============================] - 2s 660us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 46/1000\n",
      "3238/3238 [==============================] - 2s 662us/step - loss: 0.1545 - val_loss: 0.1517\n",
      "Epoch 47/1000\n",
      "3238/3238 [==============================] - 2s 680us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 48/1000\n",
      "3238/3238 [==============================] - 2s 657us/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 49/1000\n",
      "3238/3238 [==============================] - 2s 671us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 50/1000\n",
      "3238/3238 [==============================] - 2s 664us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 51/1000\n",
      "3238/3238 [==============================] - 2s 663us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 52/1000\n",
      "3238/3238 [==============================] - 2s 673us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 53/1000\n",
      "3238/3238 [==============================] - 2s 668us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 54/1000\n",
      "3238/3238 [==============================] - 2s 686us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 55/1000\n",
      "3238/3238 [==============================] - 2s 663us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 56/1000\n",
      "3238/3238 [==============================] - 2s 657us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 57/1000\n",
      "3238/3238 [==============================] - 2s 669us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 58/1000\n",
      "3238/3238 [==============================] - 2s 663us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 59/1000\n",
      "3238/3238 [==============================] - 2s 689us/step - loss: 0.1545 - val_loss: 0.1517\n",
      "Epoch 60/1000\n",
      "3238/3238 [==============================] - 2s 667us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 61/1000\n",
      "3238/3238 [==============================] - 2s 670us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 62/1000\n",
      "3238/3238 [==============================] - 3s 785us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 63/1000\n",
      "3238/3238 [==============================] - 3s 866us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 64/1000\n",
      "3238/3238 [==============================] - 2s 685us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 65/1000\n",
      "3238/3238 [==============================] - 3s 823us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 66/1000\n",
      "3238/3238 [==============================] - 2s 683us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 67/1000\n",
      "3238/3238 [==============================] - 2s 732us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 68/1000\n",
      "3238/3238 [==============================] - 3s 853us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 69/1000\n",
      "3238/3238 [==============================] - 3s 827us/step - loss: 0.1545 - val_loss: 0.1517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/1000\n",
      "3238/3238 [==============================] - 3s 814us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 71/1000\n",
      "3238/3238 [==============================] - 2s 769us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 72/1000\n",
      "3238/3238 [==============================] - 2s 679us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 73/1000\n",
      "3238/3238 [==============================] - 2s 674us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 74/1000\n",
      "3238/3238 [==============================] - 2s 724us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 75/1000\n",
      "3238/3238 [==============================] - 2s 734us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 76/1000\n",
      "3238/3238 [==============================] - 2s 707us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 77/1000\n",
      "3238/3238 [==============================] - 2s 683us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 78/1000\n",
      "3238/3238 [==============================] - 3s 775us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 79/1000\n",
      "3238/3238 [==============================] - 3s 843us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 80/1000\n",
      "3238/3238 [==============================] - 2s 679us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 81/1000\n",
      "3238/3238 [==============================] - 3s 774us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 82/1000\n",
      "3238/3238 [==============================] - 4s 1ms/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 83/1000\n",
      "3238/3238 [==============================] - 2s 694us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 84/1000\n",
      "3238/3238 [==============================] - 2s 694us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 85/1000\n",
      "3238/3238 [==============================] - 2s 723us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 86/1000\n",
      "3238/3238 [==============================] - 2s 696us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 87/1000\n",
      "3238/3238 [==============================] - 2s 713us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 88/1000\n",
      "3238/3238 [==============================] - 2s 697us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 89/1000\n",
      "3238/3238 [==============================] - 2s 711us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 90/1000\n",
      "3238/3238 [==============================] - 2s 711us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 91/1000\n",
      "3238/3238 [==============================] - 2s 697us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 92/1000\n",
      "3238/3238 [==============================] - 2s 711us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 93/1000\n",
      "3238/3238 [==============================] - 2s 712us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 94/1000\n",
      "3238/3238 [==============================] - 2s 688us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 95/1000\n",
      "3238/3238 [==============================] - 2s 716us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 96/1000\n",
      "3238/3238 [==============================] - 2s 699us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 97/1000\n",
      "3238/3238 [==============================] - 2s 701us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 98/1000\n",
      "3238/3238 [==============================] - 2s 708us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 99/1000\n",
      "3238/3238 [==============================] - 2s 686us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 100/1000\n",
      "3238/3238 [==============================] - 2s 724us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 101/1000\n",
      "3238/3238 [==============================] - 2s 714us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 102/1000\n",
      "3238/3238 [==============================] - 2s 695us/step - loss: 0.1545 - val_loss: 0.1517\n",
      "Epoch 103/1000\n",
      "3238/3238 [==============================] - 2s 709us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 104/1000\n",
      "3238/3238 [==============================] - 2s 707us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 105/1000\n",
      "3238/3238 [==============================] - 2s 699us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 106/1000\n",
      "3238/3238 [==============================] - 2s 717us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 107/1000\n",
      "3238/3238 [==============================] - 2s 699us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 108/1000\n",
      "3238/3238 [==============================] - 2s 717us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 109/1000\n",
      "3238/3238 [==============================] - 2s 706us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 110/1000\n",
      "3238/3238 [==============================] - 2s 704us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 111/1000\n",
      "3238/3238 [==============================] - 2s 720us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 112/1000\n",
      "3238/3238 [==============================] - 2s 689us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 113/1000\n",
      "3238/3238 [==============================] - 2s 728us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 114/1000\n",
      "3238/3238 [==============================] - 2s 716us/step - loss: 0.1545 - val_loss: 0.1518\n",
      "Epoch 115/1000\n",
      "3238/3238 [==============================] - 2s 703us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 116/1000\n",
      "3238/3238 [==============================] - 2s 716us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 117/1000\n",
      "3238/3238 [==============================] - 2s 703us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 118/1000\n",
      "3238/3238 [==============================] - 2s 709us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 119/1000\n",
      "3238/3238 [==============================] - 2s 756us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 120/1000\n",
      "3238/3238 [==============================] - 2s 704us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 121/1000\n",
      "3238/3238 [==============================] - 2s 725us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 122/1000\n",
      "3238/3238 [==============================] - 2s 724us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 123/1000\n",
      "3238/3238 [==============================] - 2s 708us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 124/1000\n",
      "3238/3238 [==============================] - 2s 716us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 125/1000\n",
      "3238/3238 [==============================] - 2s 711us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 126/1000\n",
      "3238/3238 [==============================] - 2s 714us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 127/1000\n",
      "3238/3238 [==============================] - 2s 734us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 128/1000\n",
      "3238/3238 [==============================] - 2s 708us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 129/1000\n",
      "3238/3238 [==============================] - 2s 716us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 130/1000\n",
      "3238/3238 [==============================] - 2s 713us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 131/1000\n",
      "3238/3238 [==============================] - 2s 704us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 132/1000\n",
      "3238/3238 [==============================] - 2s 717us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 133/1000\n",
      "3238/3238 [==============================] - 2s 708us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 134/1000\n",
      "3238/3238 [==============================] - 2s 757us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 135/1000\n",
      "3238/3238 [==============================] - 2s 723us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 136/1000\n",
      "3238/3238 [==============================] - 2s 704us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 137/1000\n",
      "3238/3238 [==============================] - 2s 728us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 138/1000\n",
      "3238/3238 [==============================] - 2s 725us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 139/1000\n",
      "3238/3238 [==============================] - 2s 714us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 140/1000\n",
      "3238/3238 [==============================] - 2s 722us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 141/1000\n",
      "3238/3238 [==============================] - 2s 716us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 142/1000\n",
      "3238/3238 [==============================] - 2s 721us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 143/1000\n",
      "3238/3238 [==============================] - 2s 716us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 144/1000\n",
      "3238/3238 [==============================] - 2s 705us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 145/1000\n",
      "3238/3238 [==============================] - 2s 716us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3238/3238 [==============================] - 2s 694us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 147/1000\n",
      "3238/3238 [==============================] - 2s 672us/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 148/1000\n",
      "3238/3238 [==============================] - 2s 681us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 149/1000\n",
      "3238/3238 [==============================] - 2s 671us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 150/1000\n",
      "3238/3238 [==============================] - 2s 678us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 151/1000\n",
      "3238/3238 [==============================] - 2s 681us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 152/1000\n",
      "3238/3238 [==============================] - 2s 655us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 153/1000\n",
      "3238/3238 [==============================] - 2s 681us/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 154/1000\n",
      "3238/3238 [==============================] - 2s 669us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 155/1000\n",
      "3238/3238 [==============================] - 2s 677us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 156/1000\n",
      "3238/3238 [==============================] - 2s 678us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 157/1000\n",
      "3238/3238 [==============================] - 2s 665us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 158/1000\n",
      "3238/3238 [==============================] - 2s 678us/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 159/1000\n",
      "3238/3238 [==============================] - 2s 680us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 160/1000\n",
      "3238/3238 [==============================] - 2s 669us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 161/1000\n",
      "3238/3238 [==============================] - 2s 677us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 162/1000\n",
      "3238/3238 [==============================] - 2s 668us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 163/1000\n",
      "3238/3238 [==============================] - 2s 713us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 164/1000\n",
      "3238/3238 [==============================] - 2s 687us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 165/1000\n",
      "3238/3238 [==============================] - 2s 674us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 166/1000\n",
      "3238/3238 [==============================] - 2s 696us/step - loss: 0.1545 - val_loss: 0.1517\n",
      "Epoch 167/1000\n",
      "3238/3238 [==============================] - 2s 682us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 168/1000\n",
      "3238/3238 [==============================] - 2s 661us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 169/1000\n",
      "3238/3238 [==============================] - 2s 672us/step - loss: 0.1545 - val_loss: 0.1518\n",
      "Epoch 170/1000\n",
      "3238/3238 [==============================] - 2s 669us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 171/1000\n",
      "3238/3238 [==============================] - 2s 676us/step - loss: 0.1545 - val_loss: 0.1518\n",
      "Epoch 172/1000\n",
      "3238/3238 [==============================] - 2s 730us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 173/1000\n",
      "3238/3238 [==============================] - 2s 686us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 174/1000\n",
      "3238/3238 [==============================] - 2s 689us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 175/1000\n",
      "3238/3238 [==============================] - 2s 684us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 176/1000\n",
      "3238/3238 [==============================] - 2s 679us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 177/1000\n",
      "3238/3238 [==============================] - 2s 689us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 178/1000\n",
      "3238/3238 [==============================] - 2s 677us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 179/1000\n",
      "3238/3238 [==============================] - 2s 680us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 180/1000\n",
      "3238/3238 [==============================] - 2s 689us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 181/1000\n",
      "3238/3238 [==============================] - 2s 665us/step - loss: 0.1545 - val_loss: 0.1517\n",
      "Epoch 182/1000\n",
      "3238/3238 [==============================] - 2s 686us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 183/1000\n",
      "3238/3238 [==============================] - 2s 692us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 184/1000\n",
      "3238/3238 [==============================] - 2s 668us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 185/1000\n",
      "3238/3238 [==============================] - 2s 687us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 186/1000\n",
      "3238/3238 [==============================] - 2s 671us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 187/1000\n",
      "3238/3238 [==============================] - 2s 685us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 188/1000\n",
      "3238/3238 [==============================] - 2s 724us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 189/1000\n",
      "3238/3238 [==============================] - 2s 682us/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 190/1000\n",
      "3238/3238 [==============================] - 2s 698us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 191/1000\n",
      "3238/3238 [==============================] - 3s 931us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 192/1000\n",
      "3238/3238 [==============================] - 3s 871us/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 193/1000\n",
      "3238/3238 [==============================] - 3s 913us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 194/1000\n",
      "3238/3238 [==============================] - 3s 936us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 195/1000\n",
      "3238/3238 [==============================] - 3s 960us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 196/1000\n",
      "3238/3238 [==============================] - 3s 926us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 197/1000\n",
      "3238/3238 [==============================] - 3s 913us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 198/1000\n",
      "3238/3238 [==============================] - 3s 926us/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 199/1000\n",
      "3238/3238 [==============================] - 3s 934us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 200/1000\n",
      "3238/3238 [==============================] - 3s 886us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 201/1000\n",
      "3238/3238 [==============================] - 3s 798us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 202/1000\n",
      "3238/3238 [==============================] - 3s 885us/step - loss: 0.1545 - val_loss: 0.1516\n",
      "Epoch 203/1000\n",
      "3238/3238 [==============================] - 3s 863us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 204/1000\n",
      "3238/3238 [==============================] - 3s 907us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 205/1000\n",
      "3238/3238 [==============================] - 3s 862us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 206/1000\n",
      "3238/3238 [==============================] - 3s 782us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 207/1000\n",
      "3238/3238 [==============================] - 2s 696us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 208/1000\n",
      "3238/3238 [==============================] - 2s 684us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 209/1000\n",
      "3238/3238 [==============================] - 2s 690us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 210/1000\n",
      "3238/3238 [==============================] - 2s 694us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 211/1000\n",
      "3238/3238 [==============================] - 2s 683us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 212/1000\n",
      "3238/3238 [==============================] - 2s 700us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 213/1000\n",
      "3238/3238 [==============================] - 2s 692us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 214/1000\n",
      "3238/3238 [==============================] - 2s 712us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 215/1000\n",
      "3238/3238 [==============================] - 2s 692us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 216/1000\n",
      "3238/3238 [==============================] - 2s 697us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 217/1000\n",
      "3238/3238 [==============================] - 2s 702us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 218/1000\n",
      "3238/3238 [==============================] - 2s 689us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 219/1000\n",
      "3238/3238 [==============================] - 2s 677us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 220/1000\n",
      "3238/3238 [==============================] - 2s 691us/step - loss: 0.1545 - val_loss: 0.1516\n",
      "Epoch 221/1000\n",
      "3238/3238 [==============================] - 2s 679us/step - loss: 0.1544 - val_loss: 0.1518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222/1000\n",
      "3238/3238 [==============================] - 2s 685us/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 223/1000\n",
      "3238/3238 [==============================] - 2s 685us/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 224/1000\n",
      "3238/3238 [==============================] - 2s 669us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 225/1000\n",
      "3238/3238 [==============================] - 2s 680us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 226/1000\n",
      "3238/3238 [==============================] - 2s 680us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 227/1000\n",
      "3238/3238 [==============================] - 2s 680us/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 228/1000\n",
      "3238/3238 [==============================] - 2s 681us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 229/1000\n",
      "3238/3238 [==============================] - 2s 666us/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 230/1000\n",
      "3238/3238 [==============================] - 2s 680us/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 231/1000\n",
      "3238/3238 [==============================] - 2s 677us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 232/1000\n",
      "3238/3238 [==============================] - 2s 656us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 233/1000\n",
      "3238/3238 [==============================] - 2s 691us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 234/1000\n",
      "3238/3238 [==============================] - 2s 672us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 235/1000\n",
      "3238/3238 [==============================] - 2s 678us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 236/1000\n",
      "3238/3238 [==============================] - 2s 688us/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 237/1000\n",
      "3238/3238 [==============================] - 2s 667us/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 238/1000\n",
      "3238/3238 [==============================] - 2s 690us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 239/1000\n",
      "3238/3238 [==============================] - 2s 678us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 240/1000\n",
      "3238/3238 [==============================] - 2s 668us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 241/1000\n",
      "3238/3238 [==============================] - 2s 681us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 242/1000\n",
      "3238/3238 [==============================] - 2s 661us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 243/1000\n",
      "3238/3238 [==============================] - 2s 679us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 244/1000\n",
      "3238/3238 [==============================] - 2s 694us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 245/1000\n",
      "3238/3238 [==============================] - 2s 660us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 246/1000\n",
      "3238/3238 [==============================] - 2s 690us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 247/1000\n",
      "3238/3238 [==============================] - 2s 675us/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 248/1000\n",
      "3238/3238 [==============================] - 2s 682us/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 249/1000\n",
      "3238/3238 [==============================] - 2s 682us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 250/1000\n",
      "3238/3238 [==============================] - 2s 668us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 251/1000\n",
      "3238/3238 [==============================] - 2s 683us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 252/1000\n",
      "3238/3238 [==============================] - 2s 685us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 253/1000\n",
      "3238/3238 [==============================] - 2s 675us/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 254/1000\n",
      "3238/3238 [==============================] - 2s 683us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 255/1000\n",
      "3238/3238 [==============================] - 2s 675us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 256/1000\n",
      "3238/3238 [==============================] - 2s 682us/step - loss: 0.1546 - val_loss: 0.1516\n",
      "Epoch 257/1000\n",
      "3238/3238 [==============================] - 2s 685us/step - loss: 0.1546 - val_loss: 0.1516\n",
      "Epoch 258/1000\n",
      "3238/3238 [==============================] - 2s 676us/step - loss: 0.1543 - val_loss: 0.1520\n",
      "Epoch 259/1000\n",
      "3238/3238 [==============================] - 2s 684us/step - loss: 0.1546 - val_loss: 0.1517\n",
      "Epoch 260/1000\n",
      "3238/3238 [==============================] - 2s 686us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 261/1000\n",
      "3238/3238 [==============================] - 2s 672us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 262/1000\n",
      "3238/3238 [==============================] - 2s 691us/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 263/1000\n",
      "3238/3238 [==============================] - 2s 728us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 264/1000\n",
      "3238/3238 [==============================] - 2s 693us/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 265/1000\n",
      "3238/3238 [==============================] - 2s 696us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 266/1000\n",
      "3238/3238 [==============================] - 2s 684us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 267/1000\n",
      "3238/3238 [==============================] - 2s 687us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 268/1000\n",
      "3238/3238 [==============================] - 2s 676us/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 269/1000\n",
      "3238/3238 [==============================] - 2s 690us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 270/1000\n",
      "3238/3238 [==============================] - 2s 690us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 271/1000\n",
      "3238/3238 [==============================] - 2s 677us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 272/1000\n",
      "3238/3238 [==============================] - 2s 698us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 273/1000\n",
      "3238/3238 [==============================] - 2s 688us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 274/1000\n",
      "3238/3238 [==============================] - 2s 674us/step - loss: 0.1545 - val_loss: 0.1517\n",
      "Epoch 275/1000\n",
      "3238/3238 [==============================] - 2s 688us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 276/1000\n",
      "3238/3238 [==============================] - 2s 683us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 277/1000\n",
      "3238/3238 [==============================] - 2s 675us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 278/1000\n",
      "3238/3238 [==============================] - 2s 693us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 279/1000\n",
      "3238/3238 [==============================] - 2s 675us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 280/1000\n",
      "3238/3238 [==============================] - 2s 705us/step - loss: 0.1544 - val_loss: 0.1518\n",
      "Epoch 281/1000\n",
      "3238/3238 [==============================] - 2s 691us/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 282/1000\n",
      "3238/3238 [==============================] - 2s 672us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 283/1000\n",
      "3238/3238 [==============================] - 2s 703us/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 284/1000\n",
      "3238/3238 [==============================] - 2s 680us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 285/1000\n",
      "3238/3238 [==============================] - 2s 683us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 286/1000\n",
      "3238/3238 [==============================] - 2s 693us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 287/1000\n",
      "3238/3238 [==============================] - 2s 673us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 288/1000\n",
      "3238/3238 [==============================] - 2s 687us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 289/1000\n",
      "3238/3238 [==============================] - 2s 702us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 290/1000\n",
      "3238/3238 [==============================] - 2s 675us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 291/1000\n",
      "3238/3238 [==============================] - 2s 728us/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 292/1000\n",
      "3238/3238 [==============================] - 2s 676us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 293/1000\n",
      "3238/3238 [==============================] - 2s 695us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 294/1000\n",
      "3238/3238 [==============================] - 2s 689us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 295/1000\n",
      "3238/3238 [==============================] - 2s 679us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 296/1000\n",
      "3238/3238 [==============================] - 2s 697us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 297/1000\n",
      "3238/3238 [==============================] - 2s 704us/step - loss: 0.1544 - val_loss: 0.1517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 298/1000\n",
      "3238/3238 [==============================] - 2s 673us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 299/1000\n",
      "3238/3238 [==============================] - 2s 672us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 300/1000\n",
      "3238/3238 [==============================] - 2s 655us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 301/1000\n",
      "3238/3238 [==============================] - 2s 668us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 302/1000\n",
      "3238/3238 [==============================] - 2s 681us/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 303/1000\n",
      "3238/3238 [==============================] - 2s 674us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 304/1000\n",
      "3238/3238 [==============================] - 2s 683us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 305/1000\n",
      "3238/3238 [==============================] - 2s 698us/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 306/1000\n",
      "3238/3238 [==============================] - 2s 690us/step - loss: 0.1544 - val_loss: 0.1517\n",
      "Epoch 307/1000\n",
      "3238/3238 [==============================] - 2s 678us/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 308/1000\n",
      "3238/3238 [==============================] - 2s 673us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 309/1000\n",
      "3238/3238 [==============================] - 2s 679us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 310/1000\n",
      "3238/3238 [==============================] - 2s 674us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 311/1000\n",
      "3238/3238 [==============================] - 2s 671us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 312/1000\n",
      "3238/3238 [==============================] - 2s 676us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 313/1000\n",
      "3238/3238 [==============================] - 2s 680us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 314/1000\n",
      "3238/3238 [==============================] - 2s 659us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 315/1000\n",
      "3238/3238 [==============================] - 2s 678us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 316/1000\n",
      "3238/3238 [==============================] - 2s 664us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 317/1000\n",
      "3238/3238 [==============================] - 2s 678us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 318/1000\n",
      "3238/3238 [==============================] - 2s 678us/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 319/1000\n",
      "3238/3238 [==============================] - 2s 677us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 320/1000\n",
      "3238/3238 [==============================] - 2s 683us/step - loss: 0.1543 - val_loss: 0.1515\n",
      "Epoch 321/1000\n",
      "3238/3238 [==============================] - 2s 682us/step - loss: 0.1543 - val_loss: 0.1522\n",
      "Epoch 322/1000\n",
      "3238/3238 [==============================] - 2s 667us/step - loss: 0.1544 - val_loss: 0.1515\n",
      "Epoch 323/1000\n",
      "3238/3238 [==============================] - 2s 670us/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 324/1000\n",
      "3238/3238 [==============================] - 2s 657us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 325/1000\n",
      "3238/3238 [==============================] - 2s 683us/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 326/1000\n",
      "3238/3238 [==============================] - 2s 689us/step - loss: 0.1545 - val_loss: 0.1517\n",
      "Epoch 327/1000\n",
      "3238/3238 [==============================] - 2s 662us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 328/1000\n",
      "3238/3238 [==============================] - 2s 687us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 329/1000\n",
      "3238/3238 [==============================] - 2s 675us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 330/1000\n",
      "3238/3238 [==============================] - 2s 670us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 331/1000\n",
      "3238/3238 [==============================] - 2s 687us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 332/1000\n",
      "3238/3238 [==============================] - 2s 674us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 333/1000\n",
      "3238/3238 [==============================] - 2s 687us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 334/1000\n",
      "3238/3238 [==============================] - 2s 679us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 335/1000\n",
      "3238/3238 [==============================] - 2s 664us/step - loss: 0.1545 - val_loss: 0.1518\n",
      "Epoch 336/1000\n",
      "3238/3238 [==============================] - 2s 695us/step - loss: 0.1542 - val_loss: 0.1517\n",
      "Epoch 337/1000\n",
      "3238/3238 [==============================] - 2s 677us/step - loss: 0.1544 - val_loss: 0.1516\n",
      "Epoch 338/1000\n",
      "3238/3238 [==============================] - 2s 671us/step - loss: 0.1542 - val_loss: 0.1516\n",
      "Epoch 339/1000\n",
      "3238/3238 [==============================] - 2s 693us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 340/1000\n",
      "3238/3238 [==============================] - 2s 677us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 341/1000\n",
      "3238/3238 [==============================] - 2s 686us/step - loss: 0.1542 - val_loss: 0.1516\n",
      "Epoch 342/1000\n",
      "3238/3238 [==============================] - 2s 695us/step - loss: 0.1543 - val_loss: 0.1515\n",
      "Epoch 343/1000\n",
      "3238/3238 [==============================] - 2s 672us/step - loss: 0.1542 - val_loss: 0.1515\n",
      "Epoch 344/1000\n",
      "3238/3238 [==============================] - 2s 679us/step - loss: 0.1543 - val_loss: 0.1515\n",
      "Epoch 345/1000\n",
      "3238/3238 [==============================] - 2s 691us/step - loss: 0.1542 - val_loss: 0.1514\n",
      "Epoch 346/1000\n",
      "3238/3238 [==============================] - 2s 681us/step - loss: 0.1545 - val_loss: 0.1521\n",
      "Epoch 347/1000\n",
      "3238/3238 [==============================] - 2s 688us/step - loss: 0.1544 - val_loss: 0.1518\n",
      "Epoch 348/1000\n",
      "3238/3238 [==============================] - 2s 674us/step - loss: 0.1545 - val_loss: 0.1516\n",
      "Epoch 349/1000\n",
      "3238/3238 [==============================] - 2s 689us/step - loss: 0.1542 - val_loss: 0.1516\n",
      "Epoch 350/1000\n",
      "3238/3238 [==============================] - 2s 690us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 351/1000\n",
      "3238/3238 [==============================] - 2s 670us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 352/1000\n",
      "3238/3238 [==============================] - 2s 683us/step - loss: 0.1542 - val_loss: 0.1515\n",
      "Epoch 353/1000\n",
      "3238/3238 [==============================] - 2s 675us/step - loss: 0.1542 - val_loss: 0.1515\n",
      "Epoch 354/1000\n",
      "3238/3238 [==============================] - 2s 683us/step - loss: 0.1542 - val_loss: 0.1515\n",
      "Epoch 355/1000\n",
      "3238/3238 [==============================] - 2s 683us/step - loss: 0.1541 - val_loss: 0.1515\n",
      "Epoch 356/1000\n",
      "3238/3238 [==============================] - 2s 679us/step - loss: 0.1541 - val_loss: 0.1515\n",
      "Epoch 357/1000\n",
      "3238/3238 [==============================] - 2s 687us/step - loss: 0.1542 - val_loss: 0.1514\n",
      "Epoch 358/1000\n",
      "3238/3238 [==============================] - 2s 690us/step - loss: 0.1552 - val_loss: 0.1519\n",
      "Epoch 359/1000\n",
      "3238/3238 [==============================] - 2s 678us/step - loss: 0.1542 - val_loss: 0.1516\n",
      "Epoch 360/1000\n",
      "3238/3238 [==============================] - 2s 696us/step - loss: 0.1543 - val_loss: 0.1515\n",
      "Epoch 361/1000\n",
      "3238/3238 [==============================] - 2s 685us/step - loss: 0.1541 - val_loss: 0.1516\n",
      "Epoch 362/1000\n",
      "3238/3238 [==============================] - 2s 684us/step - loss: 0.1543 - val_loss: 0.1515\n",
      "Epoch 363/1000\n",
      "3238/3238 [==============================] - 2s 681us/step - loss: 0.1543 - val_loss: 0.1517\n",
      "Epoch 364/1000\n",
      "3238/3238 [==============================] - 2s 682us/step - loss: 0.1541 - val_loss: 0.1517\n",
      "Epoch 365/1000\n",
      "3238/3238 [==============================] - 2s 689us/step - loss: 0.1542 - val_loss: 0.1515\n",
      "Epoch 366/1000\n",
      "3238/3238 [==============================] - 2s 690us/step - loss: 0.1543 - val_loss: 0.1515\n",
      "Epoch 367/1000\n",
      "3238/3238 [==============================] - 2s 679us/step - loss: 0.1544 - val_loss: 0.1515\n",
      "Epoch 368/1000\n",
      "3238/3238 [==============================] - 2s 680us/step - loss: 0.1544 - val_loss: 0.1518\n",
      "Epoch 369/1000\n",
      "3238/3238 [==============================] - 2s 669us/step - loss: 0.1542 - val_loss: 0.1515\n",
      "Epoch 370/1000\n",
      "3238/3238 [==============================] - 2s 682us/step - loss: 0.1540 - val_loss: 0.1515\n",
      "Epoch 371/1000\n",
      "3238/3238 [==============================] - 2s 687us/step - loss: 0.1540 - val_loss: 0.1514\n",
      "Epoch 372/1000\n",
      "3238/3238 [==============================] - 2s 674us/step - loss: 0.1539 - val_loss: 0.1513\n",
      "Epoch 373/1000\n",
      "3238/3238 [==============================] - 2s 694us/step - loss: 0.1540 - val_loss: 0.1514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 374/1000\n",
      "3238/3238 [==============================] - 2s 674us/step - loss: 0.1543 - val_loss: 0.1516\n",
      "Epoch 375/1000\n",
      "3238/3238 [==============================] - 2s 667us/step - loss: 0.1546 - val_loss: 0.1514\n",
      "Epoch 376/1000\n",
      "3238/3238 [==============================] - 2s 675us/step - loss: 0.1553 - val_loss: 0.1519\n",
      "Epoch 377/1000\n",
      "3238/3238 [==============================] - 2s 675us/step - loss: 0.1542 - val_loss: 0.1517\n",
      "Epoch 378/1000\n",
      "3238/3238 [==============================] - 2s 675us/step - loss: 0.1542 - val_loss: 0.1514\n",
      "Epoch 379/1000\n",
      "3238/3238 [==============================] - 2s 682us/step - loss: 0.1540 - val_loss: 0.1514\n",
      "Epoch 380/1000\n",
      "3238/3238 [==============================] - 2s 668us/step - loss: 0.1540 - val_loss: 0.1514\n",
      "Epoch 381/1000\n",
      "3238/3238 [==============================] - 2s 678us/step - loss: 0.1539 - val_loss: 0.1514\n",
      "Epoch 382/1000\n",
      "3238/3238 [==============================] - 2s 674us/step - loss: 0.1545 - val_loss: 0.1513\n",
      "Epoch 383/1000\n",
      "3238/3238 [==============================] - 2s 659us/step - loss: 0.1542 - val_loss: 0.1514\n",
      "Epoch 384/1000\n",
      "3238/3238 [==============================] - 2s 694us/step - loss: 0.1551 - val_loss: 0.1521\n",
      "Epoch 385/1000\n",
      "3238/3238 [==============================] - 2s 663us/step - loss: 0.1540 - val_loss: 0.1519\n",
      "Epoch 386/1000\n",
      "3238/3238 [==============================] - 2s 680us/step - loss: 0.1546 - val_loss: 0.1516\n",
      "Epoch 387/1000\n",
      "3238/3238 [==============================] - 2s 682us/step - loss: 0.1545 - val_loss: 0.1518\n",
      "Epoch 388/1000\n",
      "3238/3238 [==============================] - 2s 657us/step - loss: 0.1542 - val_loss: 0.1515\n",
      "Epoch 389/1000\n",
      "3238/3238 [==============================] - 2s 687us/step - loss: 0.1542 - val_loss: 0.1517\n",
      "Epoch 390/1000\n",
      "3238/3238 [==============================] - 2s 682us/step - loss: 0.1543 - val_loss: 0.1515\n",
      "Epoch 391/1000\n",
      "3238/3238 [==============================] - 2s 668us/step - loss: 0.1541 - val_loss: 0.1515\n",
      "Epoch 392/1000\n",
      "3238/3238 [==============================] - 2s 685us/step - loss: 0.1541 - val_loss: 0.1515\n",
      "Epoch 393/1000\n",
      "3238/3238 [==============================] - 2s 677us/step - loss: 0.1540 - val_loss: 0.1515\n",
      "Epoch 394/1000\n",
      "3238/3238 [==============================] - 2s 682us/step - loss: 0.1540 - val_loss: 0.1514\n",
      "Epoch 395/1000\n",
      "3238/3238 [==============================] - 2s 687us/step - loss: 0.1538 - val_loss: 0.1513\n",
      "Epoch 396/1000\n",
      "3238/3238 [==============================] - 2s 663us/step - loss: 0.1543 - val_loss: 0.1515\n",
      "Epoch 397/1000\n",
      "3238/3238 [==============================] - 2s 686us/step - loss: 0.1546 - val_loss: 0.1519\n",
      "Epoch 398/1000\n",
      "3238/3238 [==============================] - 2s 683us/step - loss: 0.1542 - val_loss: 0.1519\n",
      "Epoch 399/1000\n",
      "3238/3238 [==============================] - 2s 701us/step - loss: 0.1543 - val_loss: 0.1515\n",
      "Epoch 400/1000\n",
      "3238/3238 [==============================] - 2s 691us/step - loss: 0.1540 - val_loss: 0.1515\n",
      "Epoch 401/1000\n",
      "3238/3238 [==============================] - 2s 670us/step - loss: 0.1540 - val_loss: 0.1515\n",
      "Epoch 402/1000\n",
      "3238/3238 [==============================] - 2s 673us/step - loss: 0.1539 - val_loss: 0.1514\n",
      "Epoch 403/1000\n",
      "3238/3238 [==============================] - 2s 696us/step - loss: 0.1538 - val_loss: 0.1513\n",
      "Epoch 404/1000\n",
      "3238/3238 [==============================] - 2s 672us/step - loss: 0.1538 - val_loss: 0.1513\n",
      "Epoch 405/1000\n",
      "3238/3238 [==============================] - 2s 686us/step - loss: 0.1539 - val_loss: 0.1513\n",
      "Epoch 406/1000\n",
      "3238/3238 [==============================] - 2s 675us/step - loss: 0.1542 - val_loss: 0.1513\n",
      "Epoch 407/1000\n",
      "3238/3238 [==============================] - 2s 682us/step - loss: 0.1537 - val_loss: 0.1517\n",
      "Epoch 408/1000\n",
      "3238/3238 [==============================] - 2s 689us/step - loss: 0.1535 - val_loss: 0.1513\n",
      "Epoch 409/1000\n",
      "3238/3238 [==============================] - 2s 674us/step - loss: 0.1525 - val_loss: 0.1514\n",
      "Epoch 410/1000\n",
      "3238/3238 [==============================] - 2s 678us/step - loss: 0.1517 - val_loss: 0.1536\n",
      "Epoch 411/1000\n",
      "3238/3238 [==============================] - 2s 678us/step - loss: 0.1531 - val_loss: 0.1518\n",
      "Epoch 412/1000\n",
      "3238/3238 [==============================] - 2s 674us/step - loss: 0.1527 - val_loss: 0.1524\n",
      "Epoch 413/1000\n",
      "3238/3238 [==============================] - 2s 686us/step - loss: 0.1523 - val_loss: 0.1523\n",
      "Epoch 414/1000\n",
      "3238/3238 [==============================] - 2s 682us/step - loss: 0.1516 - val_loss: 0.1531\n",
      "Epoch 415/1000\n",
      "3238/3238 [==============================] - 2s 679us/step - loss: 0.1521 - val_loss: 0.1541\n",
      "Epoch 416/1000\n",
      "3238/3238 [==============================] - 2s 688us/step - loss: 0.1524 - val_loss: 0.1540\n",
      "Epoch 417/1000\n",
      "3238/3238 [==============================] - 2s 669us/step - loss: 0.1518 - val_loss: 0.1535\n",
      "Epoch 418/1000\n",
      "3238/3238 [==============================] - 2s 687us/step - loss: 0.1516 - val_loss: 0.1538\n",
      "Epoch 419/1000\n",
      "3238/3238 [==============================] - 2s 697us/step - loss: 0.1510 - val_loss: 0.1537\n",
      "Epoch 420/1000\n",
      "3238/3238 [==============================] - 2s 662us/step - loss: 0.1504 - val_loss: 0.1531\n",
      "Epoch 421/1000\n",
      "3238/3238 [==============================] - 2s 691us/step - loss: 0.1499 - val_loss: 0.1523\n",
      "Epoch 422/1000\n",
      "3238/3238 [==============================] - 2s 676us/step - loss: 0.1499 - val_loss: 0.1523\n",
      "Epoch 423/1000\n",
      "3238/3238 [==============================] - 2s 681us/step - loss: 0.1495 - val_loss: 0.1527\n",
      "Epoch 424/1000\n",
      "3238/3238 [==============================] - 2s 695us/step - loss: 0.1501 - val_loss: 0.1538\n",
      "Epoch 425/1000\n",
      "3238/3238 [==============================] - 2s 672us/step - loss: 0.1499 - val_loss: 0.1529\n",
      "Epoch 426/1000\n",
      "3238/3238 [==============================] - 2s 689us/step - loss: 0.1490 - val_loss: 0.1533\n",
      "Epoch 427/1000\n",
      "3238/3238 [==============================] - 2s 706us/step - loss: 0.1500 - val_loss: 0.1545\n",
      "Epoch 428/1000\n",
      "3238/3238 [==============================] - 2s 700us/step - loss: 0.1498 - val_loss: 0.1535\n",
      "Epoch 429/1000\n",
      "3238/3238 [==============================] - 2s 685us/step - loss: 0.1494 - val_loss: 0.1528\n",
      "Epoch 430/1000\n",
      "3238/3238 [==============================] - 2s 677us/step - loss: 0.1489 - val_loss: 0.1526\n",
      "Epoch 431/1000\n",
      "3238/3238 [==============================] - 2s 687us/step - loss: 0.1486 - val_loss: 0.1526\n",
      "Epoch 432/1000\n",
      "3238/3238 [==============================] - 2s 691us/step - loss: 0.1479 - val_loss: 0.1511\n",
      "Epoch 433/1000\n",
      "3238/3238 [==============================] - 2s 675us/step - loss: 0.1471 - val_loss: 0.1523\n",
      "Epoch 434/1000\n",
      "3238/3238 [==============================] - 2s 687us/step - loss: 0.1477 - val_loss: 0.1527\n",
      "Epoch 435/1000\n",
      "3238/3238 [==============================] - 2s 687us/step - loss: 0.1469 - val_loss: 0.1502\n",
      "Epoch 436/1000\n",
      "3238/3238 [==============================] - 2s 664us/step - loss: 0.1464 - val_loss: 0.1558\n",
      "Epoch 437/1000\n",
      "3238/3238 [==============================] - 2s 678us/step - loss: 0.1551 - val_loss: 0.1564\n",
      "Epoch 438/1000\n",
      "3238/3238 [==============================] - 2s 685us/step - loss: 0.1492 - val_loss: 0.1526\n",
      "Epoch 439/1000\n",
      "3238/3238 [==============================] - 2s 681us/step - loss: 0.1495 - val_loss: 0.1529\n",
      "Epoch 440/1000\n",
      "3238/3238 [==============================] - 2s 692us/step - loss: 0.1477 - val_loss: 0.1516\n",
      "Epoch 441/1000\n",
      "3238/3238 [==============================] - 2s 669us/step - loss: 0.1463 - val_loss: 0.1519\n",
      "Epoch 442/1000\n",
      "3238/3238 [==============================] - 2s 691us/step - loss: 0.1461 - val_loss: 0.1507\n",
      "Epoch 443/1000\n",
      "3238/3238 [==============================] - 2s 703us/step - loss: 0.1456 - val_loss: 0.1501\n",
      "Epoch 444/1000\n",
      "3238/3238 [==============================] - 2s 664us/step - loss: 0.1445 - val_loss: 0.1504\n",
      "Epoch 445/1000\n",
      "3238/3238 [==============================] - 2s 695us/step - loss: 0.1490 - val_loss: 0.1593\n",
      "Epoch 446/1000\n",
      "3238/3238 [==============================] - 2s 681us/step - loss: 0.1481 - val_loss: 0.1501\n",
      "Epoch 447/1000\n",
      "3238/3238 [==============================] - 2s 684us/step - loss: 0.1472 - val_loss: 0.1513\n",
      "Epoch 448/1000\n",
      "3238/3238 [==============================] - 2s 687us/step - loss: 0.1462 - val_loss: 0.1502\n",
      "Epoch 449/1000\n",
      "3238/3238 [==============================] - 2s 692us/step - loss: 0.1459 - val_loss: 0.1509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 450/1000\n",
      "3238/3238 [==============================] - 2s 681us/step - loss: 0.1471 - val_loss: 0.1523\n",
      "Epoch 451/1000\n",
      "3238/3238 [==============================] - 2s 674us/step - loss: 0.1459 - val_loss: 0.1520\n",
      "Epoch 452/1000\n",
      "3238/3238 [==============================] - 2s 654us/step - loss: 0.1460 - val_loss: 0.1518\n",
      "Epoch 453/1000\n",
      "3238/3238 [==============================] - 2s 676us/step - loss: 0.1468 - val_loss: 0.1555\n",
      "Epoch 454/1000\n",
      "3238/3238 [==============================] - 2s 659us/step - loss: 0.1490 - val_loss: 0.1544\n",
      "Epoch 455/1000\n",
      "3238/3238 [==============================] - 2s 693us/step - loss: 0.1484 - val_loss: 0.1507\n",
      "Epoch 456/1000\n",
      "3238/3238 [==============================] - 2s 679us/step - loss: 0.1488 - val_loss: 0.1533\n",
      "Epoch 457/1000\n",
      "3238/3238 [==============================] - 2s 669us/step - loss: 0.1486 - val_loss: 0.1524\n",
      "Epoch 458/1000\n",
      "3238/3238 [==============================] - 2s 676us/step - loss: 0.1477 - val_loss: 0.1521\n",
      "Epoch 459/1000\n",
      "3238/3238 [==============================] - 2s 678us/step - loss: 0.1462 - val_loss: 0.1507\n",
      "Epoch 460/1000\n",
      "3238/3238 [==============================] - 2s 676us/step - loss: 0.1450 - val_loss: 0.1508\n",
      "Epoch 461/1000\n",
      "3238/3238 [==============================] - 2s 681us/step - loss: 0.1448 - val_loss: 0.1492\n",
      "Epoch 462/1000\n",
      "3238/3238 [==============================] - 2s 662us/step - loss: 0.1434 - val_loss: 0.1489\n",
      "Epoch 463/1000\n",
      "3238/3238 [==============================] - 2s 677us/step - loss: 0.1432 - val_loss: 0.1503\n",
      "Epoch 464/1000\n",
      "3238/3238 [==============================] - 2s 684us/step - loss: 0.1460 - val_loss: 0.1504\n",
      "Epoch 465/1000\n",
      "3238/3238 [==============================] - 2s 659us/step - loss: 0.1449 - val_loss: 0.1504\n",
      "Epoch 466/1000\n",
      "3238/3238 [==============================] - 2s 679us/step - loss: 0.1441 - val_loss: 0.1490\n",
      "Epoch 467/1000\n",
      "3238/3238 [==============================] - 2s 679us/step - loss: 0.1428 - val_loss: 0.1491\n",
      "Epoch 468/1000\n",
      "3238/3238 [==============================] - 2s 672us/step - loss: 0.1433 - val_loss: 0.1486\n",
      "Epoch 469/1000\n",
      "3238/3238 [==============================] - 2s 685us/step - loss: 0.1441 - val_loss: 0.1521\n",
      "Epoch 470/1000\n",
      "3238/3238 [==============================] - 2s 680us/step - loss: 0.1449 - val_loss: 0.1488\n",
      "Epoch 471/1000\n",
      "3238/3238 [==============================] - 2s 682us/step - loss: 0.1427 - val_loss: 0.1485\n",
      "Epoch 472/1000\n",
      "3238/3238 [==============================] - 2s 681us/step - loss: 0.1444 - val_loss: 0.1503\n",
      "Epoch 473/1000\n",
      "3238/3238 [==============================] - 2s 673us/step - loss: 0.1443 - val_loss: 0.1497\n",
      "Epoch 474/1000\n",
      "3238/3238 [==============================] - 2s 683us/step - loss: 0.1425 - val_loss: 0.1492\n",
      "Epoch 475/1000\n",
      "3238/3238 [==============================] - 2s 672us/step - loss: 0.1421 - val_loss: 0.1486\n",
      "Epoch 476/1000\n",
      "3238/3238 [==============================] - 2s 677us/step - loss: 0.1439 - val_loss: 0.1482\n",
      "Epoch 477/1000\n",
      "3238/3238 [==============================] - 2s 680us/step - loss: 0.1421 - val_loss: 0.1493\n",
      "Epoch 478/1000\n",
      "3238/3238 [==============================] - 2s 662us/step - loss: 0.1443 - val_loss: 0.1568\n",
      "Epoch 479/1000\n",
      "3238/3238 [==============================] - 2s 686us/step - loss: 0.1441 - val_loss: 0.1482\n",
      "Epoch 480/1000\n",
      "3238/3238 [==============================] - 2s 678us/step - loss: 0.1415 - val_loss: 0.1486\n",
      "Epoch 481/1000\n",
      "3238/3238 [==============================] - 2s 666us/step - loss: 0.1420 - val_loss: 0.1489\n",
      "Epoch 482/1000\n",
      "3238/3238 [==============================] - 2s 683us/step - loss: 0.1411 - val_loss: 0.1478\n",
      "Epoch 483/1000\n",
      "3238/3238 [==============================] - 2s 672us/step - loss: 0.1432 - val_loss: 0.1503\n",
      "Epoch 484/1000\n",
      "3238/3238 [==============================] - 2s 681us/step - loss: 0.1445 - val_loss: 0.1483\n",
      "Epoch 485/1000\n",
      "3238/3238 [==============================] - 2s 679us/step - loss: 0.1414 - val_loss: 0.1476\n",
      "Epoch 486/1000\n",
      "3238/3238 [==============================] - 2s 674us/step - loss: 0.1414 - val_loss: 0.1497\n",
      "Epoch 487/1000\n",
      "3238/3238 [==============================] - 2s 684us/step - loss: 0.1424 - val_loss: 0.1484\n",
      "Epoch 488/1000\n",
      "3238/3238 [==============================] - 2s 674us/step - loss: 0.1407 - val_loss: 0.1472\n",
      "Epoch 489/1000\n",
      "3238/3238 [==============================] - 2s 660us/step - loss: 0.1412 - val_loss: 0.1541\n",
      "Epoch 490/1000\n",
      "3238/3238 [==============================] - 2s 679us/step - loss: 0.1421 - val_loss: 0.1472\n",
      "Epoch 491/1000\n",
      "3238/3238 [==============================] - 2s 686us/step - loss: 0.1407 - val_loss: 0.1481\n",
      "Epoch 492/1000\n",
      "3238/3238 [==============================] - 2s 676us/step - loss: 0.1418 - val_loss: 0.1472\n",
      "Epoch 493/1000\n",
      "3238/3238 [==============================] - 2s 691us/step - loss: 0.1439 - val_loss: 0.1617\n",
      "Epoch 494/1000\n",
      "3238/3238 [==============================] - 2s 678us/step - loss: 0.1493 - val_loss: 0.1524\n",
      "Epoch 495/1000\n",
      "3238/3238 [==============================] - 2s 678us/step - loss: 0.1462 - val_loss: 0.1519\n",
      "Epoch 496/1000\n",
      "3238/3238 [==============================] - 2s 695us/step - loss: 0.1460 - val_loss: 0.1492\n",
      "Epoch 497/1000\n",
      "3238/3238 [==============================] - 2s 671us/step - loss: 0.1425 - val_loss: 0.1481\n",
      "Epoch 498/1000\n",
      "3238/3238 [==============================] - 2s 705us/step - loss: 0.1415 - val_loss: 0.1475\n",
      "Epoch 499/1000\n",
      "3238/3238 [==============================] - 2s 682us/step - loss: 0.1417 - val_loss: 0.1472\n",
      "Epoch 500/1000\n",
      "3238/3238 [==============================] - 2s 695us/step - loss: 0.1417 - val_loss: 0.1465\n",
      "Epoch 501/1000\n",
      "3238/3238 [==============================] - 2s 680us/step - loss: 0.1415 - val_loss: 0.1467\n",
      "Epoch 502/1000\n",
      "3238/3238 [==============================] - 2s 677us/step - loss: 0.1408 - val_loss: 0.1469\n",
      "Epoch 503/1000\n",
      "3238/3238 [==============================] - 2s 683us/step - loss: 0.1422 - val_loss: 0.1528\n",
      "Epoch 504/1000\n",
      "3238/3238 [==============================] - 2s 679us/step - loss: 0.1449 - val_loss: 0.1490\n",
      "Epoch 505/1000\n",
      "3238/3238 [==============================] - 2s 676us/step - loss: 0.1449 - val_loss: 0.1519\n",
      "Epoch 506/1000\n",
      "3238/3238 [==============================] - 2s 681us/step - loss: 0.1445 - val_loss: 0.1542\n",
      "Epoch 507/1000\n",
      "3238/3238 [==============================] - 2s 682us/step - loss: 0.1450 - val_loss: 0.1515\n",
      "Epoch 508/1000\n",
      "3238/3238 [==============================] - 2s 686us/step - loss: 0.1448 - val_loss: 0.1495\n",
      "Epoch 509/1000\n",
      "3238/3238 [==============================] - 2s 691us/step - loss: 0.1419 - val_loss: 0.1477\n",
      "Epoch 510/1000\n",
      "3238/3238 [==============================] - 2s 683us/step - loss: 0.1410 - val_loss: 0.1474\n",
      "Epoch 511/1000\n",
      "3238/3238 [==============================] - 2s 688us/step - loss: 0.1420 - val_loss: 0.1465\n",
      "Epoch 512/1000\n",
      "3238/3238 [==============================] - 2s 683us/step - loss: 0.1400 - val_loss: 0.1471\n",
      "Epoch 513/1000\n",
      "3238/3238 [==============================] - 2s 689us/step - loss: 0.1403 - val_loss: 0.1466\n",
      "Epoch 514/1000\n",
      "3238/3238 [==============================] - 2s 681us/step - loss: 0.1397 - val_loss: 0.1469\n",
      "Epoch 515/1000\n",
      "3238/3238 [==============================] - 2s 681us/step - loss: 0.1402 - val_loss: 0.1465\n",
      "Epoch 516/1000\n",
      "3238/3238 [==============================] - 2s 693us/step - loss: 0.1398 - val_loss: 0.1484\n",
      "Epoch 517/1000\n",
      "3238/3238 [==============================] - 2s 690us/step - loss: 0.1437 - val_loss: 0.1503\n",
      "Epoch 518/1000\n",
      "3238/3238 [==============================] - 2s 687us/step - loss: 0.1419 - val_loss: 0.1469\n",
      "Epoch 519/1000\n",
      "3238/3238 [==============================] - 2s 689us/step - loss: 0.1407 - val_loss: 0.1464\n",
      "Epoch 520/1000\n",
      "3238/3238 [==============================] - 2s 690us/step - loss: 0.1397 - val_loss: 0.1461\n",
      "Epoch 521/1000\n",
      "3238/3238 [==============================] - 2s 693us/step - loss: 0.1390 - val_loss: 0.1462\n",
      "Epoch 522/1000\n",
      "3238/3238 [==============================] - 2s 692us/step - loss: 0.1399 - val_loss: 0.1457\n",
      "Epoch 523/1000\n",
      "3238/3238 [==============================] - 2s 679us/step - loss: 0.1388 - val_loss: 0.1457\n",
      "Epoch 524/1000\n",
      "3238/3238 [==============================] - 2s 689us/step - loss: 0.1390 - val_loss: 0.1466\n",
      "Epoch 525/1000\n",
      "3238/3238 [==============================] - 2s 688us/step - loss: 0.1388 - val_loss: 0.1456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 526/1000\n",
      "3238/3238 [==============================] - 2s 671us/step - loss: 0.1379 - val_loss: 0.1454\n",
      "Epoch 527/1000\n",
      "3238/3238 [==============================] - 2s 678us/step - loss: 0.1385 - val_loss: 0.1455\n",
      "Epoch 528/1000\n",
      "3238/3238 [==============================] - 2s 675us/step - loss: 0.1394 - val_loss: 0.1463\n",
      "Epoch 529/1000\n",
      "3238/3238 [==============================] - 2s 664us/step - loss: 0.1391 - val_loss: 0.1451\n",
      "Epoch 530/1000\n",
      "3238/3238 [==============================] - 2s 667us/step - loss: 0.1374 - val_loss: 0.1456\n",
      "Epoch 531/1000\n",
      "3238/3238 [==============================] - 2s 663us/step - loss: 0.1400 - val_loss: 0.1534\n",
      "Epoch 532/1000\n",
      "3238/3238 [==============================] - 2s 679us/step - loss: 0.1425 - val_loss: 0.1485\n",
      "Epoch 533/1000\n",
      "3238/3238 [==============================] - 2s 668us/step - loss: 0.1386 - val_loss: 0.1448\n",
      "Epoch 534/1000\n",
      "3238/3238 [==============================] - 2s 668us/step - loss: 0.1380 - val_loss: 0.1445\n",
      "Epoch 535/1000\n",
      "3238/3238 [==============================] - 2s 700us/step - loss: 0.1383 - val_loss: 0.1444\n",
      "Epoch 536/1000\n",
      "3238/3238 [==============================] - 2s 661us/step - loss: 0.1374 - val_loss: 0.1473\n",
      "Epoch 537/1000\n",
      "3238/3238 [==============================] - 2s 688us/step - loss: 0.1395 - val_loss: 0.1476\n",
      "Epoch 538/1000\n",
      "3238/3238 [==============================] - 2s 683us/step - loss: 0.1390 - val_loss: 0.1475\n",
      "Epoch 539/1000\n",
      "3238/3238 [==============================] - 2s 664us/step - loss: 0.1395 - val_loss: 0.1447\n",
      "Epoch 540/1000\n",
      "3238/3238 [==============================] - 2s 682us/step - loss: 0.1446 - val_loss: 0.1497\n",
      "Epoch 541/1000\n",
      "3238/3238 [==============================] - 2s 669us/step - loss: 0.1452 - val_loss: 0.1529\n",
      "Epoch 542/1000\n",
      "3238/3238 [==============================] - 2s 679us/step - loss: 0.1420 - val_loss: 0.1454\n",
      "Epoch 543/1000\n",
      "3238/3238 [==============================] - 2s 687us/step - loss: 0.1405 - val_loss: 0.1459\n",
      "Epoch 544/1000\n",
      "3238/3238 [==============================] - 2s 655us/step - loss: 0.1385 - val_loss: 0.1447\n",
      "Epoch 545/1000\n",
      "3238/3238 [==============================] - 2s 696us/step - loss: 0.1376 - val_loss: 0.1441\n",
      "Epoch 546/1000\n",
      "3238/3238 [==============================] - 2s 681us/step - loss: 0.1372 - val_loss: 0.1439\n",
      "Epoch 547/1000\n",
      "3238/3238 [==============================] - 2s 664us/step - loss: 0.1370 - val_loss: 0.1439\n",
      "Epoch 548/1000\n",
      "3238/3238 [==============================] - 2s 707us/step - loss: 0.1363 - val_loss: 0.1440\n",
      "Epoch 549/1000\n",
      "3238/3238 [==============================] - 2s 674us/step - loss: 0.1371 - val_loss: 0.1448\n",
      "Epoch 550/1000\n",
      "3238/3238 [==============================] - 2s 679us/step - loss: 0.1365 - val_loss: 0.1441\n",
      "Epoch 551/1000\n",
      "3238/3238 [==============================] - 2s 682us/step - loss: 0.1366 - val_loss: 0.1497\n",
      "Epoch 552/1000\n",
      "3238/3238 [==============================] - 2s 660us/step - loss: 0.1394 - val_loss: 0.1475\n",
      "Epoch 553/1000\n",
      "3238/3238 [==============================] - 2s 686us/step - loss: 0.1381 - val_loss: 0.1433\n",
      "Epoch 554/1000\n",
      "3238/3238 [==============================] - 2s 675us/step - loss: 0.1365 - val_loss: 0.1434\n",
      "Epoch 555/1000\n",
      "3238/3238 [==============================] - 2s 675us/step - loss: 0.1358 - val_loss: 0.1430\n",
      "Epoch 556/1000\n",
      "3238/3238 [==============================] - 2s 691us/step - loss: 0.1363 - val_loss: 0.1459\n",
      "Epoch 557/1000\n",
      "3238/3238 [==============================] - 2s 666us/step - loss: 0.1394 - val_loss: 0.1448\n",
      "Epoch 558/1000\n",
      "3238/3238 [==============================] - 2s 690us/step - loss: 0.1369 - val_loss: 0.1435\n",
      "Epoch 559/1000\n",
      "3238/3238 [==============================] - 2s 681us/step - loss: 0.1384 - val_loss: 0.1434\n",
      "Epoch 560/1000\n",
      "3238/3238 [==============================] - 2s 671us/step - loss: 0.1364 - val_loss: 0.1437\n",
      "Epoch 561/1000\n",
      "3238/3238 [==============================] - 2s 682us/step - loss: 0.1350 - val_loss: 0.1435\n",
      "Epoch 562/1000\n",
      "3238/3238 [==============================] - 2s 683us/step - loss: 0.1350 - val_loss: 0.1432\n",
      "Epoch 563/1000\n",
      "3238/3238 [==============================] - 2s 682us/step - loss: 0.1352 - val_loss: 0.1422\n",
      "Epoch 564/1000\n",
      "3238/3238 [==============================] - 2s 677us/step - loss: 0.1341 - val_loss: 0.1423\n",
      "Epoch 565/1000\n",
      "3238/3238 [==============================] - 2s 677us/step - loss: 0.1351 - val_loss: 0.1423\n",
      "Epoch 566/1000\n",
      "3238/3238 [==============================] - 2s 681us/step - loss: 0.1398 - val_loss: 0.1557\n",
      "Epoch 567/1000\n",
      "3238/3238 [==============================] - 2s 687us/step - loss: 0.1405 - val_loss: 0.1487\n",
      "Epoch 568/1000\n",
      "3238/3238 [==============================] - 2s 676us/step - loss: 0.1407 - val_loss: 0.1581\n",
      "Epoch 569/1000\n",
      "3238/3238 [==============================] - 2s 687us/step - loss: 0.1424 - val_loss: 0.1481\n",
      "Epoch 570/1000\n",
      "3238/3238 [==============================] - 2s 679us/step - loss: 0.1392 - val_loss: 0.1435\n",
      "Epoch 571/1000\n",
      "3238/3238 [==============================] - 2s 685us/step - loss: 0.1365 - val_loss: 0.1428\n",
      "Epoch 572/1000\n",
      "3238/3238 [==============================] - 2s 686us/step - loss: 0.1356 - val_loss: 0.1442\n",
      "Epoch 573/1000\n",
      "3238/3238 [==============================] - 2s 670us/step - loss: 0.1364 - val_loss: 0.1493\n",
      "Epoch 574/1000\n",
      "3238/3238 [==============================] - 2s 676us/step - loss: 0.1381 - val_loss: 0.1432\n",
      "Epoch 575/1000\n",
      "3238/3238 [==============================] - 2s 683us/step - loss: 0.1355 - val_loss: 0.1440\n",
      "Epoch 576/1000\n",
      "3238/3238 [==============================] - 2s 684us/step - loss: 0.1348 - val_loss: 0.1451\n",
      "Epoch 577/1000\n",
      "3238/3238 [==============================] - 2s 686us/step - loss: 0.1364 - val_loss: 0.1444\n",
      "Epoch 578/1000\n",
      "3238/3238 [==============================] - 2s 678us/step - loss: 0.1344 - val_loss: 0.1525\n",
      "Epoch 579/1000\n",
      "3238/3238 [==============================] - 2s 685us/step - loss: 0.1401 - val_loss: 0.1567\n",
      "Epoch 580/1000\n",
      "3238/3238 [==============================] - 2s 687us/step - loss: 0.1392 - val_loss: 0.1425\n",
      "Epoch 581/1000\n",
      "3238/3238 [==============================] - 2s 684us/step - loss: 0.1346 - val_loss: 0.1434\n",
      "Epoch 582/1000\n",
      "3238/3238 [==============================] - 2s 691us/step - loss: 0.1342 - val_loss: 0.1421\n",
      "Epoch 583/1000\n",
      "3238/3238 [==============================] - 2s 691us/step - loss: 0.1359 - val_loss: 0.1414\n",
      "Epoch 584/1000\n",
      "3238/3238 [==============================] - 2s 674us/step - loss: 0.1341 - val_loss: 0.1417\n",
      "Epoch 585/1000\n",
      "3238/3238 [==============================] - 2s 696us/step - loss: 0.1328 - val_loss: 0.1417\n",
      "Epoch 586/1000\n",
      "3238/3238 [==============================] - 2s 679us/step - loss: 0.1325 - val_loss: 0.1405\n",
      "Epoch 587/1000\n",
      "3238/3238 [==============================] - 2s 691us/step - loss: 0.1319 - val_loss: 0.1418\n",
      "Epoch 588/1000\n",
      "3238/3238 [==============================] - 2s 700us/step - loss: 0.1327 - val_loss: 0.1402\n",
      "Epoch 589/1000\n",
      "3238/3238 [==============================] - 2s 676us/step - loss: 0.1318 - val_loss: 0.1415\n",
      "Epoch 590/1000\n",
      "3238/3238 [==============================] - 2s 695us/step - loss: 0.1347 - val_loss: 0.1404\n",
      "Epoch 591/1000\n",
      "3238/3238 [==============================] - 2s 683us/step - loss: 0.1314 - val_loss: 0.1400\n",
      "Epoch 592/1000\n",
      "3238/3238 [==============================] - 2s 685us/step - loss: 0.1340 - val_loss: 0.1400\n",
      "Epoch 593/1000\n",
      "3238/3238 [==============================] - 2s 706us/step - loss: 0.1310 - val_loss: 0.1479\n",
      "Epoch 594/1000\n",
      "3238/3238 [==============================] - 2s 680us/step - loss: 0.1363 - val_loss: 0.1615\n",
      "Epoch 595/1000\n",
      "3238/3238 [==============================] - 2s 688us/step - loss: 0.1436 - val_loss: 0.1401\n",
      "Epoch 596/1000\n",
      "3238/3238 [==============================] - 2s 692us/step - loss: 0.1361 - val_loss: 0.1400\n",
      "Epoch 597/1000\n",
      "3238/3238 [==============================] - 2s 687us/step - loss: 0.1338 - val_loss: 0.1400\n",
      "Epoch 598/1000\n",
      "3238/3238 [==============================] - 2s 689us/step - loss: 0.1313 - val_loss: 0.1402\n",
      "Epoch 599/1000\n",
      "3238/3238 [==============================] - 2s 680us/step - loss: 0.1314 - val_loss: 0.1417\n",
      "Epoch 600/1000\n",
      "3238/3238 [==============================] - 2s 685us/step - loss: 0.1319 - val_loss: 0.1399\n",
      "Epoch 601/1000\n",
      "3238/3238 [==============================] - 2s 695us/step - loss: 0.1300 - val_loss: 0.1415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 602/1000\n",
      "3238/3238 [==============================] - 2s 671us/step - loss: 0.1309 - val_loss: 0.1393\n",
      "Epoch 603/1000\n",
      "3238/3238 [==============================] - 2s 679us/step - loss: 0.1321 - val_loss: 0.1482\n",
      "Epoch 604/1000\n",
      "3238/3238 [==============================] - 2s 693us/step - loss: 0.1330 - val_loss: 0.1402\n",
      "Epoch 605/1000\n",
      "3238/3238 [==============================] - 2s 659us/step - loss: 0.1296 - val_loss: 0.1403\n",
      "Epoch 606/1000\n",
      "3238/3238 [==============================] - 2s 670us/step - loss: 0.1299 - val_loss: 0.1385\n",
      "Epoch 607/1000\n",
      "3238/3238 [==============================] - 2s 663us/step - loss: 0.1280 - val_loss: 0.1404\n",
      "Epoch 608/1000\n",
      "3238/3238 [==============================] - 2s 665us/step - loss: 0.1326 - val_loss: 0.1411\n",
      "Epoch 609/1000\n",
      "3238/3238 [==============================] - 2s 677us/step - loss: 0.1322 - val_loss: 0.1394\n",
      "Epoch 610/1000\n",
      "3238/3238 [==============================] - 2s 671us/step - loss: 0.1300 - val_loss: 0.1401\n",
      "Epoch 611/1000\n",
      "3238/3238 [==============================] - 2s 675us/step - loss: 0.1285 - val_loss: 0.1402\n",
      "Epoch 612/1000\n",
      "3238/3238 [==============================] - 2s 688us/step - loss: 0.1279 - val_loss: 0.1380\n",
      "Epoch 613/1000\n",
      "3238/3238 [==============================] - 2s 665us/step - loss: 0.1273 - val_loss: 0.1381\n",
      "Epoch 614/1000\n",
      "3238/3238 [==============================] - 2s 684us/step - loss: 0.1264 - val_loss: 0.1382\n",
      "Epoch 615/1000\n",
      "3238/3238 [==============================] - 2s 674us/step - loss: 0.1272 - val_loss: 0.1399\n",
      "Epoch 616/1000\n",
      "3238/3238 [==============================] - 2s 679us/step - loss: 0.1272 - val_loss: 0.1403\n",
      "Epoch 617/1000\n",
      "3238/3238 [==============================] - 2s 679us/step - loss: 0.1276 - val_loss: 0.1393\n",
      "Epoch 618/1000\n",
      "3238/3238 [==============================] - 2s 665us/step - loss: 0.1298 - val_loss: 0.1369\n",
      "Epoch 619/1000\n",
      "3238/3238 [==============================] - 2s 678us/step - loss: 0.1269 - val_loss: 0.1391\n",
      "Epoch 620/1000\n",
      "3238/3238 [==============================] - 2s 671us/step - loss: 0.1298 - val_loss: 0.1449\n",
      "Epoch 621/1000\n",
      "3238/3238 [==============================] - 2s 666us/step - loss: 0.1341 - val_loss: 0.1370\n",
      "Epoch 622/1000\n",
      "3238/3238 [==============================] - 2s 688us/step - loss: 0.1310 - val_loss: 0.1491\n",
      "Epoch 623/1000\n",
      "3238/3238 [==============================] - 2s 665us/step - loss: 0.1331 - val_loss: 0.1390\n",
      "Epoch 624/1000\n",
      "3238/3238 [==============================] - 2s 677us/step - loss: 0.1284 - val_loss: 0.1366\n",
      "Epoch 625/1000\n",
      "3238/3238 [==============================] - 2s 680us/step - loss: 0.1277 - val_loss: 0.1424\n",
      "Epoch 626/1000\n",
      "3238/3238 [==============================] - 2s 663us/step - loss: 0.1297 - val_loss: 0.1437\n",
      "Epoch 627/1000\n",
      "3238/3238 [==============================] - 2s 687us/step - loss: 0.1294 - val_loss: 0.1406\n",
      "Epoch 628/1000\n",
      "3238/3238 [==============================] - 2s 680us/step - loss: 0.1269 - val_loss: 0.1370\n",
      "Epoch 629/1000\n",
      "3238/3238 [==============================] - 2s 667us/step - loss: 0.1256 - val_loss: 0.1364\n",
      "Epoch 630/1000\n",
      "3238/3238 [==============================] - 2s 678us/step - loss: 0.1264 - val_loss: 0.1398\n",
      "Epoch 631/1000\n",
      "3238/3238 [==============================] - 2s 679us/step - loss: 0.1267 - val_loss: 0.1371\n",
      "Epoch 632/1000\n",
      "3238/3238 [==============================] - 2s 680us/step - loss: 0.1241 - val_loss: 0.1386\n",
      "Epoch 633/1000\n",
      "3238/3238 [==============================] - 2s 686us/step - loss: 0.1258 - val_loss: 0.1371\n",
      "Epoch 634/1000\n",
      "3238/3238 [==============================] - 2s 680us/step - loss: 0.1244 - val_loss: 0.1411\n",
      "Epoch 635/1000\n",
      "3238/3238 [==============================] - 2s 692us/step - loss: 0.1257 - val_loss: 0.1365\n",
      "Epoch 636/1000\n",
      "3238/3238 [==============================] - 2s 673us/step - loss: 0.1278 - val_loss: 0.1429\n",
      "Epoch 637/1000\n",
      "3238/3238 [==============================] - 2s 689us/step - loss: 0.1277 - val_loss: 0.1369\n",
      "Epoch 638/1000\n",
      "3238/3238 [==============================] - 2s 683us/step - loss: 0.1239 - val_loss: 0.1407\n",
      "Epoch 639/1000\n",
      "3238/3238 [==============================] - 2s 674us/step - loss: 0.1286 - val_loss: 0.1365\n",
      "Epoch 640/1000\n",
      "3238/3238 [==============================] - 2s 683us/step - loss: 0.1234 - val_loss: 0.1386\n",
      "Epoch 641/1000\n",
      "3238/3238 [==============================] - 2s 677us/step - loss: 0.1246 - val_loss: 0.1394\n",
      "Epoch 642/1000\n",
      "3238/3238 [==============================] - 2s 662us/step - loss: 0.1268 - val_loss: 0.1378\n",
      "Epoch 643/1000\n",
      "3238/3238 [==============================] - 2s 679us/step - loss: 0.1247 - val_loss: 0.1399\n",
      "Epoch 644/1000\n",
      "3238/3238 [==============================] - 2s 683us/step - loss: 0.1247 - val_loss: 0.1432\n",
      "Epoch 645/1000\n",
      "3238/3238 [==============================] - 2s 687us/step - loss: 0.1257 - val_loss: 0.1363\n",
      "Epoch 646/1000\n",
      "3238/3238 [==============================] - 2s 692us/step - loss: 0.1236 - val_loss: 0.1402\n",
      "Epoch 647/1000\n",
      "3238/3238 [==============================] - 2s 653us/step - loss: 0.1277 - val_loss: 0.1453\n",
      "Epoch 648/1000\n",
      "3238/3238 [==============================] - 2s 684us/step - loss: 0.1278 - val_loss: 0.1372\n",
      "Epoch 649/1000\n",
      "3238/3238 [==============================] - 2s 691us/step - loss: 0.1234 - val_loss: 0.1368\n",
      "Epoch 650/1000\n",
      "3238/3238 [==============================] - 2s 670us/step - loss: 0.1248 - val_loss: 0.1380\n",
      "Epoch 651/1000\n",
      "3238/3238 [==============================] - 2s 697us/step - loss: 0.1258 - val_loss: 0.1371\n",
      "Epoch 652/1000\n",
      "3238/3238 [==============================] - 2s 688us/step - loss: 0.1235 - val_loss: 0.1371\n",
      "Epoch 653/1000\n",
      "3238/3238 [==============================] - 2s 700us/step - loss: 0.1223 - val_loss: 0.1474\n",
      "Epoch 654/1000\n",
      "3238/3238 [==============================] - 2s 691us/step - loss: 0.1269 - val_loss: 0.1359\n",
      "Epoch 655/1000\n",
      "3238/3238 [==============================] - 2s 677us/step - loss: 0.1232 - val_loss: 0.1359\n",
      "Epoch 656/1000\n",
      "3238/3238 [==============================] - 2s 687us/step - loss: 0.1224 - val_loss: 0.1392\n",
      "Epoch 657/1000\n",
      "3238/3238 [==============================] - 2s 691us/step - loss: 0.1241 - val_loss: 0.1367\n",
      "Epoch 658/1000\n",
      "3238/3238 [==============================] - 2s 677us/step - loss: 0.1257 - val_loss: 0.1385\n",
      "Epoch 659/1000\n",
      "3238/3238 [==============================] - 2s 695us/step - loss: 0.1267 - val_loss: 0.1369\n",
      "Epoch 660/1000\n",
      "3238/3238 [==============================] - 2s 684us/step - loss: 0.1258 - val_loss: 0.1498\n",
      "Epoch 661/1000\n",
      "3238/3238 [==============================] - 2s 696us/step - loss: 0.1268 - val_loss: 0.1418\n",
      "Epoch 662/1000\n",
      "3238/3238 [==============================] - 2s 698us/step - loss: 0.1259 - val_loss: 0.1368\n",
      "Epoch 663/1000\n",
      "3238/3238 [==============================] - 2s 673us/step - loss: 0.1223 - val_loss: 0.1352\n",
      "Epoch 664/1000\n",
      "3238/3238 [==============================] - 2s 693us/step - loss: 0.1211 - val_loss: 0.1351\n",
      "Epoch 665/1000\n",
      "3238/3238 [==============================] - 2s 678us/step - loss: 0.1207 - val_loss: 0.1349\n",
      "Epoch 666/1000\n",
      "3238/3238 [==============================] - 2s 688us/step - loss: 0.1219 - val_loss: 0.1349\n",
      "Epoch 667/1000\n",
      "3238/3238 [==============================] - 2s 697us/step - loss: 0.1232 - val_loss: 0.1377\n",
      "Epoch 668/1000\n",
      "3238/3238 [==============================] - 2s 684us/step - loss: 0.1213 - val_loss: 0.1360\n",
      "Epoch 669/1000\n",
      "3238/3238 [==============================] - 2s 735us/step - loss: 0.1212 - val_loss: 0.1393\n",
      "Epoch 670/1000\n",
      "3238/3238 [==============================] - 2s 720us/step - loss: 0.1236 - val_loss: 0.1348\n",
      "Epoch 671/1000\n",
      "3238/3238 [==============================] - 2s 678us/step - loss: 0.1241 - val_loss: 0.1467\n",
      "Epoch 672/1000\n",
      "3238/3238 [==============================] - 2s 683us/step - loss: 0.1247 - val_loss: 0.1346\n",
      "Epoch 673/1000\n",
      "3238/3238 [==============================] - 2s 701us/step - loss: 0.1267 - val_loss: 0.1462\n",
      "Epoch 674/1000\n",
      "3238/3238 [==============================] - 2s 686us/step - loss: 0.1334 - val_loss: 0.1503\n",
      "Epoch 675/1000\n",
      "3238/3238 [==============================] - 2s 701us/step - loss: 0.1334 - val_loss: 0.1404\n",
      "Epoch 676/1000\n",
      "3238/3238 [==============================] - 2s 675us/step - loss: 0.1236 - val_loss: 0.1357\n",
      "Epoch 677/1000\n",
      "3238/3238 [==============================] - 2s 695us/step - loss: 0.1230 - val_loss: 0.1347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 678/1000\n",
      "3238/3238 [==============================] - 2s 703us/step - loss: 0.1218 - val_loss: 0.1343\n",
      "Epoch 679/1000\n",
      "3238/3238 [==============================] - 2s 671us/step - loss: 0.1206 - val_loss: 0.1355\n",
      "Epoch 680/1000\n",
      "3238/3238 [==============================] - 2s 691us/step - loss: 0.1210 - val_loss: 0.1442\n",
      "Epoch 681/1000\n",
      "3238/3238 [==============================] - 2s 666us/step - loss: 0.1230 - val_loss: 0.1361\n",
      "Epoch 682/1000\n",
      "3238/3238 [==============================] - 2s 689us/step - loss: 0.1214 - val_loss: 0.1356\n",
      "Epoch 683/1000\n",
      "3238/3238 [==============================] - 2s 677us/step - loss: 0.1194 - val_loss: 0.1361\n",
      "Epoch 684/1000\n",
      "3238/3238 [==============================] - 2s 651us/step - loss: 0.1192 - val_loss: 0.1360\n",
      "Epoch 685/1000\n",
      "3238/3238 [==============================] - 2s 683us/step - loss: 0.1204 - val_loss: 0.1355\n",
      "Epoch 686/1000\n",
      "3238/3238 [==============================] - 2s 677us/step - loss: 0.1202 - val_loss: 0.1369\n",
      "Epoch 687/1000\n",
      "3238/3238 [==============================] - 3s 969us/step - loss: 0.1204 - val_loss: 0.1440\n",
      "Epoch 688/1000\n",
      "3238/3238 [==============================] - 4s 1ms/step - loss: 0.1230 - val_loss: 0.1349\n",
      "Epoch 689/1000\n",
      "3238/3238 [==============================] - 3s 1ms/step - loss: 0.1193 - val_loss: 0.1405\n",
      "Epoch 690/1000\n",
      "3238/3238 [==============================] - 4s 1ms/step - loss: 0.1203 - val_loss: 0.1360\n",
      "Epoch 691/1000\n",
      "3238/3238 [==============================] - 4s 1ms/step - loss: 0.1209 - val_loss: 0.1408\n",
      "Epoch 692/1000\n",
      "3238/3238 [==============================] - 3s 775us/step - loss: 0.1210 - val_loss: 0.1419\n",
      "Epoch 693/1000\n",
      "3238/3238 [==============================] - 3s 862us/step - loss: 0.1195 - val_loss: 0.1350\n",
      "Epoch 694/1000\n",
      "3238/3238 [==============================] - 3s 1ms/step - loss: 0.1175 - val_loss: 0.1348\n",
      "Epoch 695/1000\n",
      "3238/3238 [==============================] - 2s 673us/step - loss: 0.1182 - val_loss: 0.1351\n",
      "Epoch 696/1000\n",
      "3238/3238 [==============================] - 2s 729us/step - loss: 0.1186 - val_loss: 0.1365\n",
      "Epoch 697/1000\n",
      "3238/3238 [==============================] - 2s 695us/step - loss: 0.1242 - val_loss: 0.1441\n",
      "Epoch 698/1000\n",
      "3238/3238 [==============================] - 2s 730us/step - loss: 0.1222 - val_loss: 0.1347\n",
      "Epoch 699/1000\n",
      "3238/3238 [==============================] - 2s 767us/step - loss: 0.1196 - val_loss: 0.1351\n",
      "Epoch 700/1000\n",
      "3238/3238 [==============================] - 2s 650us/step - loss: 0.1178 - val_loss: 0.1352\n",
      "Epoch 701/1000\n",
      "3238/3238 [==============================] - 2s 707us/step - loss: 0.1187 - val_loss: 0.1348\n",
      "Epoch 702/1000\n",
      "3238/3238 [==============================] - 3s 815us/step - loss: 0.1171 - val_loss: 0.1370\n",
      "Epoch 703/1000\n",
      "3238/3238 [==============================] - 3s 796us/step - loss: 0.1184 - val_loss: 0.1349\n",
      "Epoch 704/1000\n",
      "3238/3238 [==============================] - 2s 682us/step - loss: 0.1179 - val_loss: 0.1387\n",
      "Epoch 705/1000\n",
      "3238/3238 [==============================] - 2s 691us/step - loss: 0.1197 - val_loss: 0.1345\n",
      "Epoch 706/1000\n",
      "3238/3238 [==============================] - 2s 722us/step - loss: 0.1174 - val_loss: 0.1364\n",
      "Epoch 707/1000\n",
      "3238/3238 [==============================] - 2s 685us/step - loss: 0.1179 - val_loss: 0.1398\n",
      "Epoch 708/1000\n",
      "3238/3238 [==============================] - 2s 670us/step - loss: 0.1198 - val_loss: 0.1450\n",
      "Epoch 709/1000\n",
      "3238/3238 [==============================] - 2s 704us/step - loss: 0.1224 - val_loss: 0.1345\n",
      "Epoch 710/1000\n",
      "3238/3238 [==============================] - 2s 679us/step - loss: 0.1236 - val_loss: 0.1467\n",
      "Epoch 711/1000\n",
      "3238/3238 [==============================] - 2s 677us/step - loss: 0.1246 - val_loss: 0.1409\n",
      "Epoch 712/1000\n",
      "3238/3238 [==============================] - 2s 706us/step - loss: 0.1230 - val_loss: 0.1339\n",
      "Epoch 713/1000\n",
      "3238/3238 [==============================] - 2s 668us/step - loss: 0.1219 - val_loss: 0.1328\n",
      "Epoch 714/1000\n",
      "3238/3238 [==============================] - 3s 843us/step - loss: 0.1226 - val_loss: 0.1328\n",
      "Epoch 715/1000\n",
      "3238/3238 [==============================] - 2s 744us/step - loss: 0.1197 - val_loss: 0.1330\n",
      "Epoch 716/1000\n",
      "3238/3238 [==============================] - 3s 983us/step - loss: 0.1167 - val_loss: 0.1404\n",
      "Epoch 717/1000\n",
      "3238/3238 [==============================] - 3s 791us/step - loss: 0.1183 - val_loss: 0.1324\n",
      "Epoch 718/1000\n",
      "3238/3238 [==============================] - 2s 706us/step - loss: 0.1188 - val_loss: 0.1356\n",
      "Epoch 719/1000\n",
      "3238/3238 [==============================] - 2s 715us/step - loss: 0.1197 - val_loss: 0.1356\n",
      "Epoch 720/1000\n",
      "3238/3238 [==============================] - 2s 748us/step - loss: 0.1177 - val_loss: 0.1336\n",
      "Epoch 721/1000\n",
      "3238/3238 [==============================] - 2s 697us/step - loss: 0.1161 - val_loss: 0.1349\n",
      "Epoch 722/1000\n",
      "3238/3238 [==============================] - 2s 696us/step - loss: 0.1163 - val_loss: 0.1336\n",
      "Epoch 723/1000\n",
      "3238/3238 [==============================] - 2s 703us/step - loss: 0.1157 - val_loss: 0.1395\n",
      "Epoch 724/1000\n",
      "3238/3238 [==============================] - 2s 699us/step - loss: 0.1172 - val_loss: 0.1352\n",
      "Epoch 725/1000\n",
      "3238/3238 [==============================] - 2s 717us/step - loss: 0.1170 - val_loss: 0.1346\n",
      "Epoch 726/1000\n",
      "3238/3238 [==============================] - 2s 722us/step - loss: 0.1150 - val_loss: 0.1338\n",
      "Epoch 727/1000\n",
      "3238/3238 [==============================] - 2s 698us/step - loss: 0.1150 - val_loss: 0.1336\n",
      "Epoch 728/1000\n",
      "3238/3238 [==============================] - 2s 716us/step - loss: 0.1180 - val_loss: 0.1342\n",
      "Epoch 729/1000\n",
      "3238/3238 [==============================] - 2s 724us/step - loss: 0.1206 - val_loss: 0.1376\n",
      "Epoch 730/1000\n",
      "3238/3238 [==============================] - 2s 703us/step - loss: 0.1191 - val_loss: 0.1359\n",
      "Epoch 731/1000\n",
      "3238/3238 [==============================] - 2s 726us/step - loss: 0.1184 - val_loss: 0.1392\n",
      "Epoch 732/1000\n",
      "3238/3238 [==============================] - 2s 703us/step - loss: 0.1171 - val_loss: 0.1330\n",
      "Epoch 733/1000\n",
      "3238/3238 [==============================] - 2s 720us/step - loss: 0.1170 - val_loss: 0.1323\n",
      "Epoch 734/1000\n",
      "3238/3238 [==============================] - 2s 719us/step - loss: 0.1164 - val_loss: 0.1341\n",
      "Epoch 735/1000\n",
      "3238/3238 [==============================] - 2s 706us/step - loss: 0.1188 - val_loss: 0.1404\n",
      "Epoch 736/1000\n",
      "3238/3238 [==============================] - 2s 727us/step - loss: 0.1164 - val_loss: 0.1320\n",
      "Epoch 737/1000\n",
      "3238/3238 [==============================] - 2s 718us/step - loss: 0.1147 - val_loss: 0.1364\n",
      "Epoch 738/1000\n",
      "3238/3238 [==============================] - 2s 723us/step - loss: 0.1158 - val_loss: 0.1332\n",
      "Epoch 739/1000\n",
      "3238/3238 [==============================] - 2s 731us/step - loss: 0.1160 - val_loss: 0.1335\n",
      "Epoch 740/1000\n",
      "3238/3238 [==============================] - 2s 705us/step - loss: 0.1153 - val_loss: 0.1331\n",
      "Epoch 741/1000\n",
      "3238/3238 [==============================] - 2s 721us/step - loss: 0.1135 - val_loss: 0.1322\n",
      "Epoch 742/1000\n",
      "3238/3238 [==============================] - 2s 716us/step - loss: 0.1132 - val_loss: 0.1327\n",
      "Epoch 743/1000\n",
      "3238/3238 [==============================] - 2s 754us/step - loss: 0.1136 - val_loss: 0.1351\n",
      "Epoch 744/1000\n",
      "3238/3238 [==============================] - 2s 735us/step - loss: 0.1143 - val_loss: 0.1432\n",
      "Epoch 745/1000\n",
      "3238/3238 [==============================] - 2s 586us/step - loss: 0.1192 - val_loss: 0.1374\n",
      "Epoch 746/1000\n",
      "3238/3238 [==============================] - 2s 637us/step - loss: 0.1164 - val_loss: 0.1319\n",
      "Epoch 747/1000\n",
      "3238/3238 [==============================] - 2s 591us/step - loss: 0.1140 - val_loss: 0.1316\n",
      "Epoch 748/1000\n",
      "3238/3238 [==============================] - 2s 602us/step - loss: 0.1127 - val_loss: 0.1374\n",
      "Epoch 749/1000\n",
      "3238/3238 [==============================] - 2s 604us/step - loss: 0.1146 - val_loss: 0.1320\n",
      "Epoch 750/1000\n",
      "3238/3238 [==============================] - 2s 591us/step - loss: 0.1132 - val_loss: 0.1317\n",
      "Epoch 751/1000\n",
      "3238/3238 [==============================] - 2s 594us/step - loss: 0.1122 - val_loss: 0.1316\n",
      "Epoch 752/1000\n",
      "3238/3238 [==============================] - 2s 597us/step - loss: 0.1150 - val_loss: 0.1328\n",
      "Epoch 753/1000\n",
      "3238/3238 [==============================] - 2s 590us/step - loss: 0.1145 - val_loss: 0.1333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 754/1000\n",
      "3238/3238 [==============================] - 2s 601us/step - loss: 0.1124 - val_loss: 0.1349\n",
      "Epoch 755/1000\n",
      "3238/3238 [==============================] - 2s 622us/step - loss: 0.1148 - val_loss: 0.1370\n",
      "Epoch 756/1000\n",
      "3238/3238 [==============================] - 2s 578us/step - loss: 0.1164 - val_loss: 0.1312\n",
      "Epoch 757/1000\n",
      "3238/3238 [==============================] - 2s 594us/step - loss: 0.1121 - val_loss: 0.1336\n",
      "Epoch 758/1000\n",
      "3238/3238 [==============================] - 2s 584us/step - loss: 0.1131 - val_loss: 0.1320\n",
      "Epoch 759/1000\n",
      "3238/3238 [==============================] - 2s 584us/step - loss: 0.1137 - val_loss: 0.1321\n",
      "Epoch 760/1000\n",
      "3238/3238 [==============================] - 2s 601us/step - loss: 0.1123 - val_loss: 0.1316\n",
      "Epoch 761/1000\n",
      "3238/3238 [==============================] - 2s 578us/step - loss: 0.1153 - val_loss: 0.1357\n",
      "Epoch 762/1000\n",
      "3238/3238 [==============================] - 2s 596us/step - loss: 0.1139 - val_loss: 0.1321\n",
      "Epoch 763/1000\n",
      "3238/3238 [==============================] - 2s 584us/step - loss: 0.1123 - val_loss: 0.1316\n",
      "Epoch 764/1000\n",
      "3238/3238 [==============================] - 2s 581us/step - loss: 0.1119 - val_loss: 0.1312\n",
      "Epoch 765/1000\n",
      "3238/3238 [==============================] - 2s 577us/step - loss: 0.1112 - val_loss: 0.1336\n",
      "Epoch 766/1000\n",
      "3238/3238 [==============================] - 2s 580us/step - loss: 0.1125 - val_loss: 0.1325\n",
      "Epoch 767/1000\n",
      "3238/3238 [==============================] - 2s 584us/step - loss: 0.1120 - val_loss: 0.1321\n",
      "Epoch 768/1000\n",
      "3238/3238 [==============================] - 2s 585us/step - loss: 0.1120 - val_loss: 0.1362\n",
      "Epoch 769/1000\n",
      "3238/3238 [==============================] - 2s 576us/step - loss: 0.1154 - val_loss: 0.1329\n",
      "Epoch 770/1000\n",
      "3238/3238 [==============================] - 2s 584us/step - loss: 0.1145 - val_loss: 0.1302\n",
      "Epoch 771/1000\n",
      "3238/3238 [==============================] - 2s 581us/step - loss: 0.1107 - val_loss: 0.1301\n",
      "Epoch 772/1000\n",
      "3238/3238 [==============================] - 2s 595us/step - loss: 0.1108 - val_loss: 0.1322\n",
      "Epoch 773/1000\n",
      "3238/3238 [==============================] - 2s 586us/step - loss: 0.1130 - val_loss: 0.1367\n",
      "Epoch 774/1000\n",
      "3238/3238 [==============================] - 2s 585us/step - loss: 0.1146 - val_loss: 0.1335\n",
      "Epoch 775/1000\n",
      "3238/3238 [==============================] - 2s 581us/step - loss: 0.1120 - val_loss: 0.1305\n",
      "Epoch 776/1000\n",
      "3238/3238 [==============================] - 2s 585us/step - loss: 0.1108 - val_loss: 0.1323\n",
      "Epoch 777/1000\n",
      "3238/3238 [==============================] - 2s 583us/step - loss: 0.1125 - val_loss: 0.1306\n",
      "Epoch 778/1000\n",
      "3238/3238 [==============================] - 2s 593us/step - loss: 0.1111 - val_loss: 0.1306\n",
      "Epoch 779/1000\n",
      "3238/3238 [==============================] - 2s 586us/step - loss: 0.1113 - val_loss: 0.1304\n",
      "Epoch 780/1000\n",
      "3238/3238 [==============================] - 2s 584us/step - loss: 0.1114 - val_loss: 0.1313\n",
      "Epoch 781/1000\n",
      "3238/3238 [==============================] - 2s 590us/step - loss: 0.1105 - val_loss: 0.1304\n",
      "Epoch 782/1000\n",
      "3238/3238 [==============================] - 2s 572us/step - loss: 0.1098 - val_loss: 0.1357\n",
      "Epoch 783/1000\n",
      "3238/3238 [==============================] - 2s 597us/step - loss: 0.1105 - val_loss: 0.1309\n",
      "Epoch 784/1000\n",
      "3238/3238 [==============================] - 2s 595us/step - loss: 0.1097 - val_loss: 0.1314\n",
      "Epoch 785/1000\n",
      "3238/3238 [==============================] - 2s 589us/step - loss: 0.1093 - val_loss: 0.1357\n",
      "Epoch 786/1000\n",
      "3238/3238 [==============================] - 2s 594us/step - loss: 0.1096 - val_loss: 0.1374\n",
      "Epoch 787/1000\n",
      "3238/3238 [==============================] - 2s 580us/step - loss: 0.1128 - val_loss: 0.1365\n",
      "Epoch 788/1000\n",
      "3238/3238 [==============================] - 2s 587us/step - loss: 0.1121 - val_loss: 0.1309\n",
      "Epoch 789/1000\n",
      "3238/3238 [==============================] - 2s 595us/step - loss: 0.1098 - val_loss: 0.1305\n",
      "Epoch 790/1000\n",
      "3238/3238 [==============================] - 2s 579us/step - loss: 0.1105 - val_loss: 0.1385\n",
      "Epoch 791/1000\n",
      "3238/3238 [==============================] - 2s 595us/step - loss: 0.1158 - val_loss: 0.1303\n",
      "Epoch 792/1000\n",
      "3238/3238 [==============================] - 2s 594us/step - loss: 0.1126 - val_loss: 0.1312\n",
      "Epoch 793/1000\n",
      "3238/3238 [==============================] - 2s 582us/step - loss: 0.1117 - val_loss: 0.1305\n",
      "Epoch 794/1000\n",
      "3238/3238 [==============================] - 2s 584us/step - loss: 0.1095 - val_loss: 0.1303\n",
      "Epoch 795/1000\n",
      "3238/3238 [==============================] - 2s 575us/step - loss: 0.1134 - val_loss: 0.1307\n",
      "Epoch 796/1000\n",
      "3238/3238 [==============================] - 2s 584us/step - loss: 0.1116 - val_loss: 0.1507\n",
      "Epoch 797/1000\n",
      "3238/3238 [==============================] - 2s 581us/step - loss: 0.1149 - val_loss: 0.1294\n",
      "Epoch 798/1000\n",
      "3238/3238 [==============================] - 2s 616us/step - loss: 0.1097 - val_loss: 0.1293\n",
      "Epoch 799/1000\n",
      "3238/3238 [==============================] - 2s 591us/step - loss: 0.1097 - val_loss: 0.1317\n",
      "Epoch 800/1000\n",
      "3238/3238 [==============================] - 2s 585us/step - loss: 0.1092 - val_loss: 0.1310\n",
      "Epoch 801/1000\n",
      "3238/3238 [==============================] - 2s 597us/step - loss: 0.1090 - val_loss: 0.1297\n",
      "Epoch 802/1000\n",
      "3238/3238 [==============================] - 2s 582us/step - loss: 0.1093 - val_loss: 0.1304\n",
      "Epoch 803/1000\n",
      "3238/3238 [==============================] - 2s 581us/step - loss: 0.1106 - val_loss: 0.1309\n",
      "Epoch 804/1000\n",
      "3238/3238 [==============================] - 2s 588us/step - loss: 0.1089 - val_loss: 0.1359\n",
      "Epoch 805/1000\n",
      "3238/3238 [==============================] - 2s 621us/step - loss: 0.1113 - val_loss: 0.1296\n",
      "Epoch 806/1000\n",
      "3238/3238 [==============================] - 2s 583us/step - loss: 0.1081 - val_loss: 0.1309\n",
      "Epoch 807/1000\n",
      "3238/3238 [==============================] - 2s 584us/step - loss: 0.1086 - val_loss: 0.1329\n",
      "Epoch 808/1000\n",
      "3238/3238 [==============================] - 2s 578us/step - loss: 0.1101 - val_loss: 0.1339\n",
      "Epoch 809/1000\n",
      "3238/3238 [==============================] - 2s 590us/step - loss: 0.1088 - val_loss: 0.1326\n",
      "Epoch 810/1000\n",
      "3238/3238 [==============================] - 2s 597us/step - loss: 0.1076 - val_loss: 0.1314\n",
      "Epoch 811/1000\n",
      "3238/3238 [==============================] - 2s 573us/step - loss: 0.1081 - val_loss: 0.1298\n",
      "Epoch 812/1000\n",
      "3238/3238 [==============================] - 2s 593us/step - loss: 0.1073 - val_loss: 0.1317\n",
      "Epoch 813/1000\n",
      "3238/3238 [==============================] - 2s 593us/step - loss: 0.1070 - val_loss: 0.1309\n",
      "Epoch 814/1000\n",
      "3238/3238 [==============================] - 2s 593us/step - loss: 0.1085 - val_loss: 0.1339\n",
      "Epoch 815/1000\n",
      "3238/3238 [==============================] - 2s 586us/step - loss: 0.1136 - val_loss: 0.1356\n",
      "Epoch 816/1000\n",
      "3238/3238 [==============================] - 2s 589us/step - loss: 0.1125 - val_loss: 0.1313\n",
      "Epoch 817/1000\n",
      "3238/3238 [==============================] - 2s 581us/step - loss: 0.1096 - val_loss: 0.1283\n",
      "Epoch 818/1000\n",
      "3238/3238 [==============================] - 2s 593us/step - loss: 0.1070 - val_loss: 0.1288\n",
      "Epoch 819/1000\n",
      "3238/3238 [==============================] - 2s 582us/step - loss: 0.1084 - val_loss: 0.1294\n",
      "Epoch 820/1000\n",
      "3238/3238 [==============================] - 2s 589us/step - loss: 0.1070 - val_loss: 0.1295\n",
      "Epoch 821/1000\n",
      "3238/3238 [==============================] - 2s 595us/step - loss: 0.1084 - val_loss: 0.1337\n",
      "Epoch 822/1000\n",
      "3238/3238 [==============================] - 2s 572us/step - loss: 0.1117 - val_loss: 0.1335\n",
      "Epoch 823/1000\n",
      "3238/3238 [==============================] - 2s 587us/step - loss: 0.1121 - val_loss: 0.1290\n",
      "Epoch 824/1000\n",
      "3238/3238 [==============================] - 2s 579us/step - loss: 0.1103 - val_loss: 0.1372\n",
      "Epoch 825/1000\n",
      "3238/3238 [==============================] - 2s 584us/step - loss: 0.1133 - val_loss: 0.1343\n",
      "Epoch 826/1000\n",
      "3238/3238 [==============================] - 2s 597us/step - loss: 0.1109 - val_loss: 0.1364\n",
      "Epoch 827/1000\n",
      "3238/3238 [==============================] - 2s 592us/step - loss: 0.1083 - val_loss: 0.1291\n",
      "Epoch 828/1000\n",
      "3238/3238 [==============================] - 2s 592us/step - loss: 0.1070 - val_loss: 0.1283\n",
      "Epoch 829/1000\n",
      "3238/3238 [==============================] - 2s 588us/step - loss: 0.1070 - val_loss: 0.1304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 830/1000\n",
      "3238/3238 [==============================] - 2s 581us/step - loss: 0.1074 - val_loss: 0.1379\n",
      "Epoch 831/1000\n",
      "3238/3238 [==============================] - 2s 584us/step - loss: 0.1082 - val_loss: 0.1309\n",
      "Epoch 832/1000\n",
      "3238/3238 [==============================] - 2s 578us/step - loss: 0.1066 - val_loss: 0.1319\n",
      "Epoch 833/1000\n",
      "3238/3238 [==============================] - 2s 589us/step - loss: 0.1092 - val_loss: 0.1306\n",
      "Epoch 834/1000\n",
      "3238/3238 [==============================] - 2s 592us/step - loss: 0.1072 - val_loss: 0.1293\n",
      "Epoch 835/1000\n",
      "3238/3238 [==============================] - 2s 583us/step - loss: 0.1081 - val_loss: 0.1294\n",
      "Epoch 836/1000\n",
      "3238/3238 [==============================] - 2s 582us/step - loss: 0.1080 - val_loss: 0.1297\n",
      "Epoch 837/1000\n",
      "3238/3238 [==============================] - 2s 584us/step - loss: 0.1061 - val_loss: 0.1287\n",
      "Epoch 838/1000\n",
      "3238/3238 [==============================] - 2s 590us/step - loss: 0.1055 - val_loss: 0.1298\n",
      "Epoch 839/1000\n",
      "3238/3238 [==============================] - 2s 588us/step - loss: 0.1068 - val_loss: 0.1324\n",
      "Epoch 840/1000\n",
      "3238/3238 [==============================] - 2s 583us/step - loss: 0.1070 - val_loss: 0.1300\n",
      "Epoch 841/1000\n",
      "3238/3238 [==============================] - 2s 584us/step - loss: 0.1069 - val_loss: 0.1294\n",
      "Epoch 842/1000\n",
      "3238/3238 [==============================] - 2s 593us/step - loss: 0.1055 - val_loss: 0.1382\n",
      "Epoch 843/1000\n",
      "3238/3238 [==============================] - 2s 563us/step - loss: 0.1087 - val_loss: 0.1295\n",
      "Epoch 844/1000\n",
      "3238/3238 [==============================] - 2s 578us/step - loss: 0.1072 - val_loss: 0.1340\n",
      "Epoch 845/1000\n",
      "3238/3238 [==============================] - 2s 574us/step - loss: 0.1081 - val_loss: 0.1301\n",
      "Epoch 846/1000\n",
      "3238/3238 [==============================] - 2s 590us/step - loss: 0.1076 - val_loss: 0.1309\n",
      "Epoch 847/1000\n",
      "3238/3238 [==============================] - 2s 588us/step - loss: 0.1055 - val_loss: 0.1289\n",
      "Epoch 848/1000\n",
      "3238/3238 [==============================] - 2s 567us/step - loss: 0.1055 - val_loss: 0.1292\n",
      "Epoch 849/1000\n",
      "3238/3238 [==============================] - 2s 585us/step - loss: 0.1069 - val_loss: 0.1415\n",
      "Epoch 850/1000\n",
      "3238/3238 [==============================] - 2s 587us/step - loss: 0.1137 - val_loss: 0.1325\n",
      "Epoch 851/1000\n",
      "3238/3238 [==============================] - 2s 615us/step - loss: 0.1080 - val_loss: 0.1320\n",
      "Epoch 852/1000\n",
      "3238/3238 [==============================] - 2s 584us/step - loss: 0.1061 - val_loss: 0.1277\n",
      "Epoch 853/1000\n",
      "3238/3238 [==============================] - 2s 579us/step - loss: 0.1047 - val_loss: 0.1289\n",
      "Epoch 854/1000\n",
      "3238/3238 [==============================] - 2s 603us/step - loss: 0.1046 - val_loss: 0.1290\n",
      "Epoch 855/1000\n",
      "3238/3238 [==============================] - 2s 594us/step - loss: 0.1041 - val_loss: 0.1296\n",
      "Epoch 856/1000\n",
      "3238/3238 [==============================] - 2s 575us/step - loss: 0.1062 - val_loss: 0.1327\n",
      "Epoch 857/1000\n",
      "3238/3238 [==============================] - 2s 590us/step - loss: 0.1045 - val_loss: 0.1289\n",
      "Epoch 858/1000\n",
      "3238/3238 [==============================] - 2s 592us/step - loss: 0.1053 - val_loss: 0.1487\n",
      "Epoch 859/1000\n",
      "3238/3238 [==============================] - 2s 584us/step - loss: 0.1119 - val_loss: 0.1362\n",
      "Epoch 860/1000\n",
      "3238/3238 [==============================] - 2s 598us/step - loss: 0.1112 - val_loss: 0.1280\n",
      "Epoch 861/1000\n",
      "3238/3238 [==============================] - 2s 580us/step - loss: 0.1075 - val_loss: 0.1311\n",
      "Epoch 862/1000\n",
      "3238/3238 [==============================] - 2s 597us/step - loss: 0.1064 - val_loss: 0.1285\n",
      "Epoch 863/1000\n",
      "3238/3238 [==============================] - 2s 598us/step - loss: 0.1042 - val_loss: 0.1299\n",
      "Epoch 864/1000\n",
      "3238/3238 [==============================] - 2s 577us/step - loss: 0.1036 - val_loss: 0.1293\n",
      "Epoch 865/1000\n",
      "3238/3238 [==============================] - 2s 595us/step - loss: 0.1039 - val_loss: 0.1303\n",
      "Epoch 866/1000\n",
      "3238/3238 [==============================] - 2s 580us/step - loss: 0.1034 - val_loss: 0.1291\n",
      "Epoch 867/1000\n",
      "3238/3238 [==============================] - 2s 587us/step - loss: 0.1044 - val_loss: 0.1287\n",
      "Epoch 868/1000\n",
      "3238/3238 [==============================] - 2s 591us/step - loss: 0.1039 - val_loss: 0.1291\n",
      "Epoch 869/1000\n",
      "3238/3238 [==============================] - 2s 587us/step - loss: 0.1032 - val_loss: 0.1288\n",
      "Epoch 870/1000\n",
      "3238/3238 [==============================] - 2s 594us/step - loss: 0.1034 - val_loss: 0.1380\n",
      "Epoch 871/1000\n",
      "3238/3238 [==============================] - 2s 600us/step - loss: 0.1046 - val_loss: 0.1292\n",
      "Epoch 872/1000\n",
      "3238/3238 [==============================] - 2s 589us/step - loss: 0.1039 - val_loss: 0.1288\n",
      "Epoch 873/1000\n",
      "3238/3238 [==============================] - 2s 583us/step - loss: 0.1028 - val_loss: 0.1296\n",
      "Epoch 874/1000\n",
      "3238/3238 [==============================] - 2s 588us/step - loss: 0.1036 - val_loss: 0.1318\n",
      "Epoch 875/1000\n",
      "3238/3238 [==============================] - 2s 594us/step - loss: 0.1051 - val_loss: 0.1310\n",
      "Epoch 876/1000\n",
      "3238/3238 [==============================] - 2s 590us/step - loss: 0.1041 - val_loss: 0.1329\n",
      "Epoch 877/1000\n",
      "3238/3238 [==============================] - 2s 585us/step - loss: 0.1045 - val_loss: 0.1339\n",
      "Epoch 878/1000\n",
      "3238/3238 [==============================] - 2s 588us/step - loss: 0.1036 - val_loss: 0.1285\n",
      "Epoch 879/1000\n",
      "3238/3238 [==============================] - 2s 588us/step - loss: 0.1022 - val_loss: 0.1291\n",
      "Epoch 880/1000\n",
      "3238/3238 [==============================] - 2s 590us/step - loss: 0.1019 - val_loss: 0.1281\n",
      "Epoch 881/1000\n",
      "3238/3238 [==============================] - 2s 586us/step - loss: 0.1018 - val_loss: 0.1291\n",
      "Epoch 882/1000\n",
      "3238/3238 [==============================] - 2s 584us/step - loss: 0.1031 - val_loss: 0.1297\n",
      "Epoch 883/1000\n",
      "3238/3238 [==============================] - 2s 592us/step - loss: 0.1071 - val_loss: 0.1280\n",
      "Epoch 884/1000\n",
      "3238/3238 [==============================] - 2s 594us/step - loss: 0.1046 - val_loss: 0.1339\n",
      "Epoch 885/1000\n",
      "3238/3238 [==============================] - 2s 581us/step - loss: 0.1053 - val_loss: 0.1274\n",
      "Epoch 886/1000\n",
      "3238/3238 [==============================] - 2s 594us/step - loss: 0.1052 - val_loss: 0.1306\n",
      "Epoch 887/1000\n",
      "3238/3238 [==============================] - 2s 591us/step - loss: 0.1028 - val_loss: 0.1285\n",
      "Epoch 888/1000\n",
      "3238/3238 [==============================] - 2s 585us/step - loss: 0.1038 - val_loss: 0.1363\n",
      "Epoch 889/1000\n",
      "3238/3238 [==============================] - 2s 592us/step - loss: 0.1037 - val_loss: 0.1299\n",
      "Epoch 890/1000\n",
      "3238/3238 [==============================] - 2s 583us/step - loss: 0.1019 - val_loss: 0.1284\n",
      "Epoch 891/1000\n",
      "3238/3238 [==============================] - 2s 581us/step - loss: 0.1021 - val_loss: 0.1332\n",
      "Epoch 892/1000\n",
      "3238/3238 [==============================] - 2s 588us/step - loss: 0.1036 - val_loss: 0.1330\n",
      "Epoch 893/1000\n",
      "3238/3238 [==============================] - 2s 575us/step - loss: 0.1039 - val_loss: 0.1278\n",
      "Epoch 894/1000\n",
      "3238/3238 [==============================] - 2s 584us/step - loss: 0.1028 - val_loss: 0.1358\n",
      "Epoch 895/1000\n",
      "3238/3238 [==============================] - 2s 590us/step - loss: 0.1049 - val_loss: 0.1309\n",
      "Epoch 896/1000\n",
      "3238/3238 [==============================] - 2s 579us/step - loss: 0.1019 - val_loss: 0.1291\n",
      "Epoch 897/1000\n",
      "3238/3238 [==============================] - 2s 593us/step - loss: 0.1033 - val_loss: 0.1297\n",
      "Epoch 898/1000\n",
      "3238/3238 [==============================] - 2s 585us/step - loss: 0.1028 - val_loss: 0.1299\n",
      "Epoch 899/1000\n",
      "3238/3238 [==============================] - 2s 594us/step - loss: 0.1009 - val_loss: 0.1284\n",
      "Epoch 900/1000\n",
      "3238/3238 [==============================] - 2s 594us/step - loss: 0.1033 - val_loss: 0.1557\n",
      "Epoch 901/1000\n",
      "3238/3238 [==============================] - 2s 583us/step - loss: 0.1114 - val_loss: 0.1323\n",
      "Epoch 902/1000\n",
      "3238/3238 [==============================] - 2s 590us/step - loss: 0.1055 - val_loss: 0.1266\n",
      "Epoch 903/1000\n",
      "3238/3238 [==============================] - 2s 584us/step - loss: 0.1058 - val_loss: 0.1354\n",
      "Epoch 904/1000\n",
      "3238/3238 [==============================] - 2s 566us/step - loss: 0.1073 - val_loss: 0.1281\n",
      "Epoch 905/1000\n",
      "3238/3238 [==============================] - 2s 595us/step - loss: 0.1043 - val_loss: 0.1260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 906/1000\n",
      "3238/3238 [==============================] - 2s 574us/step - loss: 0.1028 - val_loss: 0.1302\n",
      "Epoch 907/1000\n",
      "3238/3238 [==============================] - 2s 605us/step - loss: 0.1013 - val_loss: 0.1275\n",
      "Epoch 908/1000\n",
      "3238/3238 [==============================] - 2s 586us/step - loss: 0.1009 - val_loss: 0.1304\n",
      "Epoch 909/1000\n",
      "3238/3238 [==============================] - 2s 578us/step - loss: 0.1013 - val_loss: 0.1295\n",
      "Epoch 910/1000\n",
      "3238/3238 [==============================] - 2s 581us/step - loss: 0.1025 - val_loss: 0.1276\n",
      "Epoch 911/1000\n",
      "3238/3238 [==============================] - 2s 583us/step - loss: 0.1014 - val_loss: 0.1357\n",
      "Epoch 912/1000\n",
      "3238/3238 [==============================] - 2s 578us/step - loss: 0.1017 - val_loss: 0.1304\n",
      "Epoch 913/1000\n",
      "3238/3238 [==============================] - 2s 592us/step - loss: 0.1023 - val_loss: 0.1284\n",
      "Epoch 914/1000\n",
      "3238/3238 [==============================] - 2s 578us/step - loss: 0.1012 - val_loss: 0.1359\n",
      "Epoch 915/1000\n",
      "3238/3238 [==============================] - 2s 585us/step - loss: 0.1018 - val_loss: 0.1277\n",
      "Epoch 916/1000\n",
      "3238/3238 [==============================] - 2s 591us/step - loss: 0.0998 - val_loss: 0.1290\n",
      "Epoch 917/1000\n",
      "3238/3238 [==============================] - 2s 569us/step - loss: 0.1028 - val_loss: 0.1282\n",
      "Epoch 918/1000\n",
      "3238/3238 [==============================] - 2s 595us/step - loss: 0.0992 - val_loss: 0.1335\n",
      "Epoch 919/1000\n",
      "3238/3238 [==============================] - 2s 585us/step - loss: 0.1036 - val_loss: 0.1328\n",
      "Epoch 920/1000\n",
      "3238/3238 [==============================] - 2s 586us/step - loss: 0.1053 - val_loss: 0.1455\n",
      "Epoch 921/1000\n",
      "3238/3238 [==============================] - 2s 583us/step - loss: 0.1067 - val_loss: 0.1271\n",
      "Epoch 922/1000\n",
      "3238/3238 [==============================] - 2s 569us/step - loss: 0.1015 - val_loss: 0.1264\n",
      "Epoch 923/1000\n",
      "3238/3238 [==============================] - 2s 584us/step - loss: 0.1020 - val_loss: 0.1278\n",
      "Epoch 924/1000\n",
      "3238/3238 [==============================] - 2s 587us/step - loss: 0.1005 - val_loss: 0.1296\n",
      "Epoch 925/1000\n",
      "3238/3238 [==============================] - 2s 574us/step - loss: 0.1005 - val_loss: 0.1272\n",
      "Epoch 926/1000\n",
      "3238/3238 [==============================] - 2s 588us/step - loss: 0.0998 - val_loss: 0.1297\n",
      "Epoch 927/1000\n",
      "3238/3238 [==============================] - 2s 572us/step - loss: 0.1030 - val_loss: 0.1387\n",
      "Epoch 928/1000\n",
      "3238/3238 [==============================] - 2s 588us/step - loss: 0.1034 - val_loss: 0.1348\n",
      "Epoch 929/1000\n",
      "3238/3238 [==============================] - 2s 595us/step - loss: 0.1028 - val_loss: 0.1265\n",
      "Epoch 930/1000\n",
      "3238/3238 [==============================] - 2s 585us/step - loss: 0.0990 - val_loss: 0.1278\n",
      "Epoch 931/1000\n",
      "3238/3238 [==============================] - 2s 592us/step - loss: 0.1001 - val_loss: 0.1352\n",
      "Epoch 932/1000\n",
      "3238/3238 [==============================] - 2s 594us/step - loss: 0.1017 - val_loss: 0.1288\n",
      "Epoch 933/1000\n",
      "3238/3238 [==============================] - 2s 589us/step - loss: 0.0997 - val_loss: 0.1285\n",
      "Epoch 934/1000\n",
      "3238/3238 [==============================] - 2s 602us/step - loss: 0.0988 - val_loss: 0.1293\n",
      "Epoch 935/1000\n",
      "3238/3238 [==============================] - 2s 587us/step - loss: 0.1002 - val_loss: 0.1279\n",
      "Epoch 936/1000\n",
      "3238/3238 [==============================] - 2s 578us/step - loss: 0.0981 - val_loss: 0.1330\n",
      "Epoch 937/1000\n",
      "3238/3238 [==============================] - 2s 590us/step - loss: 0.0988 - val_loss: 0.1290\n",
      "Epoch 938/1000\n",
      "3238/3238 [==============================] - 2s 575us/step - loss: 0.0983 - val_loss: 0.1284\n",
      "Epoch 939/1000\n",
      "3238/3238 [==============================] - 2s 600us/step - loss: 0.0987 - val_loss: 0.1329\n",
      "Epoch 940/1000\n",
      "3238/3238 [==============================] - 2s 581us/step - loss: 0.1000 - val_loss: 0.1277\n",
      "Epoch 941/1000\n",
      "3238/3238 [==============================] - 2s 581us/step - loss: 0.0994 - val_loss: 0.1282\n",
      "Epoch 942/1000\n",
      "3238/3238 [==============================] - 2s 590us/step - loss: 0.1002 - val_loss: 0.1337\n",
      "Epoch 943/1000\n",
      "3238/3238 [==============================] - 2s 581us/step - loss: 0.1040 - val_loss: 0.1309\n",
      "Epoch 944/1000\n",
      "3238/3238 [==============================] - 2s 587us/step - loss: 0.1018 - val_loss: 0.1287\n",
      "Epoch 945/1000\n",
      "3238/3238 [==============================] - 2s 587us/step - loss: 0.0997 - val_loss: 0.1288\n",
      "Epoch 946/1000\n",
      "3238/3238 [==============================] - 2s 566us/step - loss: 0.0990 - val_loss: 0.1324\n",
      "Epoch 947/1000\n",
      "3238/3238 [==============================] - 2s 588us/step - loss: 0.1029 - val_loss: 0.1320\n",
      "Epoch 948/1000\n",
      "3238/3238 [==============================] - 2s 578us/step - loss: 0.1010 - val_loss: 0.1293\n",
      "Epoch 949/1000\n",
      "3238/3238 [==============================] - 2s 574us/step - loss: 0.0995 - val_loss: 0.1372\n",
      "Epoch 950/1000\n",
      "3238/3238 [==============================] - 2s 597us/step - loss: 0.1051 - val_loss: 0.1443\n",
      "Epoch 951/1000\n",
      "3238/3238 [==============================] - 2s 569us/step - loss: 0.1065 - val_loss: 0.1283\n",
      "Epoch 952/1000\n",
      "3238/3238 [==============================] - 2s 591us/step - loss: 0.1035 - val_loss: 0.1391\n",
      "Epoch 953/1000\n",
      "3238/3238 [==============================] - 2s 624us/step - loss: 0.1055 - val_loss: 0.1322\n",
      "Epoch 954/1000\n",
      "3238/3238 [==============================] - 2s 575us/step - loss: 0.1015 - val_loss: 0.1293\n",
      "Epoch 955/1000\n",
      "3238/3238 [==============================] - 2s 591us/step - loss: 0.0997 - val_loss: 0.1271\n",
      "Epoch 956/1000\n",
      "3238/3238 [==============================] - 2s 582us/step - loss: 0.0986 - val_loss: 0.1294\n",
      "Epoch 957/1000\n",
      "3238/3238 [==============================] - 2s 585us/step - loss: 0.0980 - val_loss: 0.1272\n",
      "Epoch 958/1000\n",
      "3238/3238 [==============================] - 2s 594us/step - loss: 0.0972 - val_loss: 0.1306\n",
      "Epoch 959/1000\n",
      "3238/3238 [==============================] - 2s 578us/step - loss: 0.0978 - val_loss: 0.1290\n",
      "Epoch 960/1000\n",
      "3238/3238 [==============================] - 2s 592us/step - loss: 0.0967 - val_loss: 0.1296\n",
      "Epoch 961/1000\n",
      "3238/3238 [==============================] - 2s 589us/step - loss: 0.0982 - val_loss: 0.1344\n",
      "Epoch 962/1000\n",
      "3238/3238 [==============================] - 2s 609us/step - loss: 0.0997 - val_loss: 0.1272\n",
      "Epoch 963/1000\n",
      "3238/3238 [==============================] - 2s 586us/step - loss: 0.0992 - val_loss: 0.1327\n",
      "Epoch 964/1000\n",
      "3238/3238 [==============================] - 2s 575us/step - loss: 0.0990 - val_loss: 0.1376\n",
      "Epoch 965/1000\n",
      "3238/3238 [==============================] - 2s 584us/step - loss: 0.1020 - val_loss: 0.1331\n",
      "Epoch 966/1000\n",
      "3238/3238 [==============================] - 2s 596us/step - loss: 0.0980 - val_loss: 0.1273\n",
      "Epoch 967/1000\n",
      "3238/3238 [==============================] - 2s 583us/step - loss: 0.0974 - val_loss: 0.1309\n",
      "Epoch 968/1000\n",
      "3238/3238 [==============================] - 2s 593us/step - loss: 0.0970 - val_loss: 0.1293\n",
      "Epoch 969/1000\n",
      "3238/3238 [==============================] - 2s 587us/step - loss: 0.0970 - val_loss: 0.1279\n",
      "Epoch 970/1000\n",
      "3238/3238 [==============================] - 2s 586us/step - loss: 0.0965 - val_loss: 0.1299\n",
      "Epoch 971/1000\n",
      "3238/3238 [==============================] - 2s 590us/step - loss: 0.0992 - val_loss: 0.1295\n",
      "Epoch 972/1000\n",
      "3238/3238 [==============================] - 2s 586us/step - loss: 0.0970 - val_loss: 0.1292\n",
      "Epoch 973/1000\n",
      "3238/3238 [==============================] - 2s 583us/step - loss: 0.0962 - val_loss: 0.1307\n",
      "Epoch 974/1000\n",
      "3238/3238 [==============================] - 2s 603us/step - loss: 0.0955 - val_loss: 0.1293\n",
      "Epoch 975/1000\n",
      "3238/3238 [==============================] - 2s 570us/step - loss: 0.0975 - val_loss: 0.1331\n",
      "Epoch 976/1000\n",
      "3238/3238 [==============================] - 2s 597us/step - loss: 0.1005 - val_loss: 0.1298\n",
      "Epoch 977/1000\n",
      "3238/3238 [==============================] - 2s 581us/step - loss: 0.1038 - val_loss: 0.1264\n",
      "Epoch 978/1000\n",
      "3238/3238 [==============================] - 2s 585us/step - loss: 0.0983 - val_loss: 0.1272\n",
      "Epoch 979/1000\n",
      "3238/3238 [==============================] - 2s 597us/step - loss: 0.0963 - val_loss: 0.1272\n",
      "Epoch 980/1000\n",
      "3238/3238 [==============================] - 2s 577us/step - loss: 0.0965 - val_loss: 0.1284\n",
      "Epoch 981/1000\n",
      "3238/3238 [==============================] - 2s 599us/step - loss: 0.0957 - val_loss: 0.1288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 982/1000\n",
      "3238/3238 [==============================] - 2s 585us/step - loss: 0.0957 - val_loss: 0.1289\n",
      "Epoch 983/1000\n",
      "3238/3238 [==============================] - 2s 572us/step - loss: 0.0966 - val_loss: 0.1286\n",
      "Epoch 984/1000\n",
      "3238/3238 [==============================] - 2s 591us/step - loss: 0.0959 - val_loss: 0.1279\n",
      "Epoch 985/1000\n",
      "3238/3238 [==============================] - 2s 581us/step - loss: 0.0957 - val_loss: 0.1298\n",
      "Epoch 986/1000\n",
      "3238/3238 [==============================] - 2s 582us/step - loss: 0.0963 - val_loss: 0.1275\n",
      "Epoch 987/1000\n",
      "3238/3238 [==============================] - 2s 587us/step - loss: 0.0964 - val_loss: 0.1321\n",
      "Epoch 988/1000\n",
      "3238/3238 [==============================] - 2s 576us/step - loss: 0.0969 - val_loss: 0.1276\n",
      "Epoch 989/1000\n",
      "3238/3238 [==============================] - 2s 584us/step - loss: 0.0949 - val_loss: 0.1283\n",
      "Epoch 990/1000\n",
      "3238/3238 [==============================] - 2s 578us/step - loss: 0.0944 - val_loss: 0.1312\n",
      "Epoch 991/1000\n",
      "3238/3238 [==============================] - 2s 575us/step - loss: 0.0952 - val_loss: 0.1321\n",
      "Epoch 992/1000\n",
      "3238/3238 [==============================] - 2s 582us/step - loss: 0.0949 - val_loss: 0.1278\n",
      "Epoch 993/1000\n",
      "3238/3238 [==============================] - 2s 583us/step - loss: 0.0945 - val_loss: 0.1319\n",
      "Epoch 994/1000\n",
      "3238/3238 [==============================] - 2s 592us/step - loss: 0.0974 - val_loss: 0.1278\n",
      "Epoch 995/1000\n",
      "3238/3238 [==============================] - 2s 594us/step - loss: 0.0969 - val_loss: 0.1303\n",
      "Epoch 996/1000\n",
      "3238/3238 [==============================] - 2s 580us/step - loss: 0.0961 - val_loss: 0.1332\n",
      "Epoch 997/1000\n",
      "3238/3238 [==============================] - 2s 578us/step - loss: 0.1004 - val_loss: 0.1430\n",
      "Epoch 998/1000\n",
      "3238/3238 [==============================] - 2s 581us/step - loss: 0.0975 - val_loss: 0.1288\n",
      "Epoch 999/1000\n",
      "3238/3238 [==============================] - 2s 581us/step - loss: 0.0994 - val_loss: 0.1408\n",
      "Epoch 1000/1000\n",
      "3238/3238 [==============================] - 2s 587us/step - loss: 0.0981 - val_loss: 0.1261\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(adam_lr)):\n",
    "    lr = adam_lr[i]\n",
    "    for j in range(len(initializers)):\n",
    "        initializer = initializers[j]\n",
    "        print(f'adam_lr - {lr} initializer - {initializer}')\n",
    "\n",
    "        optimizer = Adam(lr = lr)\n",
    "        model = get_model_biLSTM_attention(initializer, LSTM_size)\n",
    "        model.compile(optimizer = optimizer,\n",
    "                     loss = 'mean_squared_error')\n",
    "        # early_stopping = EarlyStopping(patience = 300)\n",
    "\n",
    "        folder_path = 'Kka2/model_and_checkpoints/' + f'biLSTM attention LSTM size - {LSTM_size} epochs - {n_epochs} adam_lr {lr} initializer - {initializer}'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "        checkpointing = ModelCheckpoint(folder_path + '/weights.{epoch:02d}-{val_loss:.5f}.hdf5',\n",
    "                               save_best_only = True)\n",
    "        history = model.fit(X_train, y_train, validation_data = (X_val, y_val), \n",
    "                            batch_size = 512, epochs = n_epochs, verbose = 1,\n",
    "                            callbacks = [checkpointing])\n",
    "\n",
    "# save the model summary\n",
    "#         model_json = model.to_json()\n",
    "#         with open(folder_path + '.json', 'w') as file:\n",
    "#             file.write(model_json)\n",
    "# get the Pearson score\n",
    "# y_pred = model.predict(X_test)\n",
    "# y_pred = np.reshape(y_pred, (1094,))\n",
    "\n",
    "# from scipy.stats import pearsonr, spearmanr\n",
    "# pearson_score = pearsonr(y_test, y_pred)\n",
    "# print(f'Pearson correlation - {pearson_score}')\n",
    "# spearman_score = spearmanr(y_test, y_pred)\n",
    "# print(f'Spearman correlation - {spearman_score}')\n",
    "\n",
    "# import pickle\n",
    "# pickle.dump(pearson_score, open(f'LSTM units - {LSTM_units} epochs - {n_epochs} adam_lr {adam_lr} v3.p', 'wb'))\n",
    "\n",
    "# visualize the training and validation loss curves\n",
    "        plt.figure()\n",
    "        loss = history.history['loss']\n",
    "        val_loss = history.history['val_loss']\n",
    "        epoch = np.arange(n_epochs)\n",
    "        plt.plot(epoch, loss, label = 'loss')\n",
    "        plt.plot(epoch, val_loss, label = 'val_loss')\n",
    "        plt.title(f'biLSTM attention LSTM size - {LSTM_size} LSTM dropout - {LSTM_dropout} epochs - {n_epochs} adam_lr {lr} initializer - {initializer}')\n",
    "        plt.legend()\n",
    "        plt.savefig('Kka2/' + f'biLSTM attention LSTM size - {LSTM_size} LSTM dropout - {LSTM_dropout} epochs - {n_epochs} adam_lr {lr} initializer - {initializer}' + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the Pearson score for biLSTM attention\n",
    "model = get_model_biLSTM_attention(initializer, LSTM_size)\n",
    "model.load_weights(folder_path + '/weights.905-0.12600.hdf5')\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred = np.reshape(y_pred, (-1,))\n",
    "\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "pearson_score = pearsonr(y_val, y_pred)\n",
    "print(f'Pearson correlation - {pearson_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(folder_path + ' full model.hdf5')\n",
    "with open(folder_path + ' full model.json', 'w') as file:\n",
    "    file.write(model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation - (0.42184031139093203, 5.767618886509837e-17)\n"
     ]
    }
   ],
   "source": [
    "# get Pearson score for LSTM attention\n",
    "model = get_model_LSTM_attention('he_uniform', LSTM_size)\n",
    "model.load_weights('Kka2/model_and_checkpoints/biLSTM attention LSTM size - 10 epochs - 1000 adam_lr 0.003 initializer - he_uniform/' + 'weights.905-0.12600.hdf5')\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred = np.reshape(y_pred, (-1,))\n",
    "\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "pearson_score = pearsonr(y_val, y_pred)\n",
    "print(f'Pearson correlation - {pearson_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# envision\n",
    "0.47"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "beta_lactamase_LSTM.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
